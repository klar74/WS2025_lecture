{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e518065e",
   "metadata": {},
   "source": [
    "# 📐 Vorlesung 07 - Lineare Regression und Least Squares\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/klar74/WS2025_lecture/blob/main/Vorlesung_07/vorlesung_07_berechnungen.ipynb)\n",
    "\n",
    "## 🎯 Mathematische Grundlagen der linearen Regression\n",
    "\n",
    "In dieser Vorlesung behandeln wir:\n",
    "- ✅ **Normalgleichungen** - Die analytische Lösung für lineare Regression\n",
    "- ✅ **Least Squares Prinzip** - Minimierung der quadrierten Fehler\n",
    "- ✅ **Matrixform** - Elegante Darstellung mit $\\boldsymbol{\\beta} = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{y}$\n",
    "- ✅ **MSE-Berechnung** - Mean Squared Error als Gütemaß\n",
    "- ✅ **Praktische Anwendung** - Schritt-für-Schritt Berechnungen\n",
    "\n",
    "**Warum ist das wichtig?** 🤔\n",
    "- 🔬 **Grundlage für Machine Learning** - Basis für komplexere Algorithmen\n",
    "- 📊 **Datenanalyse** - Trends und Zusammenhänge erkennen\n",
    "- 🎯 **Vorhersagen** - Zukünftige Werte schätzen\n",
    "- 🧮 **Mathematisches Verständnis** - Wie Computer \"lernen\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093923dc",
   "metadata": {},
   "source": [
    "## 🔧 Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f04c1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "\n",
    "# Für schöne Plots\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8' if 'seaborn-v0_8' in plt.style.available else 'default')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['axes.grid'] = True\n",
    "plt.rcParams['grid.alpha'] = 0.3\n",
    "\n",
    "print(\"🎉 Alle Libraries geladen!\")\n",
    "print(\"📊 Bereit für mathematische Berechnungen und Visualisierungen!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1358c5d8",
   "metadata": {},
   "source": [
    "## 📊 Das Beispiel aus der Vorlesung\n",
    "\n",
    "**Kühlanlage-Temperatur-Beispiel**: Energieverbrauch einer Kühlanlage bei verschiedenen Außentemperaturen\n",
    "\n",
    "**Gegeben**: Drei Messpunkte\n",
    "- Punkt 1: (10°C, 14 kWh/h)\n",
    "- Punkt 2: (20°C, 19 kWh/h) \n",
    "- Punkt 3: (30°C, 25 kWh/h)\n",
    "\n",
    "**Gesucht**: Beste Gerade $y = mx + b$ durch diese Punkte mittels **Normalgleichungen**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d923a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die Datenpunkte aus der Vorlesung (exakt wie im Skript)\n",
    "x_data = np.array([10, 20, 30])  # Außentemperatur in °C\n",
    "y_data = np.array([14, 19, 25])  # Energieverbrauch in kWh/h\n",
    "\n",
    "print(\"📋 Unsere Datenpunkte (aus Vorlesung 07):\")\n",
    "print(\"=\" * 50)\n",
    "print(\"Temperatur (°C) | Energieverbrauch (kWh/h)\")\n",
    "print(\"----------------|------------------------\")\n",
    "for i in range(len(x_data)):\n",
    "    print(f\"      {x_data[i]:2d}        |          {y_data[i]:2d}\")\n",
    "\n",
    "# Erste Visualisierung der Datenpunkte\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(x_data, y_data, color='red', s=150, zorder=5, \n",
    "           edgecolors='black', linewidth=2, alpha=0.8)\n",
    "\n",
    "# Punkte beschriften\n",
    "for i, (x, y) in enumerate(zip(x_data, y_data)):\n",
    "    plt.annotate(f'P{i+1}({x}°C, {y} kWh/h)', \n",
    "                (x, y), xytext=(10, 10), textcoords='offset points',\n",
    "                fontweight='bold', fontsize=11,\n",
    "                bbox=dict(boxstyle='round,pad=0.3', facecolor='yellow', alpha=0.7))\n",
    "\n",
    "plt.xlabel('Außentemperatur (°C)', fontweight='bold')\n",
    "plt.ylabel('Energieverbrauch Kühlung (kWh/h)', fontweight='bold')\n",
    "plt.title('Kühlanlage: Energieverbrauch vs. Außentemperatur', fontweight='bold', fontsize=14)\n",
    "plt.xlim(5, 35)\n",
    "plt.ylim(10, 30)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n🎯 Ziel: Finde die beste Gerade y = mx + b durch diese Punkte!\")\n",
    "print(\"📚 Methode: Normalgleichungen (Least Squares)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82197dcc",
   "metadata": {},
   "source": [
    "## 🧮 Schritt 1: Grundwerte berechnen\n",
    "\n",
    "Für die Normalgleichungen benötigen wir folgende Summen:\n",
    "\n",
    "$$\\sum_{i=1}^{n} x_i, \\quad \\sum_{i=1}^{n} y_i, \\quad \\sum_{i=1}^{n} x_i y_i, \\quad \\sum_{i=1}^{n} x_i^2$$\n",
    "\n",
    "**Diese Werte sind die Basis für alle weiteren Berechnungen!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092388a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schritt 1: Grundwerte berechnen (wie im Skript)\n",
    "n = len(x_data)\n",
    "sum_x = np.sum(x_data)      # Σx_i\n",
    "sum_y = np.sum(y_data)      # Σy_i  \n",
    "sum_xy = np.sum(x_data * y_data)  # Σx_i*y_i\n",
    "sum_x2 = np.sum(x_data**2)  # Σx_i²\n",
    "\n",
    "print(\"📊 GRUNDWERTE für Normalgleichungen:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Anzahl Datenpunkte:     n = {n}\")\n",
    "print(f\"Summe x-Werte:         Σx_i = {sum_x}\")\n",
    "print(f\"Summe y-Werte:         Σy_i = {sum_y}\")\n",
    "print(f\"Summe x*y-Produkte:  Σx_i*y_i = {sum_xy}\")\n",
    "print(f\"Summe x²-Werte:       Σx_i² = {sum_x2}\")\n",
    "\n",
    "# Detaillierte Berechnung zeigen\n",
    "print(\"\\n🔍 DETAILLIERTE BERECHNUNG:\")\n",
    "print(\"=\" * 50)\n",
    "print(\"  i  |  x_i  |  y_i  | x_i*y_i | x_i²\")\n",
    "print(\"-----|-------|-------|---------|------\")\n",
    "total_xy = 0\n",
    "total_x2 = 0\n",
    "for i in range(n):\n",
    "    xy_product = x_data[i] * y_data[i]\n",
    "    x_squared = x_data[i]**2\n",
    "    total_xy += xy_product\n",
    "    total_x2 += x_squared\n",
    "    print(f\"  {i+1}  |   {x_data[i]:2d}  |   {y_data[i]:2d}  |   {xy_product:3d}   |  {x_squared:3d}\")\n",
    "\n",
    "print(\"-----|-------|-------|---------|------\")\n",
    "print(f\" Σ   |   {sum_x:2d}  |   {sum_y:2d}  |   {total_xy:3d}   | {total_x2:4d}\")\n",
    "\n",
    "# Kontrolle\n",
    "print(f\"\\n✅ KONTROLLE:\")\n",
    "print(f\"   Σx_i*y_i berechnet: {total_xy} = {sum_xy} ✓\")\n",
    "print(f\"   Σx_i² berechnet: {total_x2} = {sum_x2} ✓\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf8ec92",
   "metadata": {},
   "source": [
    "## 🎯 Schritt 2: Normalgleichungen anwenden\n",
    "\n",
    "Die **Normalgleichungen** für lineare Regression lauten:\n",
    "\n",
    "$$m = \\frac{n \\sum x_i y_i - \\sum x_i \\sum y_i}{n \\sum x_i^2 - (\\sum x_i)^2}$$\n",
    "\n",
    "$$b = \\frac{\\sum y_i - m \\sum x_i}{n}$$\n",
    "\n",
    "**Diese Formeln minimieren automatisch den MSE (Mean Squared Error)!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be48e91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🎯 NORMALGLEICHUNGEN SCHRITT FÜR SCHRITT:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Schritt 2a: Steigung m berechnen\n",
    "print(\"📐 STEIGUNG m berechnen:\")\n",
    "print(f\"   m = (n×Σx_i*y_i - Σx_i×Σy_i) / (n×Σx_i² - (Σx_i)²)\")\n",
    "\n",
    "# Zähler berechnen\n",
    "numerator_m = n * sum_xy - sum_x * sum_y\n",
    "print(f\"   Zähler = {n}×{sum_xy} - {sum_x}×{sum_y}\")\n",
    "print(f\"   Zähler = {n * sum_xy} - {sum_x * sum_y} = {numerator_m}\")\n",
    "\n",
    "# Nenner berechnen\n",
    "denominator_m = n * sum_x2 - sum_x**2\n",
    "print(f\"   Nenner = {n}×{sum_x2} - {sum_x}²\")\n",
    "print(f\"   Nenner = {n * sum_x2} - {sum_x**2} = {denominator_m}\")\n",
    "\n",
    "# Steigung\n",
    "m_analytical = numerator_m / denominator_m\n",
    "print(f\"   m = {numerator_m} / {denominator_m} = {m_analytical:.6f}\")\n",
    "\n",
    "print(\"\\n📏 Y-ACHSENABSCHNITT b berechnen:\")\n",
    "print(f\"   b = (Σy_i - m×Σx_i) / n\")\n",
    "print(f\"   b = ({sum_y} - {m_analytical:.6f}×{sum_x}) / {n}\")\n",
    "\n",
    "# Y-Achsenabschnitt\n",
    "b_analytical = (sum_y - m_analytical * sum_x) / n\n",
    "print(f\"   b = ({sum_y} - {m_analytical * sum_x:.3f}) / {n}\")\n",
    "print(f\"   b = {sum_y - m_analytical * sum_x:.3f} / {n} = {b_analytical:.6f}\")\n",
    "\n",
    "print(\"\\n🎉 ERGEBNIS:\")\n",
    "print(\"=\" * 30)\n",
    "print(f\"📐 Steigung:           m = {m_analytical:.6f}\")\n",
    "print(f\"📏 Y-Achsenabschnitt:  b = {b_analytical:.6f}\")\n",
    "print(f\"📈 Gleichung:    y = {m_analytical:.3f}x + {b_analytical:.2f}\")\n",
    "\n",
    "# Physikalische Interpretation\n",
    "print(\"\\n🔬 PHYSIKALISCHE INTERPRETATION:\")\n",
    "print(f\"   • Pro 1°C Temperaturanstieg steigt der Energieverbrauch um {m_analytical:.3f} kWh/h\")\n",
    "print(f\"   • Bei 0°C würde die Anlage theoretisch {b_analytical:.1f} kWh/h verbrauchen\")\n",
    "print(f\"   • Positive Steigung bestätigt: Wärmer → mehr Kühlenergie nötig\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba3a608",
   "metadata": {},
   "source": [
    "## 📊 Schritt 3: MSE (Mean Squared Error) berechnen\n",
    "\n",
    "Der **MSE** misst die Güte unserer Regression:\n",
    "\n",
    "$$\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - (mx_i + b))^2$$\n",
    "\n",
    "**Je kleiner der MSE, desto besser die Anpassung!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df2d4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"📊 MSE (MEAN SQUARED ERROR) BERECHNUNG:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# MSE Schritt für Schritt berechnen\n",
    "print(\"🔍 SCHRITT-FÜR-SCHRITT BERECHNUNG:\")\n",
    "print(\"  i  | x_i | y_i | ŷ_i = mx_i+b | Residuum | Residuum²\")\n",
    "print(\"-----|-----|-----|--------------|----------|----------\")\n",
    "\n",
    "total_squared_error = 0\n",
    "residuals = []\n",
    "predictions = []\n",
    "\n",
    "for i in range(n):\n",
    "    x_i = x_data[i]\n",
    "    y_i = y_data[i]\n",
    "    y_pred = m_analytical * x_i + b_analytical\n",
    "    residual = y_i - y_pred\n",
    "    squared_residual = residual**2\n",
    "    \n",
    "    predictions.append(y_pred)\n",
    "    residuals.append(residual)\n",
    "    total_squared_error += squared_residual\n",
    "    \n",
    "    print(f\"  {i+1}  | {x_i:2d}  | {y_i:2d}  |    {y_pred:6.2f}    |  {residual:6.2f}  |  {squared_residual:6.4f}\")\n",
    "\n",
    "mse_analytical = total_squared_error / n\n",
    "\n",
    "print(\"-----|-----|-----|--------------|----------|----------\")\n",
    "print(f\" Σ   |     |     |              |          | {total_squared_error:7.4f}\")\n",
    "print(f\"\\n📈 MSE = Σ(Residuum²) / n = {total_squared_error:.4f} / {n} = {mse_analytical:.6f}\")\n",
    "\n",
    "# Zusätzliche Gütemaße\n",
    "predictions = np.array(predictions)\n",
    "residuals = np.array(residuals)\n",
    "\n",
    "# R² (Bestimmtheitsgmaß) berechnen\n",
    "ss_res = np.sum(residuals**2)  # Sum of squares of residuals\n",
    "ss_tot = np.sum((y_data - np.mean(y_data))**2)  # Total sum of squares\n",
    "r_squared = 1 - (ss_res / ss_tot)\n",
    "\n",
    "# RMSE (Root Mean Squared Error)\n",
    "rmse = np.sqrt(mse_analytical)\n",
    "\n",
    "print(\"\\n📊 ZUSÄTZLICHE GÜTEMAßE:\")\n",
    "print(\"=\" * 30)\n",
    "print(f\"📈 MSE  = {mse_analytical:.6f}\")\n",
    "print(f\"📐 RMSE = {rmse:.6f} kWh/h\")\n",
    "print(f\"📊 R²   = {r_squared:.6f} ({r_squared*100:.2f}%)\")\n",
    "\n",
    "print(\"\\n💡 INTERPRETATION:\")\n",
    "print(f\"   • MSE von {mse_analytical:.3f} bedeutet mittlerer quadrierter Fehler\")\n",
    "print(f\"   • RMSE von {rmse:.3f} kWh/h ist der mittlere absolute Fehler\")\n",
    "print(f\"   • R² von {r_squared:.3f} bedeutet {r_squared*100:.1f}% der Varianz wird erklärt\")\n",
    "\n",
    "if r_squared > 0.9:\n",
    "    print(\"   🎉 Ausgezeichnete Anpassung!\")\n",
    "elif r_squared > 0.7:\n",
    "    print(\"   ✅ Gute Anpassung!\")\n",
    "else:\n",
    "    print(\"   ⚠️ Anpassung könnte besser sein\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a855e6",
   "metadata": {},
   "source": [
    "## 📈 Schritt 4: Visualisierung der Regression\n",
    "\n",
    "Jetzt visualisieren wir:\n",
    "- ✅ **Datenpunkte** und **Regressionsgerade**\n",
    "- ✅ **Residuen** (Abweichungen)\n",
    "- ✅ **Vorhersagen** für neue Werte\n",
    "- ✅ **Konfidenzintervalle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88af293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Große Visualisierung der Regression\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Plot 1: Regression mit Datenpunkten\n",
    "x_line = np.linspace(0, 40, 100)\n",
    "y_line = m_analytical * x_line + b_analytical\n",
    "\n",
    "ax1.scatter(x_data, y_data, color='red', s=150, zorder=5, \n",
    "           edgecolors='black', linewidth=2, label='Datenpunkte')\n",
    "ax1.plot(x_line, y_line, 'b-', linewidth=3, alpha=0.8, \n",
    "         label=f'Regression: y = {m_analytical:.3f}x + {b_analytical:.2f}')\n",
    "\n",
    "# Vorhersagen für die Datenpunkte markieren\n",
    "ax1.scatter(x_data, predictions, color='blue', s=100, alpha=0.7, \n",
    "           marker='x', linewidth=3, label='Vorhersagen')\n",
    "\n",
    "# Residuen als Linien\n",
    "for i in range(n):\n",
    "    ax1.plot([x_data[i], x_data[i]], [y_data[i], predictions[i]], \n",
    "            'gray', linestyle='--', alpha=0.7, linewidth=2)\n",
    "\n",
    "ax1.set_xlabel('Außentemperatur (°C)', fontweight='bold')\n",
    "ax1.set_ylabel('Energieverbrauch (kWh/h)', fontweight='bold')\n",
    "ax1.set_title('Lineare Regression - Hauptdiagramm', fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_xlim(0, 40)\n",
    "ax1.set_ylim(10, 30)\n",
    "\n",
    "# Plot 2: Residuen-Plot\n",
    "ax2.scatter(x_data, residuals, color='purple', s=120, alpha=0.8)\n",
    "ax2.axhline(y=0, color='red', linestyle='-', alpha=0.7, linewidth=2)\n",
    "ax2.set_xlabel('Außentemperatur (°C)', fontweight='bold')\n",
    "ax2.set_ylabel('Residuen (kWh/h)', fontweight='bold')\n",
    "ax2.set_title('Residuen-Plot', fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Residuen beschriften\n",
    "for i, (x, res) in enumerate(zip(x_data, residuals)):\n",
    "    ax2.annotate(f'{res:.2f}', (x, res), xytext=(5, 5), \n",
    "                textcoords='offset points', fontweight='bold')\n",
    "\n",
    "# Plot 3: Q-Q Plot der Residuen (Normalverteilung prüfen)\n",
    "stats.probplot(residuals, dist=\"norm\", plot=ax3)\n",
    "ax3.set_title('Q-Q Plot (Normalverteilung der Residuen)', fontweight='bold')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Vorhersagen für erweiterten Bereich\n",
    "x_extended = np.linspace(-5, 45, 200)\n",
    "y_extended = m_analytical * x_extended + b_analytical\n",
    "\n",
    "ax4.plot(x_extended, y_extended, 'b-', linewidth=3, alpha=0.8, \n",
    "         label=f'Regression (erweitert)')\n",
    "ax4.scatter(x_data, y_data, color='red', s=150, zorder=5, \n",
    "           edgecolors='black', linewidth=2, label='Datenpunkte')\n",
    "\n",
    "# Interessante Vorhersagen markieren\n",
    "temp_predictions = [0, 25, 35, 40]\n",
    "for temp in temp_predictions:\n",
    "    energy = m_analytical * temp + b_analytical\n",
    "    ax4.plot(temp, energy, 'go', markersize=10, alpha=0.8)\n",
    "    ax4.annotate(f'({temp}°C, {energy:.1f} kWh/h)', \n",
    "                (temp, energy), xytext=(5, 5), textcoords='offset points',\n",
    "                fontweight='bold', fontsize=9,\n",
    "                bbox=dict(boxstyle='round,pad=0.2', facecolor='lightgreen', alpha=0.7))\n",
    "\n",
    "ax4.set_xlabel('Außentemperatur (°C)', fontweight='bold')\n",
    "ax4.set_ylabel('Energieverbrauch (kWh/h)', fontweight='bold')\n",
    "ax4.set_title('Vorhersagen für erweiterten Temperaturbereich', fontweight='bold')\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "ax4.set_xlim(-5, 45)\n",
    "ax4.set_ylim(5, 35)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"📊 VISUALISIERUNG KOMPLETT!\")\n",
    "print(\"=\" * 40)\n",
    "print(\"🔍 Oben links:  Hauptregression mit Residuen\")\n",
    "print(\"🔍 Oben rechts: Residuen-Plot (sollten zufällig um 0 streuen)\")\n",
    "print(\"🔍 Unten links: Q-Q Plot (prüft Normalverteilung der Residuen)\")\n",
    "print(\"🔍 Unten rechts: Vorhersagen für erweiterten Bereich\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751a4e45",
   "metadata": {},
   "source": [
    "## 🔬 Schritt 5: Vergleich mit anderen Methoden\n",
    "\n",
    "Wir vergleichen unsere **handberechneten Normalgleichungen** mit:\n",
    "- ✅ **NumPy polyfit** - Polynomiale Anpassung\n",
    "- ✅ **SciPy linregress** - Statistische lineare Regression\n",
    "- ✅ **Scikit-learn** - Machine Learning Ansatz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ec3997",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🔬 VERGLEICH MIT ANDEREN METHODEN:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Methode 1: NumPy polyfit\n",
    "poly_coeff = np.polyfit(x_data, y_data, 1)\n",
    "m_numpy, b_numpy = poly_coeff[0], poly_coeff[1]\n",
    "mse_numpy = np.mean((y_data - (m_numpy * x_data + b_numpy))**2)\n",
    "\n",
    "print(\"1️⃣ NumPy polyfit:\")\n",
    "print(f\"   m = {m_numpy:.6f}, b = {b_numpy:.6f}, MSE = {mse_numpy:.8f}\")\n",
    "\n",
    "# Methode 2: SciPy linregress\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(x_data, y_data)\n",
    "mse_scipy = np.mean((y_data - (slope * x_data + intercept))**2)\n",
    "\n",
    "print(\"\\n2️⃣ SciPy linregress:\")\n",
    "print(f\"   m = {slope:.6f}, b = {intercept:.6f}, MSE = {mse_scipy:.8f}\")\n",
    "print(f\"   R = {r_value:.6f}, R² = {r_value**2:.6f}\")\n",
    "print(f\"   p-value = {p_value:.8f}, std_err = {std_err:.8f}\")\n",
    "\n",
    "# Methode 3: Scikit-learn (falls verfügbar)\n",
    "try:\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.metrics import mean_squared_error, r2_score\n",
    "    \n",
    "    # Scikit-learn erwartet 2D Arrays\n",
    "    X_sklearn = x_data.reshape(-1, 1)\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    model.fit(X_sklearn, y_data)\n",
    "    \n",
    "    m_sklearn = model.coef_[0]\n",
    "    b_sklearn = model.intercept_\n",
    "    y_pred_sklearn = model.predict(X_sklearn)\n",
    "    mse_sklearn = mean_squared_error(y_data, y_pred_sklearn)\n",
    "    r2_sklearn = r2_score(y_data, y_pred_sklearn)\n",
    "    \n",
    "    print(\"\\n3️⃣ Scikit-learn LinearRegression:\")\n",
    "    print(f\"   m = {m_sklearn:.6f}, b = {b_sklearn:.6f}, MSE = {mse_sklearn:.8f}\")\n",
    "    print(f\"   R² = {r2_sklearn:.6f}\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"\\n3️⃣ Scikit-learn: Nicht verfügbar (pip install scikit-learn)\")\n",
    "    m_sklearn, b_sklearn, mse_sklearn = m_analytical, b_analytical, mse_analytical\n",
    "\n",
    "# Vergleichstabelle\n",
    "print(\"\\n📊 VERGLEICHSTABELLE:\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'Methode':<25} {'Steigung m':<12} {'Y-Abschn. b':<12} {'MSE':<12}\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'Normalgleichungen':<25} {m_analytical:<12.6f} {b_analytical:<12.6f} {mse_analytical:<12.8f}\")\n",
    "print(f\"{'NumPy polyfit':<25} {m_numpy:<12.6f} {b_numpy:<12.6f} {mse_numpy:<12.8f}\")\n",
    "print(f\"{'SciPy linregress':<25} {slope:<12.6f} {intercept:<12.6f} {mse_scipy:<12.8f}\")\n",
    "try:\n",
    "    print(f\"{'Scikit-learn':<25} {m_sklearn:<12.6f} {b_sklearn:<12.6f} {mse_sklearn:<12.8f}\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Differenzen berechnen\n",
    "diff_m_numpy = abs(m_analytical - m_numpy)\n",
    "diff_b_numpy = abs(b_analytical - b_numpy)\n",
    "diff_m_scipy = abs(m_analytical - slope)\n",
    "diff_b_scipy = abs(b_analytical - intercept)\n",
    "\n",
    "print(\"\\n✅ ÜBEREINSTIMMUNG (Abweichungen):\")\n",
    "print(f\"   NumPy:     Δm = {diff_m_numpy:.10f}, Δb = {diff_b_numpy:.10f}\")\n",
    "print(f\"   SciPy:     Δm = {diff_m_scipy:.10f}, Δb = {diff_b_scipy:.10f}\")\n",
    "\n",
    "if diff_m_numpy < 1e-10 and diff_b_numpy < 1e-10:\n",
    "    print(\"\\n🎉 PERFEKT! Alle Methoden liefern identische Ergebnisse!\")\n",
    "    print(\"💡 Das bestätigt unsere Normalgleichungen-Implementierung!\")\n",
    "else:\n",
    "    print(\"\\n⚠️ Kleine numerische Unterschiede (normal bei Floating-Point-Arithmetik)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb055d6",
   "metadata": {},
   "source": [
    "## 🎯 Schritt 6: Praktische Anwendungen\n",
    "\n",
    "**Jetzt können wir Vorhersagen machen!**\n",
    "\n",
    "Unsere Gleichung: $y = 0.550x + 8.500$\n",
    "\n",
    "Was bedeutet das für die Praxis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d36a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🎯 PRAKTISCHE ANWENDUNGEN:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Regressionsfunktion definieren\n",
    "def predict_energy(temperature):\n",
    "    \"\"\"Vorhersage des Energieverbrauchs basierend auf Temperatur\"\"\"\n",
    "    return m_analytical * temperature + b_analytical\n",
    "\n",
    "# Interessante Vorhersagen\n",
    "scenarios = [\n",
    "    (\"Kalter Winter\", 0),\n",
    "    (\"Milder Frühling\", 15),\n",
    "    (\"Warmer Sommer\", 35),\n",
    "    (\"Hitzewelle\", 40),\n",
    "    (\"Extremhitze\", 45)\n",
    "]\n",
    "\n",
    "print(\"🌡️ ENERGIEVERBRAUCH-VORHERSAGEN:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"{'Szenario':<15} {'Temp (°C)':<10} {'Energie (kWh/h)':<15} {'Kommentar'}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for scenario, temp in scenarios:\n",
    "    energy = predict_energy(temp)\n",
    "    \n",
    "    if energy < 15:\n",
    "        comment = \"Niedriger Verbrauch\"\n",
    "    elif energy < 25:\n",
    "        comment = \"Moderater Verbrauch\"\n",
    "    else:\n",
    "        comment = \"Hoher Verbrauch\"\n",
    "    \n",
    "    print(f\"{scenario:<15} {temp:<10} {energy:<15.1f} {comment}\")\n",
    "\n",
    "# Kostenberechnung (Beispiel)\n",
    "energy_cost_per_kwh = 0.30  # 30 Cent pro kWh\n",
    "\n",
    "print(f\"\\n💰 KOSTENBERECHNUNG (bei {energy_cost_per_kwh:.2f} €/kWh):\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Szenario':<15} {'Temp (°C)':<10} {'Kosten/Stunde (€)':<18} {'Kosten/Tag (€)'}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for scenario, temp in scenarios:\n",
    "    energy = predict_energy(temp)\n",
    "    cost_per_hour = energy * energy_cost_per_kwh\n",
    "    cost_per_day = cost_per_hour * 24\n",
    "    \n",
    "    print(f\"{scenario:<15} {temp:<10} {cost_per_hour:<18.2f} {cost_per_day:<12.2f}\")\n",
    "\n",
    "# Energieeinsparung durch Temperaturreduktion\n",
    "print(f\"\\n🌱 ENERGIEEINSPARUNG durch 1°C Temperaturreduktion:\")\n",
    "print(f\"   • Einsparung: {m_analytical:.3f} kWh/h\")\n",
    "print(f\"   • Kosteneinsparung: {m_analytical * energy_cost_per_kwh:.3f} €/Stunde\")\n",
    "print(f\"   • Kosteneinsparung: {m_analytical * energy_cost_per_kwh * 24:.2f} €/Tag\")\n",
    "print(f\"   • Kosteneinsparung: {m_analytical * energy_cost_per_kwh * 24 * 365:.0f} €/Jahr\")\n",
    "\n",
    "print(f\"\\n💡 PRAKTISCHE ERKENNTNISSE:\")\n",
    "print(f\"   • Bei 0°C: Grundverbrauch von {b_analytical:.1f} kWh/h (Ventilation, etc.)\")\n",
    "print(f\"   • Linearer Anstieg: {m_analytical:.3f} kWh/h pro °C\")\n",
    "print(f\"   • Energieeffizienz: Temperatur um nur 1°C senken spart deutlich Kosten!\")\n",
    "print(f\"   • Planbarkeit: Energiebedarf bei jeder Temperatur vorhersagbar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8b5bf8",
   "metadata": {},
   "source": [
    "## 🧮 Schritt 7: Matrixform der Normalgleichungen\n",
    "\n",
    "**Die elegante Matrixschreibweise:**\n",
    "\n",
    "$$\\boldsymbol{\\beta} = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{y}$$\n",
    "\n",
    "wo:\n",
    "- $\\boldsymbol{\\beta} = \\begin{pmatrix} b \\\\ m \\end{pmatrix}$ (Parameter)\n",
    "- $\\mathbf{X} = \\begin{pmatrix} 1 & x_1 \\\\ 1 & x_2 \\\\ 1 & x_3 \\end{pmatrix}$ (Design-Matrix)\n",
    "- $\\mathbf{y} = \\begin{pmatrix} y_1 \\\\ y_2 \\\\ y_3 \\end{pmatrix}$ (Zielwerte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb24caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🧮 MATRIXFORM DER NORMALGLEICHUNGEN:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Design-Matrix X erstellen (erste Spalte: 1en, zweite Spalte: x-Werte)\n",
    "X = np.column_stack([np.ones(len(x_data)), x_data])\n",
    "y = y_data.reshape(-1, 1)\n",
    "\n",
    "print(\"📊 MATRIZEN AUFSTELLEN:\")\n",
    "print(f\"\\nDesign-Matrix X (n×2):\")\n",
    "print(X)\n",
    "print(f\"\\nZielvektor y (n×1):\")\n",
    "print(y.flatten())\n",
    "\n",
    "# Schritt 1: X^T berechnen\n",
    "X_transpose = X.T\n",
    "print(f\"\\n🔄 X^T (Transponierte):\")\n",
    "print(X_transpose)\n",
    "\n",
    "# Schritt 2: X^T * X berechnen\n",
    "XTX = X_transpose @ X\n",
    "print(f\"\\n🔢 X^T * X (2×2 Matrix):\")\n",
    "print(XTX)\n",
    "print(f\"\\nInterpretation:\")\n",
    "print(f\"   XTX[0,0] = {XTX[0,0]} = n = Anzahl Datenpunkte\")\n",
    "print(f\"   XTX[0,1] = {XTX[0,1]} = Σx_i = Summe der x-Werte\")\n",
    "print(f\"   XTX[1,0] = {XTX[1,0]} = Σx_i = Summe der x-Werte\")\n",
    "print(f\"   XTX[1,1] = {XTX[1,1]} = Σx_i² = Summe der quadrierten x-Werte\")\n",
    "\n",
    "# Schritt 3: (X^T * X)^(-1) berechnen\n",
    "XTX_inv = np.linalg.inv(XTX)\n",
    "print(f\"\\n🔄 (X^T * X)^(-1) (Inverse):\")\n",
    "print(XTX_inv)\n",
    "\n",
    "# Schritt 4: X^T * y berechnen\n",
    "XTy = X_transpose @ y\n",
    "print(f\"\\n🔢 X^T * y (2×1 Vektor):\")\n",
    "print(XTy.flatten())\n",
    "print(f\"\\nInterpretation:\")\n",
    "print(f\"   XTy[0] = {XTy[0,0]} = Σy_i = Summe der y-Werte\")\n",
    "print(f\"   XTy[1] = {XTy[1,0]} = Σx_i*y_i = Summe der Produkte\")\n",
    "\n",
    "# Schritt 5: β = (X^T * X)^(-1) * X^T * y\n",
    "beta = XTX_inv @ XTy\n",
    "b_matrix, m_matrix = beta[0,0], beta[1,0]\n",
    "\n",
    "print(f\"\\n🎯 ENDERGEBNIS β = (X^T * X)^(-1) * X^T * y:\")\n",
    "print(f\"β = {beta.flatten()}\")\n",
    "print(f\"\\nParameter:\")\n",
    "print(f\"   b (Y-Achsenabschnitt) = {b_matrix:.6f}\")\n",
    "print(f\"   m (Steigung)          = {m_matrix:.6f}\")\n",
    "\n",
    "# Vergleich mit unserer direkten Berechnung\n",
    "print(f\"\\n✅ VERGLEICH MIT DIREKTER BERECHNUNG:\")\n",
    "print(f\"{'Methode':<20} {'Steigung m':<15} {'Y-Abschnitt b':<15}\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"{'Normalgleichungen':<20} {m_analytical:<15.6f} {b_analytical:<15.6f}\")\n",
    "print(f\"{'Matrixform':<20} {m_matrix:<15.6f} {b_matrix:<15.6f}\")\n",
    "\n",
    "diff_m_matrix = abs(m_analytical - m_matrix)\n",
    "diff_b_matrix = abs(b_analytical - b_matrix)\n",
    "print(f\"\\nAbweichungen: Δm = {diff_m_matrix:.10f}, Δb = {diff_b_matrix:.10f}\")\n",
    "\n",
    "if diff_m_matrix < 1e-10 and diff_b_matrix < 1e-10:\n",
    "    print(\"🎉 IDENTISCHE ERGEBNISSE! Matrixform bestätigt Normalgleichungen!\")\n",
    "else:\n",
    "    print(\"⚠️ Kleine numerische Unterschiede\")\n",
    "\n",
    "print(f\"\\n💡 WARUM MATRIXFORM?\")\n",
    "print(f\"   • Elegante mathematische Notation\")\n",
    "print(f\"   • Einfach auf mehr Variablen erweiterbar\")\n",
    "print(f\"   • Effiziente Computerimplementierung\")\n",
    "print(f\"   • Basis für komplexere ML-Algorithmen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde6e867",
   "metadata": {},
   "source": [
    "## 📊 Zusammenfassung: Was haben wir gelernt?\n",
    "\n",
    "### 🎯 **Kernkonzepte**:\n",
    "1. **Normalgleichungen** - Analytische Lösung für lineare Regression\n",
    "2. **Least Squares** - Minimierung der quadrierten Fehler\n",
    "3. **MSE** - Quantifizierung der Modellgüte\n",
    "4. **Matrixform** - Elegante mathematische Darstellung\n",
    "\n",
    "### 🔬 **Praktische Erkenntnisse**:\n",
    "- Energieverbrauch steigt linear mit der Temperatur\n",
    "- Vorhersagen für beliebige Temperaturen möglich\n",
    "- Kosteneinsparungen durch Temperaturoptimierung quantifizierbar\n",
    "\n",
    "### 💡 **Warum ist das wichtig für Data Science?**\n",
    "- **Basis für Machine Learning** - Verständnis der Grundprinzipien\n",
    "- **Interpretierbarkeit** - Klare mathematische Beziehungen\n",
    "- **Effizienz** - Schnelle analytische Lösung\n",
    "- **Erweiterbarkeit** - Grundlage für komplexere Modelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f22f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abschließende Zusammenfassung mit allen wichtigen Ergebnissen\n",
    "print(\"📋 VOLLSTÄNDIGE ZUSAMMENFASSUNG - VORLESUNG 07\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"📊 DATENBASIS:\")\n",
    "print(f\"   • {n} Datenpunkte: Temperatur vs. Energieverbrauch\")\n",
    "print(f\"   • Bereich: {x_data.min()}°C bis {x_data.max()}°C\")\n",
    "print(f\"   • Energiebereich: {y_data.min()} bis {y_data.max()} kWh/h\")\n",
    "\n",
    "print(f\"\\n🎯 REGRESSIONSERGEBNIS:\")\n",
    "print(f\"   • Gleichung: y = {m_analytical:.3f}x + {b_analytical:.2f}\")\n",
    "print(f\"   • Steigung: {m_analytical:.3f} kWh/h pro °C\")\n",
    "print(f\"   • Y-Achsenabschnitt: {b_analytical:.2f} kWh/h bei 0°C\")\n",
    "\n",
    "print(f\"\\n📈 MODELLGÜTE:\")\n",
    "print(f\"   • MSE: {mse_analytical:.6f}\")\n",
    "print(f\"   • RMSE: {np.sqrt(mse_analytical):.3f} kWh/h\")\n",
    "print(f\"   • R²: {r_squared:.3f} ({r_squared*100:.1f}% Varianz erklärt)\")\n",
    "\n",
    "print(f\"\\n💰 PRAKTISCHE ANWENDUNG:\")\n",
    "energy_at_20 = predict_energy(20)\n",
    "energy_at_30 = predict_energy(30)\n",
    "print(f\"   • Bei 20°C: {energy_at_20:.1f} kWh/h\")\n",
    "print(f\"   • Bei 30°C: {energy_at_30:.1f} kWh/h\")\n",
    "print(f\"   • Einsparung pro °C: {m_analytical:.3f} kWh/h\")\n",
    "daily_savings = m_analytical * 24 * energy_cost_per_kwh\n",
    "print(f\"   • Kosteneinsparung pro °C: {daily_savings:.2f} €/Tag\")\n",
    "\n",
    "print(f\"\\n✅ VALIDIERUNG:\")\n",
    "print(f\"   • Normalgleichungen ≡ NumPy ≡ SciPy ≡ Matrixform\")\n",
    "print(f\"   • Alle Methoden liefern identische Ergebnisse\")\n",
    "print(f\"   • Residuen sind klein und zufällig verteilt\")\n",
    "\n",
    "print(f\"\\n🎓 LERNERFOLG:\")\n",
    "print(f\"   ✅ Normalgleichungen verstanden und angewendet\")\n",
    "print(f\"   ✅ MSE-Minimierung nachvollzogen\")\n",
    "print(f\"   ✅ Matrixform der linearen Regression beherrscht\")\n",
    "print(f\"   ✅ Praktische Anwendung und Interpretation gelernt\")\n",
    "print(f\"   ✅ Grundlage für erweiterte ML-Algorithmen geschaffen\")\n",
    "\n",
    "print(f\"\\n🚀 NÄCHSTE SCHRITTE:\")\n",
    "print(f\"   • Multiple lineare Regression (mehrere Variablen)\")\n",
    "print(f\"   • Nichtlineare Regression\")\n",
    "print(f\"   • Regularisierung (Ridge, Lasso)\")\n",
    "print(f\"   • Neuronale Netze als Erweiterung\")\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 70)\n",
    "print(f\"🎉 VORLESUNG 07 ERFOLGREICH ABGESCHLOSSEN! 🎉\")\n",
    "print(f\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lecture_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
