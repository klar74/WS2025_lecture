{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e518065e",
   "metadata": {},
   "source": [
    "# üìê Vorlesung 07 - Lineare Regression und Least Squares\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/klar74/WS2025_lecture/blob/main/Vorlesung_07/vorlesung_07_berechnungen.ipynb)\n",
    "\n",
    "## üéØ Mathematische Grundlagen der linearen Regression\n",
    "\n",
    "In dieser Vorlesung behandeln wir:\n",
    "- ‚úÖ **Normalgleichungen** - Die analytische L√∂sung f√ºr lineare Regression\n",
    "- ‚úÖ **Least Squares Prinzip** - Minimierung der quadrierten Fehler\n",
    "- ‚úÖ **Matrixform** - Elegante Darstellung mit $\\boldsymbol{\\beta} = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{y}$\n",
    "- ‚úÖ **MSE-Berechnung** - Mean Squared Error als G√ºtema√ü\n",
    "- ‚úÖ **Praktische Anwendung** - Schritt-f√ºr-Schritt Berechnungen\n",
    "\n",
    "**Warum ist das wichtig?** ü§î\n",
    "- üî¨ **Grundlage f√ºr Machine Learning** - Basis f√ºr komplexere Algorithmen\n",
    "- üìä **Datenanalyse** - Trends und Zusammenh√§nge erkennen\n",
    "- üéØ **Vorhersagen** - Zuk√ºnftige Werte sch√§tzen\n",
    "- üßÆ **Mathematisches Verst√§ndnis** - Wie Computer \"lernen\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093923dc",
   "metadata": {},
   "source": [
    "## üîß Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f04c1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "\n",
    "# F√ºr sch√∂ne Plots\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8' if 'seaborn-v0_8' in plt.style.available else 'default')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['axes.grid'] = True\n",
    "plt.rcParams['grid.alpha'] = 0.3\n",
    "\n",
    "print(\"üéâ Alle Libraries geladen!\")\n",
    "print(\"üìä Bereit f√ºr mathematische Berechnungen und Visualisierungen!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1358c5d8",
   "metadata": {},
   "source": [
    "## üìä Das Beispiel aus der Vorlesung\n",
    "\n",
    "**K√ºhlanlage-Temperatur-Beispiel**: Energieverbrauch einer K√ºhlanlage bei verschiedenen Au√üentemperaturen\n",
    "\n",
    "**Gegeben**: Drei Messpunkte\n",
    "- Punkt 1: (10¬∞C, 14 kWh/h)\n",
    "- Punkt 2: (20¬∞C, 19 kWh/h) \n",
    "- Punkt 3: (30¬∞C, 25 kWh/h)\n",
    "\n",
    "**Gesucht**: Beste Gerade $y = mx + b$ durch diese Punkte mittels **Normalgleichungen**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d923a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die Datenpunkte aus der Vorlesung (exakt wie im Skript)\n",
    "x_data = np.array([10, 20, 30])  # Au√üentemperatur in ¬∞C\n",
    "y_data = np.array([14, 19, 25])  # Energieverbrauch in kWh/h\n",
    "\n",
    "print(\"üìã Unsere Datenpunkte (aus Vorlesung 07):\")\n",
    "print(\"=\" * 50)\n",
    "print(\"Temperatur (¬∞C) | Energieverbrauch (kWh/h)\")\n",
    "print(\"----------------|------------------------\")\n",
    "for i in range(len(x_data)):\n",
    "    print(f\"      {x_data[i]:2d}        |          {y_data[i]:2d}\")\n",
    "\n",
    "# Erste Visualisierung der Datenpunkte\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(x_data, y_data, color='red', s=150, zorder=5, \n",
    "           edgecolors='black', linewidth=2, alpha=0.8)\n",
    "\n",
    "# Punkte beschriften\n",
    "for i, (x, y) in enumerate(zip(x_data, y_data)):\n",
    "    plt.annotate(f'P{i+1}({x}¬∞C, {y} kWh/h)', \n",
    "                (x, y), xytext=(10, 10), textcoords='offset points',\n",
    "                fontweight='bold', fontsize=11,\n",
    "                bbox=dict(boxstyle='round,pad=0.3', facecolor='yellow', alpha=0.7))\n",
    "\n",
    "plt.xlabel('Au√üentemperatur (¬∞C)', fontweight='bold')\n",
    "plt.ylabel('Energieverbrauch K√ºhlung (kWh/h)', fontweight='bold')\n",
    "plt.title('K√ºhlanlage: Energieverbrauch vs. Au√üentemperatur', fontweight='bold', fontsize=14)\n",
    "plt.xlim(5, 35)\n",
    "plt.ylim(10, 30)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüéØ Ziel: Finde die beste Gerade y = mx + b durch diese Punkte!\")\n",
    "print(\"üìö Methode: Normalgleichungen (Least Squares)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82197dcc",
   "metadata": {},
   "source": [
    "## üßÆ Schritt 1: Grundwerte berechnen\n",
    "\n",
    "F√ºr die Normalgleichungen ben√∂tigen wir folgende Summen:\n",
    "\n",
    "$$\\sum_{i=1}^{n} x_i, \\quad \\sum_{i=1}^{n} y_i, \\quad \\sum_{i=1}^{n} x_i y_i, \\quad \\sum_{i=1}^{n} x_i^2$$\n",
    "\n",
    "**Diese Werte sind die Basis f√ºr alle weiteren Berechnungen!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092388a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schritt 1: Grundwerte berechnen (wie im Skript)\n",
    "n = len(x_data)\n",
    "sum_x = np.sum(x_data)      # Œ£x_i\n",
    "sum_y = np.sum(y_data)      # Œ£y_i  \n",
    "sum_xy = np.sum(x_data * y_data)  # Œ£x_i*y_i\n",
    "sum_x2 = np.sum(x_data**2)  # Œ£x_i¬≤\n",
    "\n",
    "print(\"üìä GRUNDWERTE f√ºr Normalgleichungen:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Anzahl Datenpunkte:     n = {n}\")\n",
    "print(f\"Summe x-Werte:         Œ£x_i = {sum_x}\")\n",
    "print(f\"Summe y-Werte:         Œ£y_i = {sum_y}\")\n",
    "print(f\"Summe x*y-Produkte:  Œ£x_i*y_i = {sum_xy}\")\n",
    "print(f\"Summe x¬≤-Werte:       Œ£x_i¬≤ = {sum_x2}\")\n",
    "\n",
    "# Detaillierte Berechnung zeigen\n",
    "print(\"\\nüîç DETAILLIERTE BERECHNUNG:\")\n",
    "print(\"=\" * 50)\n",
    "print(\"  i  |  x_i  |  y_i  | x_i*y_i | x_i¬≤\")\n",
    "print(\"-----|-------|-------|---------|------\")\n",
    "total_xy = 0\n",
    "total_x2 = 0\n",
    "for i in range(n):\n",
    "    xy_product = x_data[i] * y_data[i]\n",
    "    x_squared = x_data[i]**2\n",
    "    total_xy += xy_product\n",
    "    total_x2 += x_squared\n",
    "    print(f\"  {i+1}  |   {x_data[i]:2d}  |   {y_data[i]:2d}  |   {xy_product:3d}   |  {x_squared:3d}\")\n",
    "\n",
    "print(\"-----|-------|-------|---------|------\")\n",
    "print(f\" Œ£   |   {sum_x:2d}  |   {sum_y:2d}  |   {total_xy:3d}   | {total_x2:4d}\")\n",
    "\n",
    "# Kontrolle\n",
    "print(f\"\\n‚úÖ KONTROLLE:\")\n",
    "print(f\"   Œ£x_i*y_i berechnet: {total_xy} = {sum_xy} ‚úì\")\n",
    "print(f\"   Œ£x_i¬≤ berechnet: {total_x2} = {sum_x2} ‚úì\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf8ec92",
   "metadata": {},
   "source": [
    "## üéØ Schritt 2: Normalgleichungen anwenden\n",
    "\n",
    "Die **Normalgleichungen** f√ºr lineare Regression lauten:\n",
    "\n",
    "$$m = \\frac{n \\sum x_i y_i - \\sum x_i \\sum y_i}{n \\sum x_i^2 - (\\sum x_i)^2}$$\n",
    "\n",
    "$$b = \\frac{\\sum y_i - m \\sum x_i}{n}$$\n",
    "\n",
    "**Diese Formeln minimieren automatisch den MSE (Mean Squared Error)!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be48e91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üéØ NORMALGLEICHUNGEN SCHRITT F√úR SCHRITT:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Schritt 2a: Steigung m berechnen\n",
    "print(\"üìê STEIGUNG m berechnen:\")\n",
    "print(f\"   m = (n√óŒ£x_i*y_i - Œ£x_i√óŒ£y_i) / (n√óŒ£x_i¬≤ - (Œ£x_i)¬≤)\")\n",
    "\n",
    "# Z√§hler berechnen\n",
    "numerator_m = n * sum_xy - sum_x * sum_y\n",
    "print(f\"   Z√§hler = {n}√ó{sum_xy} - {sum_x}√ó{sum_y}\")\n",
    "print(f\"   Z√§hler = {n * sum_xy} - {sum_x * sum_y} = {numerator_m}\")\n",
    "\n",
    "# Nenner berechnen\n",
    "denominator_m = n * sum_x2 - sum_x**2\n",
    "print(f\"   Nenner = {n}√ó{sum_x2} - {sum_x}¬≤\")\n",
    "print(f\"   Nenner = {n * sum_x2} - {sum_x**2} = {denominator_m}\")\n",
    "\n",
    "# Steigung\n",
    "m_analytical = numerator_m / denominator_m\n",
    "print(f\"   m = {numerator_m} / {denominator_m} = {m_analytical:.6f}\")\n",
    "\n",
    "print(\"\\nüìè Y-ACHSENABSCHNITT b berechnen:\")\n",
    "print(f\"   b = (Œ£y_i - m√óŒ£x_i) / n\")\n",
    "print(f\"   b = ({sum_y} - {m_analytical:.6f}√ó{sum_x}) / {n}\")\n",
    "\n",
    "# Y-Achsenabschnitt\n",
    "b_analytical = (sum_y - m_analytical * sum_x) / n\n",
    "print(f\"   b = ({sum_y} - {m_analytical * sum_x:.3f}) / {n}\")\n",
    "print(f\"   b = {sum_y - m_analytical * sum_x:.3f} / {n} = {b_analytical:.6f}\")\n",
    "\n",
    "print(\"\\nüéâ ERGEBNIS:\")\n",
    "print(\"=\" * 30)\n",
    "print(f\"üìê Steigung:           m = {m_analytical:.6f}\")\n",
    "print(f\"üìè Y-Achsenabschnitt:  b = {b_analytical:.6f}\")\n",
    "print(f\"üìà Gleichung:    y = {m_analytical:.3f}x + {b_analytical:.2f}\")\n",
    "\n",
    "# Physikalische Interpretation\n",
    "print(\"\\nüî¨ PHYSIKALISCHE INTERPRETATION:\")\n",
    "print(f\"   ‚Ä¢ Pro 1¬∞C Temperaturanstieg steigt der Energieverbrauch um {m_analytical:.3f} kWh/h\")\n",
    "print(f\"   ‚Ä¢ Bei 0¬∞C w√ºrde die Anlage theoretisch {b_analytical:.1f} kWh/h verbrauchen\")\n",
    "print(f\"   ‚Ä¢ Positive Steigung best√§tigt: W√§rmer ‚Üí mehr K√ºhlenergie n√∂tig\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba3a608",
   "metadata": {},
   "source": [
    "## üìä Schritt 3: MSE (Mean Squared Error) berechnen\n",
    "\n",
    "Der **MSE** misst die G√ºte unserer Regression:\n",
    "\n",
    "$$\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - (mx_i + b))^2$$\n",
    "\n",
    "**Je kleiner der MSE, desto besser die Anpassung!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df2d4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìä MSE (MEAN SQUARED ERROR) BERECHNUNG:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# MSE Schritt f√ºr Schritt berechnen\n",
    "print(\"üîç SCHRITT-F√úR-SCHRITT BERECHNUNG:\")\n",
    "print(\"  i  | x_i | y_i | ≈∑_i = mx_i+b | Residuum | Residuum¬≤\")\n",
    "print(\"-----|-----|-----|--------------|----------|----------\")\n",
    "\n",
    "total_squared_error = 0\n",
    "residuals = []\n",
    "predictions = []\n",
    "\n",
    "for i in range(n):\n",
    "    x_i = x_data[i]\n",
    "    y_i = y_data[i]\n",
    "    y_pred = m_analytical * x_i + b_analytical\n",
    "    residual = y_i - y_pred\n",
    "    squared_residual = residual**2\n",
    "    \n",
    "    predictions.append(y_pred)\n",
    "    residuals.append(residual)\n",
    "    total_squared_error += squared_residual\n",
    "    \n",
    "    print(f\"  {i+1}  | {x_i:2d}  | {y_i:2d}  |    {y_pred:6.2f}    |  {residual:6.2f}  |  {squared_residual:6.4f}\")\n",
    "\n",
    "mse_analytical = total_squared_error / n\n",
    "\n",
    "print(\"-----|-----|-----|--------------|----------|----------\")\n",
    "print(f\" Œ£   |     |     |              |          | {total_squared_error:7.4f}\")\n",
    "print(f\"\\nüìà MSE = Œ£(Residuum¬≤) / n = {total_squared_error:.4f} / {n} = {mse_analytical:.6f}\")\n",
    "\n",
    "# Zus√§tzliche G√ºtema√üe\n",
    "predictions = np.array(predictions)\n",
    "residuals = np.array(residuals)\n",
    "\n",
    "# R¬≤ (Bestimmtheitsgma√ü) berechnen\n",
    "ss_res = np.sum(residuals**2)  # Sum of squares of residuals\n",
    "ss_tot = np.sum((y_data - np.mean(y_data))**2)  # Total sum of squares\n",
    "r_squared = 1 - (ss_res / ss_tot)\n",
    "\n",
    "# RMSE (Root Mean Squared Error)\n",
    "rmse = np.sqrt(mse_analytical)\n",
    "\n",
    "print(\"\\nüìä ZUS√ÑTZLICHE G√úTEMA√üE:\")\n",
    "print(\"=\" * 30)\n",
    "print(f\"üìà MSE  = {mse_analytical:.6f}\")\n",
    "print(f\"üìê RMSE = {rmse:.6f} kWh/h\")\n",
    "print(f\"üìä R¬≤   = {r_squared:.6f} ({r_squared*100:.2f}%)\")\n",
    "\n",
    "print(\"\\nüí° INTERPRETATION:\")\n",
    "print(f\"   ‚Ä¢ MSE von {mse_analytical:.3f} bedeutet mittlerer quadrierter Fehler\")\n",
    "print(f\"   ‚Ä¢ RMSE von {rmse:.3f} kWh/h ist der mittlere absolute Fehler\")\n",
    "print(f\"   ‚Ä¢ R¬≤ von {r_squared:.3f} bedeutet {r_squared*100:.1f}% der Varianz wird erkl√§rt\")\n",
    "\n",
    "if r_squared > 0.9:\n",
    "    print(\"   üéâ Ausgezeichnete Anpassung!\")\n",
    "elif r_squared > 0.7:\n",
    "    print(\"   ‚úÖ Gute Anpassung!\")\n",
    "else:\n",
    "    print(\"   ‚ö†Ô∏è Anpassung k√∂nnte besser sein\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a855e6",
   "metadata": {},
   "source": [
    "## üìà Schritt 4: Visualisierung der Regression\n",
    "\n",
    "Jetzt visualisieren wir:\n",
    "- ‚úÖ **Datenpunkte** und **Regressionsgerade**\n",
    "- ‚úÖ **Residuen** (Abweichungen)\n",
    "- ‚úÖ **Vorhersagen** f√ºr neue Werte\n",
    "- ‚úÖ **Konfidenzintervalle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88af293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gro√üe Visualisierung der Regression\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Plot 1: Regression mit Datenpunkten\n",
    "x_line = np.linspace(0, 40, 100)\n",
    "y_line = m_analytical * x_line + b_analytical\n",
    "\n",
    "ax1.scatter(x_data, y_data, color='red', s=150, zorder=5, \n",
    "           edgecolors='black', linewidth=2, label='Datenpunkte')\n",
    "ax1.plot(x_line, y_line, 'b-', linewidth=3, alpha=0.8, \n",
    "         label=f'Regression: y = {m_analytical:.3f}x + {b_analytical:.2f}')\n",
    "\n",
    "# Vorhersagen f√ºr die Datenpunkte markieren\n",
    "ax1.scatter(x_data, predictions, color='blue', s=100, alpha=0.7, \n",
    "           marker='x', linewidth=3, label='Vorhersagen')\n",
    "\n",
    "# Residuen als Linien\n",
    "for i in range(n):\n",
    "    ax1.plot([x_data[i], x_data[i]], [y_data[i], predictions[i]], \n",
    "            'gray', linestyle='--', alpha=0.7, linewidth=2)\n",
    "\n",
    "ax1.set_xlabel('Au√üentemperatur (¬∞C)', fontweight='bold')\n",
    "ax1.set_ylabel('Energieverbrauch (kWh/h)', fontweight='bold')\n",
    "ax1.set_title('Lineare Regression - Hauptdiagramm', fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_xlim(0, 40)\n",
    "ax1.set_ylim(10, 30)\n",
    "\n",
    "# Plot 2: Residuen-Plot\n",
    "ax2.scatter(x_data, residuals, color='purple', s=120, alpha=0.8)\n",
    "ax2.axhline(y=0, color='red', linestyle='-', alpha=0.7, linewidth=2)\n",
    "ax2.set_xlabel('Au√üentemperatur (¬∞C)', fontweight='bold')\n",
    "ax2.set_ylabel('Residuen (kWh/h)', fontweight='bold')\n",
    "ax2.set_title('Residuen-Plot', fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Residuen beschriften\n",
    "for i, (x, res) in enumerate(zip(x_data, residuals)):\n",
    "    ax2.annotate(f'{res:.2f}', (x, res), xytext=(5, 5), \n",
    "                textcoords='offset points', fontweight='bold')\n",
    "\n",
    "# Plot 3: Q-Q Plot der Residuen (Normalverteilung pr√ºfen)\n",
    "stats.probplot(residuals, dist=\"norm\", plot=ax3)\n",
    "ax3.set_title('Q-Q Plot (Normalverteilung der Residuen)', fontweight='bold')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Vorhersagen f√ºr erweiterten Bereich\n",
    "x_extended = np.linspace(-5, 45, 200)\n",
    "y_extended = m_analytical * x_extended + b_analytical\n",
    "\n",
    "ax4.plot(x_extended, y_extended, 'b-', linewidth=3, alpha=0.8, \n",
    "         label=f'Regression (erweitert)')\n",
    "ax4.scatter(x_data, y_data, color='red', s=150, zorder=5, \n",
    "           edgecolors='black', linewidth=2, label='Datenpunkte')\n",
    "\n",
    "# Interessante Vorhersagen markieren\n",
    "temp_predictions = [0, 25, 35, 40]\n",
    "for temp in temp_predictions:\n",
    "    energy = m_analytical * temp + b_analytical\n",
    "    ax4.plot(temp, energy, 'go', markersize=10, alpha=0.8)\n",
    "    ax4.annotate(f'({temp}¬∞C, {energy:.1f} kWh/h)', \n",
    "                (temp, energy), xytext=(5, 5), textcoords='offset points',\n",
    "                fontweight='bold', fontsize=9,\n",
    "                bbox=dict(boxstyle='round,pad=0.2', facecolor='lightgreen', alpha=0.7))\n",
    "\n",
    "ax4.set_xlabel('Au√üentemperatur (¬∞C)', fontweight='bold')\n",
    "ax4.set_ylabel('Energieverbrauch (kWh/h)', fontweight='bold')\n",
    "ax4.set_title('Vorhersagen f√ºr erweiterten Temperaturbereich', fontweight='bold')\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "ax4.set_xlim(-5, 45)\n",
    "ax4.set_ylim(5, 35)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üìä VISUALISIERUNG KOMPLETT!\")\n",
    "print(\"=\" * 40)\n",
    "print(\"üîç Oben links:  Hauptregression mit Residuen\")\n",
    "print(\"üîç Oben rechts: Residuen-Plot (sollten zuf√§llig um 0 streuen)\")\n",
    "print(\"üîç Unten links: Q-Q Plot (pr√ºft Normalverteilung der Residuen)\")\n",
    "print(\"üîç Unten rechts: Vorhersagen f√ºr erweiterten Bereich\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751a4e45",
   "metadata": {},
   "source": [
    "## üî¨ Schritt 5: Vergleich mit anderen Methoden\n",
    "\n",
    "Wir vergleichen unsere **handberechneten Normalgleichungen** mit:\n",
    "- ‚úÖ **NumPy polyfit** - Polynomiale Anpassung\n",
    "- ‚úÖ **SciPy linregress** - Statistische lineare Regression\n",
    "- ‚úÖ **Scikit-learn** - Machine Learning Ansatz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ec3997",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üî¨ VERGLEICH MIT ANDEREN METHODEN:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Methode 1: NumPy polyfit\n",
    "poly_coeff = np.polyfit(x_data, y_data, 1)\n",
    "m_numpy, b_numpy = poly_coeff[0], poly_coeff[1]\n",
    "mse_numpy = np.mean((y_data - (m_numpy * x_data + b_numpy))**2)\n",
    "\n",
    "print(\"1Ô∏è‚É£ NumPy polyfit:\")\n",
    "print(f\"   m = {m_numpy:.6f}, b = {b_numpy:.6f}, MSE = {mse_numpy:.8f}\")\n",
    "\n",
    "# Methode 2: SciPy linregress\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(x_data, y_data)\n",
    "mse_scipy = np.mean((y_data - (slope * x_data + intercept))**2)\n",
    "\n",
    "print(\"\\n2Ô∏è‚É£ SciPy linregress:\")\n",
    "print(f\"   m = {slope:.6f}, b = {intercept:.6f}, MSE = {mse_scipy:.8f}\")\n",
    "print(f\"   R = {r_value:.6f}, R¬≤ = {r_value**2:.6f}\")\n",
    "print(f\"   p-value = {p_value:.8f}, std_err = {std_err:.8f}\")\n",
    "\n",
    "# Methode 3: Scikit-learn (falls verf√ºgbar)\n",
    "try:\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.metrics import mean_squared_error, r2_score\n",
    "    \n",
    "    # Scikit-learn erwartet 2D Arrays\n",
    "    X_sklearn = x_data.reshape(-1, 1)\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    model.fit(X_sklearn, y_data)\n",
    "    \n",
    "    m_sklearn = model.coef_[0]\n",
    "    b_sklearn = model.intercept_\n",
    "    y_pred_sklearn = model.predict(X_sklearn)\n",
    "    mse_sklearn = mean_squared_error(y_data, y_pred_sklearn)\n",
    "    r2_sklearn = r2_score(y_data, y_pred_sklearn)\n",
    "    \n",
    "    print(\"\\n3Ô∏è‚É£ Scikit-learn LinearRegression:\")\n",
    "    print(f\"   m = {m_sklearn:.6f}, b = {b_sklearn:.6f}, MSE = {mse_sklearn:.8f}\")\n",
    "    print(f\"   R¬≤ = {r2_sklearn:.6f}\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"\\n3Ô∏è‚É£ Scikit-learn: Nicht verf√ºgbar (pip install scikit-learn)\")\n",
    "    m_sklearn, b_sklearn, mse_sklearn = m_analytical, b_analytical, mse_analytical\n",
    "\n",
    "# Vergleichstabelle\n",
    "print(\"\\nüìä VERGLEICHSTABELLE:\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'Methode':<25} {'Steigung m':<12} {'Y-Abschn. b':<12} {'MSE':<12}\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'Normalgleichungen':<25} {m_analytical:<12.6f} {b_analytical:<12.6f} {mse_analytical:<12.8f}\")\n",
    "print(f\"{'NumPy polyfit':<25} {m_numpy:<12.6f} {b_numpy:<12.6f} {mse_numpy:<12.8f}\")\n",
    "print(f\"{'SciPy linregress':<25} {slope:<12.6f} {intercept:<12.6f} {mse_scipy:<12.8f}\")\n",
    "try:\n",
    "    print(f\"{'Scikit-learn':<25} {m_sklearn:<12.6f} {b_sklearn:<12.6f} {mse_sklearn:<12.8f}\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Differenzen berechnen\n",
    "diff_m_numpy = abs(m_analytical - m_numpy)\n",
    "diff_b_numpy = abs(b_analytical - b_numpy)\n",
    "diff_m_scipy = abs(m_analytical - slope)\n",
    "diff_b_scipy = abs(b_analytical - intercept)\n",
    "\n",
    "print(\"\\n‚úÖ √úBEREINSTIMMUNG (Abweichungen):\")\n",
    "print(f\"   NumPy:     Œîm = {diff_m_numpy:.10f}, Œîb = {diff_b_numpy:.10f}\")\n",
    "print(f\"   SciPy:     Œîm = {diff_m_scipy:.10f}, Œîb = {diff_b_scipy:.10f}\")\n",
    "\n",
    "if diff_m_numpy < 1e-10 and diff_b_numpy < 1e-10:\n",
    "    print(\"\\nüéâ PERFEKT! Alle Methoden liefern identische Ergebnisse!\")\n",
    "    print(\"üí° Das best√§tigt unsere Normalgleichungen-Implementierung!\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Kleine numerische Unterschiede (normal bei Floating-Point-Arithmetik)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb055d6",
   "metadata": {},
   "source": [
    "## üéØ Schritt 6: Praktische Anwendungen\n",
    "\n",
    "**Jetzt k√∂nnen wir Vorhersagen machen!**\n",
    "\n",
    "Unsere Gleichung: $y = 0.550x + 8.500$\n",
    "\n",
    "Was bedeutet das f√ºr die Praxis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d36a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üéØ PRAKTISCHE ANWENDUNGEN:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Regressionsfunktion definieren\n",
    "def predict_energy(temperature):\n",
    "    \"\"\"Vorhersage des Energieverbrauchs basierend auf Temperatur\"\"\"\n",
    "    return m_analytical * temperature + b_analytical\n",
    "\n",
    "# Interessante Vorhersagen\n",
    "scenarios = [\n",
    "    (\"Kalter Winter\", 0),\n",
    "    (\"Milder Fr√ºhling\", 15),\n",
    "    (\"Warmer Sommer\", 35),\n",
    "    (\"Hitzewelle\", 40),\n",
    "    (\"Extremhitze\", 45)\n",
    "]\n",
    "\n",
    "print(\"üå°Ô∏è ENERGIEVERBRAUCH-VORHERSAGEN:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"{'Szenario':<15} {'Temp (¬∞C)':<10} {'Energie (kWh/h)':<15} {'Kommentar'}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for scenario, temp in scenarios:\n",
    "    energy = predict_energy(temp)\n",
    "    \n",
    "    if energy < 15:\n",
    "        comment = \"Niedriger Verbrauch\"\n",
    "    elif energy < 25:\n",
    "        comment = \"Moderater Verbrauch\"\n",
    "    else:\n",
    "        comment = \"Hoher Verbrauch\"\n",
    "    \n",
    "    print(f\"{scenario:<15} {temp:<10} {energy:<15.1f} {comment}\")\n",
    "\n",
    "# Kostenberechnung (Beispiel)\n",
    "energy_cost_per_kwh = 0.30  # 30 Cent pro kWh\n",
    "\n",
    "print(f\"\\nüí∞ KOSTENBERECHNUNG (bei {energy_cost_per_kwh:.2f} ‚Ç¨/kWh):\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Szenario':<15} {'Temp (¬∞C)':<10} {'Kosten/Stunde (‚Ç¨)':<18} {'Kosten/Tag (‚Ç¨)'}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for scenario, temp in scenarios:\n",
    "    energy = predict_energy(temp)\n",
    "    cost_per_hour = energy * energy_cost_per_kwh\n",
    "    cost_per_day = cost_per_hour * 24\n",
    "    \n",
    "    print(f\"{scenario:<15} {temp:<10} {cost_per_hour:<18.2f} {cost_per_day:<12.2f}\")\n",
    "\n",
    "# Energieeinsparung durch Temperaturreduktion\n",
    "print(f\"\\nüå± ENERGIEEINSPARUNG durch 1¬∞C Temperaturreduktion:\")\n",
    "print(f\"   ‚Ä¢ Einsparung: {m_analytical:.3f} kWh/h\")\n",
    "print(f\"   ‚Ä¢ Kosteneinsparung: {m_analytical * energy_cost_per_kwh:.3f} ‚Ç¨/Stunde\")\n",
    "print(f\"   ‚Ä¢ Kosteneinsparung: {m_analytical * energy_cost_per_kwh * 24:.2f} ‚Ç¨/Tag\")\n",
    "print(f\"   ‚Ä¢ Kosteneinsparung: {m_analytical * energy_cost_per_kwh * 24 * 365:.0f} ‚Ç¨/Jahr\")\n",
    "\n",
    "print(f\"\\nüí° PRAKTISCHE ERKENNTNISSE:\")\n",
    "print(f\"   ‚Ä¢ Bei 0¬∞C: Grundverbrauch von {b_analytical:.1f} kWh/h (Ventilation, etc.)\")\n",
    "print(f\"   ‚Ä¢ Linearer Anstieg: {m_analytical:.3f} kWh/h pro ¬∞C\")\n",
    "print(f\"   ‚Ä¢ Energieeffizienz: Temperatur um nur 1¬∞C senken spart deutlich Kosten!\")\n",
    "print(f\"   ‚Ä¢ Planbarkeit: Energiebedarf bei jeder Temperatur vorhersagbar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8b5bf8",
   "metadata": {},
   "source": [
    "## üßÆ Schritt 7: Matrixform der Normalgleichungen\n",
    "\n",
    "**Die elegante Matrixschreibweise:**\n",
    "\n",
    "$$\\boldsymbol{\\beta} = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{y}$$\n",
    "\n",
    "wo:\n",
    "- $\\boldsymbol{\\beta} = \\begin{pmatrix} b \\\\ m \\end{pmatrix}$ (Parameter)\n",
    "- $\\mathbf{X} = \\begin{pmatrix} 1 & x_1 \\\\ 1 & x_2 \\\\ 1 & x_3 \\end{pmatrix}$ (Design-Matrix)\n",
    "- $\\mathbf{y} = \\begin{pmatrix} y_1 \\\\ y_2 \\\\ y_3 \\end{pmatrix}$ (Zielwerte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb24caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üßÆ MATRIXFORM DER NORMALGLEICHUNGEN:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Design-Matrix X erstellen (erste Spalte: 1en, zweite Spalte: x-Werte)\n",
    "X = np.column_stack([np.ones(len(x_data)), x_data])\n",
    "y = y_data.reshape(-1, 1)\n",
    "\n",
    "print(\"üìä MATRIZEN AUFSTELLEN:\")\n",
    "print(f\"\\nDesign-Matrix X (n√ó2):\")\n",
    "print(X)\n",
    "print(f\"\\nZielvektor y (n√ó1):\")\n",
    "print(y.flatten())\n",
    "\n",
    "# Schritt 1: X^T berechnen\n",
    "X_transpose = X.T\n",
    "print(f\"\\nüîÑ X^T (Transponierte):\")\n",
    "print(X_transpose)\n",
    "\n",
    "# Schritt 2: X^T * X berechnen\n",
    "XTX = X_transpose @ X\n",
    "print(f\"\\nüî¢ X^T * X (2√ó2 Matrix):\")\n",
    "print(XTX)\n",
    "print(f\"\\nInterpretation:\")\n",
    "print(f\"   XTX[0,0] = {XTX[0,0]} = n = Anzahl Datenpunkte\")\n",
    "print(f\"   XTX[0,1] = {XTX[0,1]} = Œ£x_i = Summe der x-Werte\")\n",
    "print(f\"   XTX[1,0] = {XTX[1,0]} = Œ£x_i = Summe der x-Werte\")\n",
    "print(f\"   XTX[1,1] = {XTX[1,1]} = Œ£x_i¬≤ = Summe der quadrierten x-Werte\")\n",
    "\n",
    "# Schritt 3: (X^T * X)^(-1) berechnen\n",
    "XTX_inv = np.linalg.inv(XTX)\n",
    "print(f\"\\nüîÑ (X^T * X)^(-1) (Inverse):\")\n",
    "print(XTX_inv)\n",
    "\n",
    "# Schritt 4: X^T * y berechnen\n",
    "XTy = X_transpose @ y\n",
    "print(f\"\\nüî¢ X^T * y (2√ó1 Vektor):\")\n",
    "print(XTy.flatten())\n",
    "print(f\"\\nInterpretation:\")\n",
    "print(f\"   XTy[0] = {XTy[0,0]} = Œ£y_i = Summe der y-Werte\")\n",
    "print(f\"   XTy[1] = {XTy[1,0]} = Œ£x_i*y_i = Summe der Produkte\")\n",
    "\n",
    "# Schritt 5: Œ≤ = (X^T * X)^(-1) * X^T * y\n",
    "beta = XTX_inv @ XTy\n",
    "b_matrix, m_matrix = beta[0,0], beta[1,0]\n",
    "\n",
    "print(f\"\\nüéØ ENDERGEBNIS Œ≤ = (X^T * X)^(-1) * X^T * y:\")\n",
    "print(f\"Œ≤ = {beta.flatten()}\")\n",
    "print(f\"\\nParameter:\")\n",
    "print(f\"   b (Y-Achsenabschnitt) = {b_matrix:.6f}\")\n",
    "print(f\"   m (Steigung)          = {m_matrix:.6f}\")\n",
    "\n",
    "# Vergleich mit unserer direkten Berechnung\n",
    "print(f\"\\n‚úÖ VERGLEICH MIT DIREKTER BERECHNUNG:\")\n",
    "print(f\"{'Methode':<20} {'Steigung m':<15} {'Y-Abschnitt b':<15}\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"{'Normalgleichungen':<20} {m_analytical:<15.6f} {b_analytical:<15.6f}\")\n",
    "print(f\"{'Matrixform':<20} {m_matrix:<15.6f} {b_matrix:<15.6f}\")\n",
    "\n",
    "diff_m_matrix = abs(m_analytical - m_matrix)\n",
    "diff_b_matrix = abs(b_analytical - b_matrix)\n",
    "print(f\"\\nAbweichungen: Œîm = {diff_m_matrix:.10f}, Œîb = {diff_b_matrix:.10f}\")\n",
    "\n",
    "if diff_m_matrix < 1e-10 and diff_b_matrix < 1e-10:\n",
    "    print(\"üéâ IDENTISCHE ERGEBNISSE! Matrixform best√§tigt Normalgleichungen!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Kleine numerische Unterschiede\")\n",
    "\n",
    "print(f\"\\nüí° WARUM MATRIXFORM?\")\n",
    "print(f\"   ‚Ä¢ Elegante mathematische Notation\")\n",
    "print(f\"   ‚Ä¢ Einfach auf mehr Variablen erweiterbar\")\n",
    "print(f\"   ‚Ä¢ Effiziente Computerimplementierung\")\n",
    "print(f\"   ‚Ä¢ Basis f√ºr komplexere ML-Algorithmen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde6e867",
   "metadata": {},
   "source": [
    "## üìä Zusammenfassung: Was haben wir gelernt?\n",
    "\n",
    "### üéØ **Kernkonzepte**:\n",
    "1. **Normalgleichungen** - Analytische L√∂sung f√ºr lineare Regression\n",
    "2. **Least Squares** - Minimierung der quadrierten Fehler\n",
    "3. **MSE** - Quantifizierung der Modellg√ºte\n",
    "4. **Matrixform** - Elegante mathematische Darstellung\n",
    "\n",
    "### üî¨ **Praktische Erkenntnisse**:\n",
    "- Energieverbrauch steigt linear mit der Temperatur\n",
    "- Vorhersagen f√ºr beliebige Temperaturen m√∂glich\n",
    "- Kosteneinsparungen durch Temperaturoptimierung quantifizierbar\n",
    "\n",
    "### üí° **Warum ist das wichtig f√ºr Data Science?**\n",
    "- **Basis f√ºr Machine Learning** - Verst√§ndnis der Grundprinzipien\n",
    "- **Interpretierbarkeit** - Klare mathematische Beziehungen\n",
    "- **Effizienz** - Schnelle analytische L√∂sung\n",
    "- **Erweiterbarkeit** - Grundlage f√ºr komplexere Modelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f22f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abschlie√üende Zusammenfassung mit allen wichtigen Ergebnissen\n",
    "print(\"üìã VOLLST√ÑNDIGE ZUSAMMENFASSUNG - VORLESUNG 07\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"üìä DATENBASIS:\")\n",
    "print(f\"   ‚Ä¢ {n} Datenpunkte: Temperatur vs. Energieverbrauch\")\n",
    "print(f\"   ‚Ä¢ Bereich: {x_data.min()}¬∞C bis {x_data.max()}¬∞C\")\n",
    "print(f\"   ‚Ä¢ Energiebereich: {y_data.min()} bis {y_data.max()} kWh/h\")\n",
    "\n",
    "print(f\"\\nüéØ REGRESSIONSERGEBNIS:\")\n",
    "print(f\"   ‚Ä¢ Gleichung: y = {m_analytical:.3f}x + {b_analytical:.2f}\")\n",
    "print(f\"   ‚Ä¢ Steigung: {m_analytical:.3f} kWh/h pro ¬∞C\")\n",
    "print(f\"   ‚Ä¢ Y-Achsenabschnitt: {b_analytical:.2f} kWh/h bei 0¬∞C\")\n",
    "\n",
    "print(f\"\\nüìà MODELLG√úTE:\")\n",
    "print(f\"   ‚Ä¢ MSE: {mse_analytical:.6f}\")\n",
    "print(f\"   ‚Ä¢ RMSE: {np.sqrt(mse_analytical):.3f} kWh/h\")\n",
    "print(f\"   ‚Ä¢ R¬≤: {r_squared:.3f} ({r_squared*100:.1f}% Varianz erkl√§rt)\")\n",
    "\n",
    "print(f\"\\nüí∞ PRAKTISCHE ANWENDUNG:\")\n",
    "energy_at_20 = predict_energy(20)\n",
    "energy_at_30 = predict_energy(30)\n",
    "print(f\"   ‚Ä¢ Bei 20¬∞C: {energy_at_20:.1f} kWh/h\")\n",
    "print(f\"   ‚Ä¢ Bei 30¬∞C: {energy_at_30:.1f} kWh/h\")\n",
    "print(f\"   ‚Ä¢ Einsparung pro ¬∞C: {m_analytical:.3f} kWh/h\")\n",
    "daily_savings = m_analytical * 24 * energy_cost_per_kwh\n",
    "print(f\"   ‚Ä¢ Kosteneinsparung pro ¬∞C: {daily_savings:.2f} ‚Ç¨/Tag\")\n",
    "\n",
    "print(f\"\\n‚úÖ VALIDIERUNG:\")\n",
    "print(f\"   ‚Ä¢ Normalgleichungen ‚â° NumPy ‚â° SciPy ‚â° Matrixform\")\n",
    "print(f\"   ‚Ä¢ Alle Methoden liefern identische Ergebnisse\")\n",
    "print(f\"   ‚Ä¢ Residuen sind klein und zuf√§llig verteilt\")\n",
    "\n",
    "print(f\"\\nüéì LERNERFOLG:\")\n",
    "print(f\"   ‚úÖ Normalgleichungen verstanden und angewendet\")\n",
    "print(f\"   ‚úÖ MSE-Minimierung nachvollzogen\")\n",
    "print(f\"   ‚úÖ Matrixform der linearen Regression beherrscht\")\n",
    "print(f\"   ‚úÖ Praktische Anwendung und Interpretation gelernt\")\n",
    "print(f\"   ‚úÖ Grundlage f√ºr erweiterte ML-Algorithmen geschaffen\")\n",
    "\n",
    "print(f\"\\nüöÄ N√ÑCHSTE SCHRITTE:\")\n",
    "print(f\"   ‚Ä¢ Multiple lineare Regression (mehrere Variablen)\")\n",
    "print(f\"   ‚Ä¢ Nichtlineare Regression\")\n",
    "print(f\"   ‚Ä¢ Regularisierung (Ridge, Lasso)\")\n",
    "print(f\"   ‚Ä¢ Neuronale Netze als Erweiterung\")\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 70)\n",
    "print(f\"üéâ VORLESUNG 07 ERFOLGREICH ABGESCHLOSSEN! üéâ\")\n",
    "print(f\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lecture_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
