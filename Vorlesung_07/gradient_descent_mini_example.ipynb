{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0101cafb",
   "metadata": {},
   "source": [
    "# 📐 Gradientenabstieg am Mini-Beispiel - Vorlesung 07\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/klar74/WS2025_lecture/blob/main/Vorlesung_07/gradient_descent_mini_example.ipynb)\n",
    "\n",
    "## 🎯 Das Energie-Temperatur-Beispiel aus der Vorlesung\n",
    "\n",
    "Wir haben drei Messpunkte vom **Energieverbrauch einer Kühlanlage** bei verschiedenen **Außentemperaturen**:\n",
    "- Punkt 1: (10°C, 14 kWh/h) \n",
    "- Punkt 2: (20°C, 19 kWh/h)\n",
    "- Punkt 3: (30°C, 25 kWh/h)\n",
    "\n",
    "**Ziel**: Finde die beste Gerade $y = mx + b$ durch diese Punkte!\n",
    "\n",
    "**Warum macht das Sinn?** 🤔\n",
    "- ❄️ **Niedrigere Temperaturen** → Weniger Kühlbedarf → Geringerer Energieverbrauch  \n",
    "- ☀️ **Höhere Temperaturen** → Mehr Kühlbedarf → Höherer Energieverbrauch\n",
    "- 📈 **Vorhersagen möglich**: Was passiert bei 0°C? Bei 40°C? Bei 25°C?\n",
    "\n",
    "**In der Vorlesung haben wir gelernt:**\n",
    "- ✅ **Normalgleichungen** - Die exakte analytische Lösung\n",
    "- ✅ **Matrixform** - $\\boldsymbol{\\beta} = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{y}$\n",
    "- ✅ **MSE minimieren** - Das Least-Squares-Prinzip\n",
    "\n",
    "**Aber was passiert, wenn Normalgleichungen nicht funktionieren?**\n",
    "- 🔴 **Nichtlineare Modelle** (z.B. $y = ae^{bx}$)\n",
    "- 🔴 **Millionen von Parametern** (neuronale Netze)\n",
    "- 🔴 **Große Datensätze** (Matrix-Inversion zu langsam)\n",
    "\n",
    "**Antwort: Gradientenabstieg!** 🚀\n",
    "\n",
    "Wir schauen uns jetzt den Gradientenabstieg an diesem einfachen Beispiel an!\n",
    "\n",
    "## 🗺️ Was lernen wir heute?\n",
    "\n",
    "✅ **MSE-Landschaft visualisieren** - Wie sieht das \"Gebirge\" aus?  \n",
    "✅ **Gradientenabstieg Schritt für Schritt** - Wie findet der Computer den Weg bergab?  \n",
    "✅ **Parameter-Optimierung verstehen** - Warum funktioniert das Verfahren?  \n",
    "✅ **Verbindung zu neuronalen Netzen** - Das gleiche Prinzip bei Millionen Parametern!  \n",
    "✅ **Wann Normalgleichungen vs. Gradientenabstieg** - Die richtige Wahl treffen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072698cb",
   "metadata": {},
   "source": [
    "## 🔧 Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c94778",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pandas as pd\n",
    "\n",
    "# Für schöne Plots\n",
    "%matplotlib inline\n",
    "# Versuche verschiedene Styles (fallback wenn seaborn nicht verfügbar)\n",
    "try:\n",
    "    plt.style.use('seaborn-v0_8')\n",
    "except:\n",
    "    try:\n",
    "        plt.style.use('seaborn')\n",
    "    except:\n",
    "        plt.style.use('default')\n",
    "        \n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "print(\"🎉 Alle Libraries geladen!\")\n",
    "print(\"📊 Bereit für Gradientenabstieg-Visualisierung!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e0eca8",
   "metadata": {},
   "source": [
    "## 📊 Unsere Datenpunkte - Das Kühlanlage-Temperatur-Beispiel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e86ce2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🎯 STARTPUNKT-KONFIGURATION für Gradientenabstieg\n",
    "# =================================================================\n",
    "# HIER KANNST DU VERSCHIEDENE STARTPUNKTE AUSPROBIEREN!\n",
    "# Diese Variablen werden in allen nachfolgenden Visualisierungen verwendet\n",
    "\n",
    "# Startpunkt 1: Bewusst schlecht gewählt (Standard)\n",
    "#START_M = 0.3   # Steigung\n",
    "#START_B = 16.0  # Y-Achsenabschnitt\n",
    "START_M = 0   # Steigung\n",
    "START_B = 0  # Y-Achsenabschnitt\n",
    "\n",
    "# Alternative Startpunkte zum Testen (einfach auskommentieren):\n",
    "# START_M, START_B = 0.1, 20.0   # Sehr flache Steigung, hoher Y-Achsenabschnitt\n",
    "# START_M, START_B = 0.8, 5.0    # Steile Steigung, niedriger Y-Achsenabschnitt  \n",
    "# START_M, START_B = 1.0, 0.0    # Sehr steile Steigung, kein Y-Achsenabschnitt\n",
    "# START_M, START_B = 0.0, 15.0   # Horizontale Linie\n",
    "# START_M, START_B = -0.2, 25.0  # Negative Steigung (unphysikalisch!)\n",
    "\n",
    "print(\"=== STARTPUNKT-KONFIGURATION ===\")\n",
    "print(f\"Gewählter Startpunkt: m = {START_M}, b = {START_B}\")\n",
    "\n",
    "# Kompatibilität: Setze auch die alten Variablen\n",
    "m_guess, b_guess = START_M, START_B\n",
    "\n",
    "print(\">>> Startpunkt für alle Visualisierungen und Gradientenabstieg gesetzt!\")\n",
    "print(\">>> Du kannst verschiedene Startpunkte ausprobieren, indem du die Werte oben änderst.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9a8157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die Datenpunkte aus der Vorlesung (exakt wie im Skript)\n",
    "x_data = np.array([10, 20, 30])  # Außentemperatur in °C\n",
    "y_data = np.array([14, 19, 25])  # Energieverbrauch in kWh/h\n",
    "\n",
    "print(\"📋 Unsere Datenpunkte (exakt aus Vorlesung 07):\")\n",
    "print(\"Temperatur (°C) | Energieverbrauch (kWh/h)\")\n",
    "print(\"----------------|------------------------\")\n",
    "for i in range(len(x_data)):\n",
    "    print(f\"      {x_data[i]:2d}        |          {y_data[i]:2d}\")\n",
    "\n",
    "# Analytische Lösung berechnen (wie im Skript)\n",
    "n = len(x_data)\n",
    "sum_x = np.sum(x_data)      # Σx_i = 60\n",
    "sum_y = np.sum(y_data)      # Σy_i = 58  \n",
    "sum_xy = np.sum(x_data * y_data)  # Σx_i*y_i berechnen\n",
    "sum_x2 = np.sum(x_data**2)  # Σx_i² = 1400\n",
    "\n",
    "print(f\"\\n🧮 Berechnungen für Normalgleichungen (wie im Skript):\")\n",
    "print(f\"   n = {n}\")\n",
    "print(f\"   Σx_i = {sum_x}\")\n",
    "print(f\"   Σy_i = {sum_y}\")\n",
    "print(f\"   Σx_i*y_i = {sum_xy}\")\n",
    "print(f\"   Σx_i² = {sum_x2}\")\n",
    "\n",
    "# Normalgleichungen anwenden\n",
    "m_analytical = (n * sum_xy - sum_x * sum_y) / (n * sum_x2 - sum_x**2)\n",
    "b_analytical = (sum_y - m_analytical * sum_x) / n\n",
    "\n",
    "print(f\"\\n🎯 Analytische Lösung (Normalgleichungen):\")\n",
    "print(f\"   m = ({n}×{sum_xy} - {sum_x}×{sum_y}) / ({n}×{sum_x2} - {sum_x}²)\")\n",
    "print(f\"   m = ({n*sum_xy} - {sum_x*sum_y}) / ({n*sum_x2} - {sum_x**2})\")\n",
    "print(f\"   m = {n*sum_xy - sum_x*sum_y} / {n*sum_x2 - sum_x**2} = {m_analytical:.3f}\")\n",
    "print(f\"   b = ({sum_y} - {m_analytical:.3f}×{sum_x}) / {n} = {b_analytical:.3f}\")\n",
    "\n",
    "mse_analytical = np.mean((y_data - (m_analytical * x_data + b_analytical))**2)\n",
    "print(f\"\\n📊 Optimaler MSE: {mse_analytical:.6f}\")\n",
    "\n",
    "# 🔧 KONTROLLE: Berechnung mit Library-Funktionen\n",
    "print(f\"\\n🔧 KONTROLLE mit Standard-Libraries:\")\n",
    "\n",
    "# Methode 1: numpy.polyfit (Polynom-Fitting, Grad 1 = Gerade)\n",
    "polyfit_coeff = np.polyfit(x_data, y_data, deg=1)\n",
    "m_polyfit, b_polyfit = polyfit_coeff[0], polyfit_coeff[1]\n",
    "mse_polyfit = np.mean((y_data - (m_polyfit * x_data + b_polyfit))**2)\n",
    "\n",
    "print(f\"\\n1️⃣ np.polyfit(deg=1):\")\n",
    "print(f\"   m = {m_polyfit:.6f}\")\n",
    "print(f\"   b = {b_polyfit:.6f}\")\n",
    "print(f\"   MSE = {mse_polyfit:.8f}\")\n",
    "\n",
    "# Methode 2: Least Squares mit numpy.linalg.lstsq\n",
    "X_matrix = np.column_stack([x_data, np.ones(len(x_data))])  # [x, 1] Matrix\n",
    "lstsq_result = np.linalg.lstsq(X_matrix, y_data, rcond=None)\n",
    "m_lstsq, b_lstsq = lstsq_result[0][0], lstsq_result[0][1]\n",
    "mse_lstsq = np.mean((y_data - (m_lstsq * x_data + b_lstsq))**2)\n",
    "\n",
    "print(f\"\\n2️⃣ np.linalg.lstsq (Matrix-Lösung):\")\n",
    "print(f\"   m = {m_lstsq:.6f}\")\n",
    "print(f\"   b = {b_lstsq:.6f}\")\n",
    "print(f\"   MSE = {mse_lstsq:.8f}\")\n",
    "\n",
    "# Methode 3: scipy.stats.linregress (falls verfügbar)\n",
    "try:\n",
    "    from scipy.stats import linregress\n",
    "    linreg_result = linregress(x_data, y_data)\n",
    "    m_scipy, b_scipy = linreg_result.slope, linreg_result.intercept\n",
    "    mse_scipy = np.mean((y_data - (m_scipy * x_data + b_scipy))**2)\n",
    "    \n",
    "    print(f\"\\n3️⃣ scipy.stats.linregress:\")\n",
    "    print(f\"   m = {m_scipy:.6f}\")\n",
    "    print(f\"   b = {b_scipy:.6f}\")\n",
    "    print(f\"   MSE = {mse_scipy:.8f}\")\n",
    "    print(f\"   R² = {linreg_result.rvalue**2:.6f}\")\n",
    "    print(f\"   p-value = {linreg_result.pvalue:.8f}\")\n",
    "except ImportError:\n",
    "    print(f\"\\n3️⃣ scipy.stats.linregress: Nicht verfügbar\")\n",
    "    m_scipy, b_scipy = m_analytical, b_analytical  # Fallback\n",
    "\n",
    "# Vergleichstabelle\n",
    "print(f\"\\n📊 VERGLEICHSTABELLE:\")\n",
    "print(f\"{'Methode':<20} {'m (Steigung)':<15} {'b (Achsenabschnitt)':<20} {'MSE':<15}\")\n",
    "print(f\"{'-'*20} {'-'*15} {'-'*20} {'-'*15}\")\n",
    "print(f\"{'Normalgleichungen':<20} {m_analytical:<15.6f} {b_analytical:<20.6f} {mse_analytical:<15.8f}\")\n",
    "print(f\"{'np.polyfit':<20} {m_polyfit:<15.6f} {b_polyfit:<20.6f} {mse_polyfit:<15.8f}\")\n",
    "print(f\"{'np.linalg.lstsq':<20} {m_lstsq:<15.6f} {b_lstsq:<20.6f} {mse_lstsq:<15.8f}\")\n",
    "try:\n",
    "    print(f\"{'scipy.linregress':<20} {m_scipy:<15.6f} {b_scipy:<20.6f} {mse_scipy:<15.8f}\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Differenzen berechnen\n",
    "diff_m_polyfit = abs(m_analytical - m_polyfit)\n",
    "diff_b_polyfit = abs(b_analytical - b_polyfit)\n",
    "diff_m_lstsq = abs(m_analytical - m_lstsq)\n",
    "diff_b_lstsq = abs(b_analytical - b_lstsq)\n",
    "\n",
    "print(f\"\\n✅ ÜBEREINSTIMMUNG:\")\n",
    "print(f\"   np.polyfit:     Δm = {diff_m_polyfit:.10f}, Δb = {diff_b_polyfit:.10f}\")\n",
    "print(f\"   np.linalg.lstsq: Δm = {diff_m_lstsq:.10f}, Δb = {diff_b_lstsq:.10f}\")\n",
    "\n",
    "if diff_m_polyfit < 1e-10 and diff_b_polyfit < 1e-10:\n",
    "    print(f\"🎯 Alle Methoden liefern IDENTISCHE Ergebnisse!\")\n",
    "    print(f\"💡 Das bestätigt unsere Normalgleichungen-Implementierung!\")\n",
    "else:\n",
    "    print(f\"⚠️  Kleine numerische Unterschiede (normal bei Floating-Point)\")\n",
    "\n",
    "# Plotten der Datenpunkte mit verschiedenen Lösungen\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(x_data, y_data, color='red', s=150, zorder=5, edgecolors='black', linewidth=2)\n",
    "plt.xlabel('Außentemperatur (°C)', fontweight='bold')\n",
    "plt.ylabel('Energieverbrauch Kühlung (kWh/h)', fontweight='bold')\n",
    "plt.title('Kühlanlage: Vergleich verschiedener Berechnungsmethoden', fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xlim(0, 40)\n",
    "plt.ylim(5, 35)\n",
    "\n",
    "# Alle Lösungen einzeichnen (sollten identisch sein)\n",
    "x_line = np.linspace(0, 40, 100)\n",
    "y_analytical = m_analytical * x_line + b_analytical\n",
    "y_polyfit = m_polyfit * x_line + b_polyfit\n",
    "y_lstsq = m_lstsq * x_line + b_lstsq\n",
    "\n",
    "plt.plot(x_line, y_analytical, 'b-', linewidth=3, alpha=0.8, \n",
    "         label=f'Normalgleichungen: y = {m_analytical:.3f}x + {b_analytical:.2f}')\n",
    "plt.plot(x_line, y_polyfit, 'g--', linewidth=2, alpha=0.7,\n",
    "         label=f'np.polyfit: y = {m_polyfit:.3f}x + {b_polyfit:.2f}')\n",
    "plt.plot(x_line, y_lstsq, 'r:', linewidth=2, alpha=0.7,\n",
    "         label=f'np.linalg.lstsq: y = {m_lstsq:.3f}x + {b_lstsq:.2f}')\n",
    "\n",
    "# Punkte beschriften\n",
    "for i, (x, y) in enumerate(zip(x_data, y_data)):\n",
    "    plt.annotate(f'({x}°C, {y} kWh/h)', (x, y), xytext=(5, 5), textcoords='offset points', \n",
    "                fontweight='bold', fontsize=10, bbox=dict(boxstyle='round,pad=0.2', facecolor='yellow', alpha=0.7))\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n🎯 Frage: Kann Gradientenabstieg die gleiche Lösung finden?\")\n",
    "print(\"💡 Erwartung: Klare positive Steigung (mehr Kühlenergie bei höherer Temperatur)\")\n",
    "print(\"🔮 Anwendung: Energieplanung für verschiedene Wetterbedingungen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d454e49",
   "metadata": {},
   "source": [
    "## 🧮 MSE-Funktion definieren\n",
    "\n",
    "**MSE (Mean Squared Error)** = Mittlerer quadrierter Fehler\n",
    "\n",
    "$$\\text{MSE}(m,b) = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - (mx_i + b))^2$$\n",
    "\n",
    "**Das ist exakt die Kostenfunktion aus der Vorlesung!**\n",
    "\n",
    "Für unsere drei Punkte (10,14), (20,19), (30,25):\n",
    "- **Normalgleichungen**: Finden das Minimum durch $\\frac{\\partial \\text{MSE}}{\\partial m} = 0$ und $\\frac{\\partial \\text{MSE}}{\\partial b} = 0$\n",
    "- **Gradientenabstieg**: Folgt dem Gradienten iterativ bergab zum Minimum\n",
    "\n",
    "**Beide Methoden sollten zum gleichen Ergebnis führen!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7bc16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mse(m, b, x_data, y_data):\n",
    "    \"\"\"\n",
    "    Berechnet den Mean Squared Error für gegebene Parameter m und b\n",
    "    \"\"\"\n",
    "    # Vorhersagen: y_hat = mx + b\n",
    "    y_predicted = m * x_data + b\n",
    "    \n",
    "    # Residuen: Differenz zwischen echten und vorhergesagten Werten\n",
    "    residuals = y_data - y_predicted\n",
    "    \n",
    "    # MSE: Mittlerer quadrierter Fehler\n",
    "    mse = np.mean(residuals**2)\n",
    "    \n",
    "    return mse\n",
    "\n",
    "# Test mit der analytischen Lösung (Kontrolle)\n",
    "mse_check = calculate_mse(m_analytical, b_analytical, x_data, y_data)\n",
    "print(f\"🔍 Kontrolle - MSE der analytischen Lösung: {mse_check:.6f}\")\n",
    "print(f\"📋 Übereinstimmung: {abs(mse_check - mse_analytical) < 1e-10}\")\n",
    "\n",
    "# Test: Verwende den konfigurierten Startpunkt  \n",
    "# (m_guess und b_guess wurden bereits in der Startpunkt-Konfiguration gesetzt)\n",
    "mse_guess = calculate_mse(START_M, START_B, x_data, y_data)\n",
    "\n",
    "print(f\"\\n🤔 Konfigurierter Startpunkt: m = {START_M}, b = {START_B}\")\n",
    "print(f\"📊 MSE = {mse_guess:.3f}\")\n",
    "\n",
    "# Berechnung per Hand für unsere Schätzung (Demonstration)\n",
    "print(\"\\n✋ Per Hand gerechnet (zur Kontrolle):\")\n",
    "total_squared_error = 0\n",
    "for i, (x, y) in enumerate(zip(x_data, y_data)):\n",
    "    y_pred = START_M * x + START_B\n",
    "    residual = y - y_pred\n",
    "    squared_residual = residual**2\n",
    "    total_squared_error += squared_residual\n",
    "    print(f\"Punkt {i+1}: ({x}°C, {y} kWh/h) → Vorhersage {y_pred:.1f} → Residuum {residual:.1f} → r² = {squared_residual:.3f}\")\n",
    "\n",
    "manual_mse = total_squared_error / len(x_data)\n",
    "print(f\"\\n🧮 MSE per Hand: {manual_mse:.3f}\")\n",
    "print(f\"🖥️  MSE per Code: {mse_guess:.3f}\")\n",
    "print(\"✅ Stimmen überein!\")\n",
    "\n",
    "print(f\"\\n💭 Die Frage:\")\n",
    "print(f\"   • Wie kann der Computer automatisch von MSE={mse_guess:.3f} zu MSE={mse_analytical:.6f} kommen?\")\n",
    "print(f\"   • Antwort: Gradientenabstieg!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bb52de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_gradients_correct(m, b, x_data, y_data):\n",
    "    \"\"\"\n",
    "    Berechnet die Gradienten der MSE-Funktion korrekt für m und b.\n",
    "    \n",
    "    Aus der Vorlesung: MSE(m,b) = 1/n * Σ(y_i - (mx_i + b))²\n",
    "    \n",
    "    Partielle Ableitungen:\n",
    "    ∂MSE/∂m = -2/n * Σ[x_i * (y_i - (mx_i + b))]\n",
    "    ∂MSE/∂b = -2/n * Σ[y_i - (mx_i + b)]\n",
    "    \"\"\"\n",
    "    n = len(x_data)\n",
    "    y_pred = m * x_data + b\n",
    "    residuals = y_data - y_pred\n",
    "    \n",
    "    # Gradient nach m: -2/n * Summe[x_i * (y_i - (mx_i + b))]\n",
    "    grad_m = -2 * np.sum(x_data * residuals) / n\n",
    "    # Gradient nach b: -2/n * Summe[y_i - (mx_i + b)]\n",
    "    grad_b = -2 * np.sum(residuals) / n\n",
    "    \n",
    "    return grad_m, grad_b\n",
    "\n",
    "# Test der Gradienten am optimalen Punkt (sollten ~0 sein)\n",
    "grad_m_opt, grad_b_opt = calculate_gradients_correct(m_analytical, b_analytical, x_data, y_data)\n",
    "print(f\"🎯 Gradienten am Optimum (sollten ≈ 0 sein):\")\n",
    "print(f\"   ∂MSE/∂m = {grad_m_opt:.8f}\")\n",
    "print(f\"   ∂MSE/∂b = {grad_b_opt:.8f}\")\n",
    "print(f\"✅ Praktisch null - Normalgleichungen haben das Minimum gefunden!\")\n",
    "\n",
    "# Test der Gradienten am schlechten Startpunkt\n",
    "grad_m_start, grad_b_start = calculate_gradients_correct(START_M, START_B, x_data, y_data)\n",
    "print(f\"\\n🤔 Gradienten am Startpunkt m={START_M}, b={START_B}:\")\n",
    "print(f\"   ∂MSE/∂m = {grad_m_start:.4f}\")\n",
    "print(f\"   ∂MSE/∂b = {grad_b_start:.4f}\")\n",
    "print(f\"💡 Diese zeigen die Richtung des steilsten Anstiegs!\")\n",
    "print(f\"🏔️  Für Abstieg gehen wir in die entgegengesetzte Richtung!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b675e4",
   "metadata": {},
   "source": [
    "## 🗺️ Die MSE-Landschaft erstellen\n",
    "\n",
    "Jetzt kommt das Spannende! Wir berechnen MSE für viele verschiedene Kombinationen von **m** (Steigung) und **b** (Achsenabschnitt) und visualisieren das als \"Gebirge\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18dbeabb",
   "metadata": {},
   "source": [
    "## 🌄 Interaktive 3D-MSE-Landschaft\n",
    "\n",
    "**Jetzt wird's spannend!** Wir erstellen eine **interaktive 3D-Visualisierung** der MSE-Landschaft, die du mit der Maus drehen und zoomen kannst!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fcf44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative für interaktive 3D-Plots - BOKEH ist besser für Jupyter!\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Bokeh als beste Alternative für echte Interaktivität in Jupyter\n",
    "try:\n",
    "    from bokeh.plotting import figure, show, output_notebook\n",
    "    from bokeh.models import HoverTool, ColorBar, LinearColorMapper\n",
    "    from bokeh.palettes import Plasma256\n",
    "    from bokeh.layouts import row, column\n",
    "    from bokeh.models import ColumnDataSource\n",
    "    import bokeh.io\n",
    "    \n",
    "    # Bokeh für Jupyter Notebook aktivieren\n",
    "    output_notebook()\n",
    "    BOKEH_AVAILABLE = True\n",
    "    print(\">>> Bokeh gefunden und für Jupyter konfiguriert!\")\n",
    "    print(\"*** Bokeh funktioniert deutlich besser als Plotly in Notebooks!\")\n",
    "    \n",
    "except ImportError:\n",
    "    BOKEH_AVAILABLE = False\n",
    "    print(\">>> Bokeh nicht verfügbar - verwende Matplotlib\")\n",
    "    print(\"!!! Installiere Bokeh für echte Interaktivität: pip install bokeh\")\n",
    "except Exception as e:\n",
    "    BOKEH_AVAILABLE = False\n",
    "    print(f\"!!! Bokeh-Konfigurationsproblem: {e}\")\n",
    "    print(\">>> Verwende Matplotlib als Fallback\")\n",
    "\n",
    "print(\">>> 3D-Visualisierung wird erstellt...\")\n",
    "\n",
    "# Parameter-Bereiche für 3D-Plot definieren (größerer Bereich für Startpunkt)\n",
    "m_range_3d = np.linspace(-0.1, 1.2, 60)   # Erweitert um Startpunkt m=0.3 zu erfassen\n",
    "b_range_3d = np.linspace(0, 25, 60)       # Erweitert um Startpunkt b=16.0 zu erfassen\n",
    "\n",
    "# Gitter erstellen\n",
    "M_3d, B_3d = np.meshgrid(m_range_3d, b_range_3d)\n",
    "\n",
    "# MSE für alle Kombinationen berechnen\n",
    "MSE_3d = np.zeros_like(M_3d)\n",
    "\n",
    "print(f\"\\n>>> Berechne MSE-Landschaft (höhere Auflösung: {len(m_range_3d)}×{len(b_range_3d)})...\")\n",
    "for i in range(M_3d.shape[0]):\n",
    "    for j in range(M_3d.shape[1]):\n",
    "        MSE_3d[i, j] = calculate_mse(M_3d[i, j], B_3d[i, j], x_data, y_data)\n",
    "\n",
    "print(\"*** MSE-Landschaft berechnet!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efb581f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🌋 INTERAKTIVE MSE-LANDSCHAFT (Bokeh ist die beste Lösung für Jupyter!)\n",
    "# =========================================================================\n",
    "\n",
    "if BOKEH_AVAILABLE:\n",
    "    print(\">>> Erstelle interaktive Bokeh-Visualisierung...\")\n",
    "    \n",
    "    try:\n",
    "        # Daten für Bokeh vorbereiten (2D Heatmap + Konturen)\n",
    "        # Bokeh macht zwar keine echten 3D-Plots, aber sehr schöne interaktive 2D-Plots\n",
    "        \n",
    "        # 1. INTERAKTIVE HEATMAP der MSE-Landschaft\n",
    "        # Flatten der Daten für Bokeh\n",
    "        m_flat = M_3d.flatten()\n",
    "        b_flat = B_3d.flatten()  \n",
    "        mse_flat = MSE_3d.flatten()\n",
    "        \n",
    "        # ColumnDataSource für Bokeh\n",
    "        source = ColumnDataSource(data=dict(\n",
    "            m=m_flat,\n",
    "            b=b_flat,\n",
    "            mse=mse_flat\n",
    "        ))\n",
    "        \n",
    "        # Color mapper für MSE-Werte\n",
    "        color_mapper = LinearColorMapper(palette=Plasma256, \n",
    "                                       low=mse_flat.min(), \n",
    "                                       high=mse_flat.max())\n",
    "        \n",
    "        # Hauptplot erstellen\n",
    "        p = figure(width=600, height=500,\n",
    "                  title=\"Interaktive MSE-Energielandschaft\",\n",
    "                  x_axis_label=\"Steigung m\",\n",
    "                  y_axis_label=\"Y-Achsenabschnitt b\",\n",
    "                  toolbar_location=\"above\")\n",
    "        \n",
    "        # Heatmap/Scatter plot\n",
    "        scatter = p.scatter('m', 'b', size=8, source=source,\n",
    "                          color={'field': 'mse', 'transform': color_mapper},\n",
    "                          alpha=0.8)\n",
    "        \n",
    "        # Optimum markieren\n",
    "        p.scatter([m_analytical], [b_analytical], size=20, color='red', \n",
    "                 marker='star', line_color='white', line_width=2, \n",
    "                 legend_label=f'* Optimum ({m_analytical:.3f}, {b_analytical:.3f})')\n",
    "        \n",
    "        # Startpunkt markieren  \n",
    "        p.scatter([START_M], [START_B], size=15, color='lime', marker='circle',\n",
    "                 line_color='black', line_width=2,\n",
    "                 legend_label=f'> Start ({START_M}, {START_B})')\n",
    "        \n",
    "        # Hover-Tool für Interaktivität\n",
    "        hover = HoverTool(tooltips=[\n",
    "            (\"Steigung m\", \"@m{0.000}\"),\n",
    "            (\"Y-Achsenabschnitt b\", \"@b{0.000}\"), \n",
    "            (\"MSE\", \"@mse{0.000000}\")\n",
    "        ])\n",
    "        p.add_tools(hover)\n",
    "        \n",
    "        # Color bar hinzufügen\n",
    "        color_bar = ColorBar(color_mapper=color_mapper, width=8, location=(0,0))\n",
    "        p.add_layout(color_bar, 'right')\n",
    "        \n",
    "        # 2. ZUSÄTZLICHER QUERSCHNITT-PLOT\n",
    "        mse_slice = [calculate_mse(m, b_analytical, x_data, y_data) for m in m_range_3d]\n",
    "        \n",
    "        p2 = figure(width=600, height=300,\n",
    "                   title=f\"MSE-Querschnitt bei b={b_analytical:.2f}\",\n",
    "                   x_axis_label=\"Steigung m\",\n",
    "                   y_axis_label=\"MSE\")\n",
    "        \n",
    "        p2.line(m_range_3d, mse_slice, line_width=3, color='purple', \n",
    "               legend_label='MSE(m)')\n",
    "        p2.line([m_analytical, m_analytical], [0, max(mse_slice)], \n",
    "               line_width=2, color='red', line_dash='dashed',\n",
    "               legend_label=f'Optimum m={m_analytical:.3f}')\n",
    "        p2.line([START_M, START_M], [0, max(mse_slice)],\n",
    "               line_width=2, color='green', line_dash='dashed', \n",
    "               legend_label=f'Start m={START_M}')\n",
    "        \n",
    "        # Beide Plots anzeigen\n",
    "        layout = column(p, p2)\n",
    "        show(layout)\n",
    "        \n",
    "        print(\"*** INTERAKTIVE BOKEH-VISUALISIERUNG AKTIV!\")\n",
    "        print(\"=\" * 60)\n",
    "        print(\">>> INTERAKTIVE FEATURES:\")\n",
    "        print(\"   • Hover über Punkte → MSE-Werte anzeigen\")\n",
    "        print(\"   • Pan-Tool → Verschieben der Ansicht\")\n",
    "        print(\"   • Zoom-Tool → Hinein-/Herauszoomen\")\n",
    "        print(\"   • Reset-Tool → Zurück zur ursprünglichen Ansicht\")\n",
    "        print()\n",
    "        print(\">>> Was du siehst:\")\n",
    "        print(\"   • Roter Stern = Optimum (Tiefster MSE-Wert)\")\n",
    "        print(\"   • Grüner Kreis = Startschätzung\")\n",
    "        print(\"   • Farbverlauf = MSE-Landschaft (dunkel = niedrig, hell = hoch)\")\n",
    "        print(\"   • Unterer Plot = Querschnitt durch die Landschaft\")\n",
    "        print(\"   • >>> Gradientenabstieg würde vom grünen zum roten Punkt laufen!\")\n",
    "        \n",
    "    except Exception as bokeh_error:\n",
    "        print(f\"!!! Bokeh-Fehler: {bokeh_error}\")\n",
    "        print(\">>> Verwende Matplotlib als Fallback...\")\n",
    "        BOKEH_AVAILABLE = False\n",
    "\n",
    "# HAUPTVISUALISIERUNG: 3D MSE-LANDSCHAFT\n",
    "print(\"*** Erstelle große 3D-MSE-Landschaft mit Startpunkt...\")\n",
    "\n",
    "# Große 3D-Visualisierung mit Fokus auf 3D-Plot\n",
    "fig = plt.figure(figsize=(20, 8))\n",
    "\n",
    "# 3D Surface Plot (größer und zentraler)\n",
    "ax1 = fig.add_subplot(121, projection='3d')\n",
    "surf = ax1.plot_surface(M_3d, B_3d, MSE_3d, \n",
    "                      cmap='viridis', alpha=0.8, linewidth=0, antialiased=True,\n",
    "                      rstride=1, cstride=1)\n",
    "\n",
    "# Optimum und Startpunkt markieren\n",
    "start_mse = calculate_mse(START_M, START_B, x_data, y_data)\n",
    "ax1.scatter([m_analytical], [b_analytical], [mse_analytical], \n",
    "           color='red', s=300, alpha=1.0, label='* Optimum', edgecolors='white', linewidth=2)\n",
    "ax1.scatter([START_M], [START_B], [start_mse], \n",
    "           color='lime', s=250, alpha=1.0, label='> Start', edgecolors='black', linewidth=2)\n",
    "\n",
    "# Schönere Achsenbeschriftung\n",
    "ax1.set_xlabel('Steigung m', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel('Y-Achsenabschnitt b', fontsize=12, fontweight='bold')\n",
    "ax1.set_zlabel('MSE', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('3D MSE-Landschaft (Erweitert)', fontsize=14, fontweight='bold')\n",
    "ax1.legend(fontsize=11)\n",
    "\n",
    "# Colorbar für 3D-Plot\n",
    "fig.colorbar(surf, ax=ax1, shrink=0.5, aspect=30)\n",
    "\n",
    "# Bessere Ansicht einstellen (um 90° gedreht für bessere Perspektive)\n",
    "ax1.view_init(elev=20, azim=135)\n",
    "\n",
    "# Konturkarte mit mehr Details\n",
    "ax2 = fig.add_subplot(122)\n",
    "contour = ax2.contourf(M_3d, B_3d, MSE_3d, levels=25, cmap='viridis', alpha=0.8)\n",
    "contour_lines = ax2.contour(M_3d, B_3d, MSE_3d, levels=15, colors='white', alpha=0.6, linewidths=0.8)\n",
    "ax2.clabel(contour_lines, inline=True, fontsize=8, fmt='%.2f')\n",
    "\n",
    "# Punkte markieren\n",
    "ax2.plot(m_analytical, b_analytical, 'r*', markersize=20, label='* Optimum', \n",
    "         markeredgecolor='white', markeredgewidth=2)\n",
    "ax2.plot(START_M, START_B, 'o', color='lime', markersize=15, label='> Start',\n",
    "         markeredgecolor='black', markeredgewidth=2)\n",
    "\n",
    "ax2.set_xlabel('Steigung m', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('Y-Achsenabschnitt b', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('MSE-Konturen (von oben)', fontsize=14, fontweight='bold')\n",
    "ax2.legend(fontsize=11)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Achsenbereiche erweitern für bessere Übersicht\n",
    "ax2.set_xlim(m_range_3d.min() - 0.05, m_range_3d.max() + 0.05)\n",
    "ax2.set_ylim(b_range_3d.min() - 1, b_range_3d.max() + 1)\n",
    "\n",
    "# Colorbar für Konturkarte\n",
    "plt.colorbar(contour, ax=ax2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"*** GROßE 3D MSE-LANDSCHAFT ERSTELLT!\")\n",
    "print(\"=\" * 60)\n",
    "print(\">>> Was du siehst:\")\n",
    "print(\"   • Links: 3D-Oberfläche der MSE-Landschaft (drehbar im interaktiven Modus)\")\n",
    "print(\"   • Rechts: Konturkarte von oben (Höhenlinien mit MSE-Werten)\")\n",
    "print()\n",
    "print(\"!!! INTERPRETATION:\")\n",
    "print(f\"   • Roter Stern = Optimum bei m={m_analytical:.3f}, b={b_analytical:.3f}\")\n",
    "print(f\"   • Grüner Kreis = Startpunkt bei m={START_M}, b={START_B}\")\n",
    "print(f\"   • MSE-Bereich: {MSE_3d.min():.3f} bis {MSE_3d.max():.1f}\")\n",
    "print(\"   • Tiefe Täler = Niedrige MSE (besser)\")\n",
    "print(\"   • Hohe Berge = Hohe MSE (schlechter)\")\n",
    "print()\n",
    "print(\">>> Gradientenabstieg würde vom grünen Punkt bergab zum roten Stern laufen!\")\n",
    "\n",
    "print(f\"\\n!!! EMPFEHLUNG für echte Interaktivität:\")\n",
    "print(f\"   pip install bokeh\")  \n",
    "print(f\"   Bokeh funktioniert viel besser als Plotly in Jupyter Notebooks!\")\n",
    "print(f\"   Mit Bokeh bekommst du echte Mouse-Over-Effekte und Zoom-Funktionen!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda96b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🏔️ ALTERNATIVE: NOCH GRÖßERE 3D-LANDSCHAFT\n",
    "# =============================================\n",
    "\n",
    "# Für eine noch bessere Übersicht eine extra große Visualisierung\n",
    "print(\"*** Erstelle maximale 3D-MSE-Landschaft...\")\n",
    "\n",
    "fig = plt.figure(figsize=(16, 12))\n",
    "\n",
    "# Großer 3D-Plot\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Surface mit noch mehr Details\n",
    "surf = ax.plot_surface(M_3d, B_3d, MSE_3d, \n",
    "                      cmap='viridis', alpha=0.9, linewidth=0, antialiased=True,\n",
    "                      rstride=1, cstride=1, shade=True)\n",
    "\n",
    "# Optimum und Startpunkt extra groß markieren\n",
    "start_mse = calculate_mse(START_M, START_B, x_data, y_data)\n",
    "ax.scatter([m_analytical], [b_analytical], [mse_analytical], \n",
    "          color='red', s=400, alpha=1.0, label='* Optimum', \n",
    "          edgecolors='white', linewidth=3, depthshade=False)\n",
    "ax.scatter([START_M], [START_B], [start_mse], \n",
    "          color='lime', s=350, alpha=1.0, label='> Start', \n",
    "          edgecolors='black', linewidth=3, depthshade=False)\n",
    "\n",
    "# Schöne Achsenbeschriftung\n",
    "ax.set_xlabel('Steigung m', fontsize=14, fontweight='bold', labelpad=10)\n",
    "ax.set_ylabel('Y-Achsenabschnitt b', fontsize=14, fontweight='bold', labelpad=10)\n",
    "ax.set_zlabel('MSE', fontsize=14, fontweight='bold', labelpad=10)\n",
    "ax.set_title('3D MSE-Landschaft - Komplette Übersicht', fontsize=16, fontweight='bold', pad=20)\n",
    "\n",
    "# Legende größer\n",
    "ax.legend(fontsize=12, loc='upper right')\n",
    "\n",
    "# Colorbar\n",
    "cbar = fig.colorbar(surf, ax=ax, shrink=0.6, aspect=40, pad=0.1)\n",
    "cbar.set_label('MSE-Wert', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Optimale 3D-Ansicht (um 90° gedreht für bessere Perspektive)\n",
    "ax.view_init(elev=25, azim=135)\n",
    "\n",
    "# Gitter für bessere Orientierung\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"*** MAXIMALE 3D-VISUALISIERUNG FERTIG!\")\n",
    "print(\"=\" * 60)\n",
    "print(\">>> Parameter-Bereiche:\")\n",
    "print(f\"   • Steigung m: {m_range_3d.min():.1f} bis {m_range_3d.max():.1f}\")\n",
    "print(f\"   • Y-Achsenabschnitt b: {b_range_3d.min():.1f} bis {b_range_3d.max():.1f}\")\n",
    "print(f\"   • MSE-Bereich: {MSE_3d.min():.3f} bis {MSE_3d.max():.1f}\")\n",
    "print()\n",
    "print(\">>> Wichtige Punkte:\")\n",
    "print(f\"   • Optimum: m={m_analytical:.3f}, b={b_analytical:.3f}, MSE={mse_analytical:.6f}\")\n",
    "print(f\"   • Start: m={START_M}, b={START_B}, MSE={start_mse:.3f}\")\n",
    "print(f\"   • Verbesserung: {start_mse/mse_analytical:.1f}x niedriger MSE beim Optimum!\")\n",
    "print()\n",
    "print(\"!!! Diese Landschaft zeigt perfekt, wie Gradientenabstieg funktioniert:\")\n",
    "print(\"   1. Start auf dem hohen 'Berg' (grüner Punkt)\")\n",
    "print(\"   2. Folge dem steilsten Abstieg (Gradientenrichtung)\")\n",
    "print(\"   3. Erreiche das tiefste Tal (rotes Optimum)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3590e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔄 Zurück zu statischen Plots für den Rest des Notebooks\n",
    "%matplotlib inline\n",
    "\n",
    "print(\">>> Matplotlib auf statische Plots zurückgesetzt für weitere Visualisierungen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbb5895",
   "metadata": {},
   "source": [
    "## 🚶‍♂️ Gradientenabstieg Schritt für Schritt\n",
    "\n",
    "Jetzt simulieren wir, wie der Computer den Weg bergab findet! Wir starten von unserer Schätzung aus und folgen dem steilsten Abstieg.\n",
    "\n",
    "⚠️ **Wichtig**: Die **Lernrate α** ist kritisch! Zu groß → Divergenz, zu klein → sehr langsam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636e27cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Für eine stabile Demonstration fügen wir diskret einige zusätzliche Punkte hinzu\n",
    "x_demo = np.array([8, 10, 12, 15, 18, 20, 22, 25, 27, 30, 32, 35])\n",
    "y_demo = np.array([12.5, 14, 15.2, 16.8, 18.1, 19, 20.5, 22.3, 23.8, 25, 26.1, 28.2])\n",
    "\n",
    "# WICHTIG: Analytische Lösung für die erweiterten Punkte berechnen\n",
    "n_demo = len(x_demo)\n",
    "sum_x_demo = np.sum(x_demo)\n",
    "sum_y_demo = np.sum(y_demo)\n",
    "sum_xy_demo = np.sum(x_demo * y_demo)\n",
    "sum_x2_demo = np.sum(x_demo**2)\n",
    "\n",
    "m_demo_optimal = (n_demo * sum_xy_demo - sum_x_demo * sum_y_demo) / (n_demo * sum_x2_demo - sum_x_demo**2)\n",
    "b_demo_optimal = (sum_y_demo - m_demo_optimal * sum_x_demo) / n_demo\n",
    "mse_demo_optimal = calculate_mse(m_demo_optimal, b_demo_optimal, x_demo, y_demo)\n",
    "\n",
    "print(\"📊 ANALYTISCHE LÖSUNG für die erweiterten Punkte:\")\n",
    "print(f\"   Anzahl Punkte: {n_demo}\")\n",
    "print(f\"   Optimale Steigung: m = {m_demo_optimal:.6f}\")\n",
    "print(f\"   Optimaler Y-Achsenabschnitt: b = {b_demo_optimal:.6f}\")\n",
    "print(f\"   Optimaler MSE: {mse_demo_optimal:.8f}\")\n",
    "\n",
    "print(f\"\\n🔍 Vergleich Original vs. Erweitert:\")\n",
    "print(f\"   Original (3 Punkte): m = {m_analytical:.6f}, b = {b_analytical:.6f}\")\n",
    "print(f\"   Erweitert ({n_demo} Punkte): m = {m_demo_optimal:.6f}, b = {b_demo_optimal:.6f}\")\n",
    "\n",
    "def gradient_descent_simple(x_data, y_data, start_m=0.3, start_b=16.0, learning_rate=0.01, max_iterations=200):\n",
    "    \"\"\"Einfacher Gradientenabstieg für Demonstrationszwecke\"\"\"\n",
    "    m, b = start_m, start_b\n",
    "    history = {'m': [m], 'b': [b], 'mse': []}\n",
    "    \n",
    "    for i in range(max_iterations):\n",
    "        # MSE berechnen\n",
    "        mse = calculate_mse(m, b, x_data, y_data)\n",
    "        history['mse'].append(mse)\n",
    "        \n",
    "        # Gradienten berechnen\n",
    "        grad_m, grad_b = calculate_gradients_correct(m, b, x_data, y_data)\n",
    "        \n",
    "        # Parameter aktualisieren\n",
    "        m = m - learning_rate * grad_m\n",
    "        b = b - learning_rate * grad_b\n",
    "        \n",
    "        # Historie speichern\n",
    "        history['m'].append(m)\n",
    "        history['b'].append(b)\n",
    "        \n",
    "        # Fortschritt anzeigen (alle 1000 Iterationen)\n",
    "        if (i + 1) % 1000 == 0:\n",
    "            print(f\"Iteration {i+1:5d}: m = {m:.6f}, b = {b:.6f}, MSE = {mse:.8f}\")\n",
    "    \n",
    "    # Finale MSE\n",
    "    final_mse = calculate_mse(m, b, x_data, y_data)\n",
    "    history['mse'].append(final_mse)\n",
    "    \n",
    "    return history\n",
    "\n",
    "print(f\"\\n🚀 Gradientenabstieg ist bereit!\")\n",
    "print(f\"📊 Ziel: m = {m_demo_optimal:.6f}, b = {b_demo_optimal:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cbcb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INFO: Startpunkt-Konfiguration wurde bereits früher im Notebook definiert\n",
    "# Die Variablen START_M und START_B sind bereits gesetzt und werden hier nur referenziert\n",
    "\n",
    "print(\"=== STARTPUNKT FÜR GRADIENTENABSTIEG ===\")\n",
    "print(f\"Verwendeter Startpunkt: m = {START_M}, b = {START_B}\")\n",
    "\n",
    "# Erweiterte Validierung für den Gradientenabstieg\n",
    "if 'x_demo' in locals():\n",
    "    start_mse_value = calculate_mse(START_M, START_B, x_demo, y_demo)\n",
    "    print(f\"MSE am Startpunkt: {start_mse_value:.4f}\")\n",
    "    \n",
    "    if 'mse_demo_optimal' in locals():\n",
    "        print(f\"Ziel-MSE (optimal): {mse_demo_optimal:.6f}\")\n",
    "        print(f\"Verbesserungspotential: {start_mse_value/mse_demo_optimal:.1f}x\")\n",
    "\n",
    "# Validierung des Startpunkts\n",
    "if START_M < -1.0 or START_M > 2.0:\n",
    "    print(\"!!! WARNUNG: Steigung außerhalb des sinnvollen Bereichs (-1.0 bis 2.0)\")\n",
    "if START_B < -10.0 or START_B > 40.0:\n",
    "    print(\"!!! WARNUNG: Y-Achsenabschnitt außerhalb des sinnvollen Bereichs (-10 bis 40)\")\n",
    "\n",
    "print(f\"\\n>>> Bereit für Gradientenabstieg von ({START_M}, {START_B}) zum Optimum!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856603ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🧪 EXPERIMENTIER-BEREICH: Ändere die Lernrate hier!\n",
    "# ===============================================================\n",
    "\n",
    "LEARNING_RATE = 0.0015  # ⚠️ OPTIMAL GEFUNDEN! \n",
    "# Funktioniert: 0.0015 mit 20000 Iterationen\n",
    "# Andere Werte zum Testen: 0.001, 0.002, 0.005\n",
    "\n",
    "print(\"🎯 Starte Gradientenabstieg...\")\n",
    "print(f\"📍 Startpunkt: m = {START_M}, b = {START_B}\")\n",
    "print(f\"🎯 ZIEL (korrekt für erweiterte Daten): m = {m_demo_optimal:.6f}, b = {b_demo_optimal:.6f}\")\n",
    "print(f\"🔧 Lernrate: {LEARNING_RATE}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Gradientenabstieg ausführen\n",
    "history = gradient_descent_simple(x_demo, y_demo, start_m=START_M, start_b=START_B, \n",
    "                                learning_rate=LEARNING_RATE, max_iterations=20000)\n",
    "\n",
    "# Finale Ergebnisse\n",
    "final_m = history['m'][-1]\n",
    "final_b = history['b'][-1]\n",
    "final_mse = history['mse'][-1]\n",
    "\n",
    "print(\"-\" * 70)\n",
    "print(\"🎉 FERTIG!\")\n",
    "print(f\"📊 Ergebnis: m = {final_m:.6f}, b = {final_b:.6f}\")\n",
    "print(f\"📈 Finale MSE: {final_mse:.8f}\")\n",
    "\n",
    "# Vergleich mit analytischer Lösung (KORREKT für erweiterte Daten)\n",
    "print(f\"✅ Optimal MSE: {mse_demo_optimal:.8f}\")\n",
    "print(f\"📊 MSE-Differenz: {abs(final_mse - mse_demo_optimal):.8f}\")\n",
    "print(f\"📊 Parameter-Differenz: Δm = {abs(final_m - m_demo_optimal):.6f}, Δb = {abs(final_b - b_demo_optimal):.6f}\")\n",
    "\n",
    "if abs(final_mse - mse_demo_optimal) < 0.001:\n",
    "    print(\"🎉 PERFEKT! Gradientenabstieg hat das Optimum erreicht!\")\n",
    "elif abs(final_mse - mse_demo_optimal) < 0.01:\n",
    "    print(\"✅ SEHR GUT! Gradientenabstieg ist sehr nah am Optimum!\")\n",
    "elif abs(final_mse - mse_demo_optimal) < 0.1:\n",
    "    print(\"👍 GUT! Gradientenabstieg konvergiert zum Optimum!\")\n",
    "else:\n",
    "    print(\"⚠️ ACHTUNG! Möglicherweise divergiert oder Lernrate zu groß/klein!\")\n",
    "    \n",
    "# Konvergenz-Check\n",
    "if len(history['mse']) > 10:\n",
    "    recent_change = abs(history['mse'][-1] - history['mse'][-10])\n",
    "    if recent_change < 1e-6:\n",
    "        print(\"✅ Konvergiert stabil\")\n",
    "    elif recent_change > 1000:\n",
    "        print(\"🚨 DIVERGENZ! Lernrate zu groß!\")\n",
    "    else:\n",
    "        print(\"📈 Noch am konvergieren...\")\n",
    "\n",
    "print(f\"\\n💡 TIPP: Experimentiere mit verschiedenen Lernraten!\")\n",
    "print(f\"   • Zu groß (z.B. 0.1): Divergenz oder Oszillation\")\n",
    "print(f\"   • Zu klein (z.B. 0.0001): Sehr langsame Konvergenz\")\n",
    "print(f\"   • Optimal (z.B. 0.01): Schnelle, stabile Konvergenz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdad4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisierung der Konvergenz\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Plot 1: MSE-Verlauf\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(history['mse'], 'purple', linewidth=2, marker='o', markersize=3)\n",
    "plt.axhline(y=mse_demo_optimal, color='red', linestyle='--', alpha=0.7, \n",
    "           label=f'Optimum: {mse_demo_optimal:.6f}')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('MSE')\n",
    "plt.title('MSE-Minimierung')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.yscale('log')  # Log-Skala für bessere Sichtbarkeit\n",
    "\n",
    "# Plot 2: Parameter-Entwicklung m\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(history['m'], 'blue', linewidth=2, marker='o', markersize=3, label='Steigung m')\n",
    "plt.axhline(y=m_demo_optimal, color='red', linestyle='--', alpha=0.7, \n",
    "           label=f'Optimum: {m_demo_optimal:.4f}')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Steigung m')\n",
    "plt.title('Konvergenz der Steigung')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Parameter-Entwicklung b\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(history['b'], 'green', linewidth=2, marker='o', markersize=3, label='Y-Achsenabschnitt b')\n",
    "plt.axhline(y=b_demo_optimal, color='red', linestyle='--', alpha=0.7, \n",
    "           label=f'Optimum: {b_demo_optimal:.4f}')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Y-Achsenabschnitt b')\n",
    "plt.title('Konvergenz des Y-Achsenabschnitts')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"📊 Die Plots zeigen die schrittweise Verbesserung der Parameter!\")\n",
    "print(\"💡 MSE ist auf logarithmischer Skala für bessere Sichtbarkeit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2211c6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finale Vergleichstabelle und Visualisierung\n",
    "comparison_data = {\n",
    "    'Methode': ['Startschätzung', 'Gradientenabstieg', 'Analytisch (optimal)'],\n",
    "    'Steigung m': [START_M, final_m, m_demo_optimal],\n",
    "    'Achsenabschnitt b': [START_B, final_b, b_demo_optimal],\n",
    "    'MSE': [calculate_mse(START_M, START_B, x_demo, y_demo), final_mse, mse_demo_optimal]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(comparison_data)\n",
    "print(\"ERGEBNISVERGLEICH (für erweiterte Daten):\")\n",
    "print(\"=\" * 70)\n",
    "print(df.to_string(index=False, float_format='%.6f'))\n",
    "\n",
    "# Visualisierung der drei Geraden\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Datenpunkte\n",
    "plt.scatter(x_demo, y_demo, color='red', s=100, zorder=5, edgecolors='black', \n",
    "           linewidth=1, label='Demonstrationsdaten', alpha=0.8)\n",
    "\n",
    "# Geraden\n",
    "x_line = np.linspace(5, 40, 100)\n",
    "y_start = START_M * x_line + START_B\n",
    "y_gradient = final_m * x_line + final_b\n",
    "y_optimal = m_demo_optimal * x_line + b_demo_optimal\n",
    "\n",
    "plt.plot(x_line, y_start, 'b:', linewidth=3, alpha=0.7,\n",
    "         label=f'Start: y = {START_M}x + {START_B} (MSE={comparison_data[\"MSE\"][0]:.4f})')\n",
    "plt.plot(x_line, y_gradient, 'g--', linewidth=3, \n",
    "         label=f'Gradientenabstieg: y = {final_m:.4f}x + {final_b:.4f} (MSE={final_mse:.4f})')\n",
    "plt.plot(x_line, y_optimal, 'r-', linewidth=3, alpha=0.8,\n",
    "         label=f'Optimal: y = {m_demo_optimal:.4f}x + {b_demo_optimal:.4f} (MSE={mse_demo_optimal:.4f})')\n",
    "\n",
    "plt.xlabel('Außentemperatur (°C)', fontweight='bold')\n",
    "plt.ylabel('Energieverbrauch (kWh/h)', fontweight='bold')\n",
    "plt.title('Gradientenabstieg vs. Analytische Lösung', fontweight='bold', fontsize=14)\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xlim(5, 40)\n",
    "plt.ylim(10, 30)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Erfolgsauswertung\n",
    "if abs(final_mse - mse_demo_optimal) < 0.001:\n",
    "    print(\"\\n🎉 PERFEKTER ERFOLG! Gradientenabstieg hat die optimale Lösung gefunden!\")\n",
    "    print(\"💡 Der Computer kann automatisch die beste Gerade durch die Punkte finden!\")\n",
    "elif abs(final_mse - mse_demo_optimal) < 0.01:\n",
    "    print(\"\\n✅ SEHR GUTER ERFOLG! Gradientenabstieg ist sehr nah an der optimalen Lösung!\")\n",
    "    print(\"💡 Mit mehr Iterationen oder angepasster Lernrate wäre perfekte Konvergenz möglich!\")\n",
    "else:\n",
    "    print(\"\\n⚠️ Bitte Lernrate anpassen! Aktuell noch nicht optimal konvergiert.\")\n",
    "    print(\"💡 Versuchen Sie verschiedene Lernraten in der vorherigen Zelle!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lecture_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
