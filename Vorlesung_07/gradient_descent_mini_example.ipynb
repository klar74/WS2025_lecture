{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0101cafb",
   "metadata": {},
   "source": [
    "# üìê Gradientenabstieg am Mini-Beispiel - Vorlesung 07\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/klar74/WS2025_lecture/blob/main/Vorlesung_07/gradient_descent_mini_example.ipynb)\n",
    "\n",
    "## üéØ Das Energie-Temperatur-Beispiel aus der Vorlesung\n",
    "\n",
    "Wir haben drei Messpunkte vom **Energieverbrauch einer K√ºhlanlage** bei verschiedenen **Au√üentemperaturen**:\n",
    "- Punkt 1: (10¬∞C, 14 kWh/h) \n",
    "- Punkt 2: (20¬∞C, 19 kWh/h)\n",
    "- Punkt 3: (30¬∞C, 25 kWh/h)\n",
    "\n",
    "**Ziel**: Finde die beste Gerade $y = mx + b$ durch diese Punkte!\n",
    "\n",
    "**Warum macht das Sinn?** ü§î\n",
    "- ‚ùÑÔ∏è **Niedrigere Temperaturen** ‚Üí Weniger K√ºhlbedarf ‚Üí Geringerer Energieverbrauch  \n",
    "- ‚òÄÔ∏è **H√∂here Temperaturen** ‚Üí Mehr K√ºhlbedarf ‚Üí H√∂herer Energieverbrauch\n",
    "- üìà **Vorhersagen m√∂glich**: Was passiert bei 0¬∞C? Bei 40¬∞C? Bei 25¬∞C?\n",
    "\n",
    "**In der Vorlesung haben wir gelernt:**\n",
    "- ‚úÖ **Normalgleichungen** - Die exakte analytische L√∂sung\n",
    "- ‚úÖ **Matrixform** - $\\boldsymbol{\\beta} = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{y}$\n",
    "- ‚úÖ **MSE minimieren** - Das Least-Squares-Prinzip\n",
    "\n",
    "**Aber was passiert, wenn Normalgleichungen nicht funktionieren?**\n",
    "- üî¥ **Nichtlineare Modelle** (z.B. $y = ae^{bx}$)\n",
    "- üî¥ **Millionen von Parametern** (neuronale Netze)\n",
    "- üî¥ **Gro√üe Datens√§tze** (Matrix-Inversion zu langsam)\n",
    "\n",
    "**Antwort: Gradientenabstieg!** üöÄ\n",
    "\n",
    "Wir schauen uns jetzt den Gradientenabstieg an diesem einfachen Beispiel an!\n",
    "\n",
    "## üó∫Ô∏è Was lernen wir heute?\n",
    "\n",
    "‚úÖ **MSE-Landschaft visualisieren** - Wie sieht das \"Gebirge\" aus?  \n",
    "‚úÖ **Gradientenabstieg Schritt f√ºr Schritt** - Wie findet der Computer den Weg bergab?  \n",
    "‚úÖ **Parameter-Optimierung verstehen** - Warum funktioniert das Verfahren?  \n",
    "‚úÖ **Verbindung zu neuronalen Netzen** - Das gleiche Prinzip bei Millionen Parametern!  \n",
    "‚úÖ **Wann Normalgleichungen vs. Gradientenabstieg** - Die richtige Wahl treffen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072698cb",
   "metadata": {},
   "source": [
    "## üîß Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c94778",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pandas as pd\n",
    "\n",
    "# F√ºr sch√∂ne Plots\n",
    "%matplotlib inline\n",
    "# Versuche verschiedene Styles (fallback wenn seaborn nicht verf√ºgbar)\n",
    "try:\n",
    "    plt.style.use('seaborn-v0_8')\n",
    "except:\n",
    "    try:\n",
    "        plt.style.use('seaborn')\n",
    "    except:\n",
    "        plt.style.use('default')\n",
    "        \n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "print(\"üéâ Alle Libraries geladen!\")\n",
    "print(\"üìä Bereit f√ºr Gradientenabstieg-Visualisierung!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e0eca8",
   "metadata": {},
   "source": [
    "## üìä Unsere Datenpunkte - Das K√ºhlanlage-Temperatur-Beispiel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e86ce2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üéØ STARTPUNKT-KONFIGURATION f√ºr Gradientenabstieg\n",
    "# =================================================================\n",
    "# HIER KANNST DU VERSCHIEDENE STARTPUNKTE AUSPROBIEREN!\n",
    "# Diese Variablen werden in allen nachfolgenden Visualisierungen verwendet\n",
    "\n",
    "# Startpunkt 1: Bewusst schlecht gew√§hlt (Standard)\n",
    "#START_M = 0.3   # Steigung\n",
    "#START_B = 16.0  # Y-Achsenabschnitt\n",
    "START_M = 0   # Steigung\n",
    "START_B = 0  # Y-Achsenabschnitt\n",
    "\n",
    "# Alternative Startpunkte zum Testen (einfach auskommentieren):\n",
    "# START_M, START_B = 0.1, 20.0   # Sehr flache Steigung, hoher Y-Achsenabschnitt\n",
    "# START_M, START_B = 0.8, 5.0    # Steile Steigung, niedriger Y-Achsenabschnitt  \n",
    "# START_M, START_B = 1.0, 0.0    # Sehr steile Steigung, kein Y-Achsenabschnitt\n",
    "# START_M, START_B = 0.0, 15.0   # Horizontale Linie\n",
    "# START_M, START_B = -0.2, 25.0  # Negative Steigung (unphysikalisch!)\n",
    "\n",
    "print(\"=== STARTPUNKT-KONFIGURATION ===\")\n",
    "print(f\"Gew√§hlter Startpunkt: m = {START_M}, b = {START_B}\")\n",
    "\n",
    "# Kompatibilit√§t: Setze auch die alten Variablen\n",
    "m_guess, b_guess = START_M, START_B\n",
    "\n",
    "print(\">>> Startpunkt f√ºr alle Visualisierungen und Gradientenabstieg gesetzt!\")\n",
    "print(\">>> Du kannst verschiedene Startpunkte ausprobieren, indem du die Werte oben √§nderst.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9a8157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die Datenpunkte aus der Vorlesung (exakt wie im Skript)\n",
    "x_data = np.array([10, 20, 30])  # Au√üentemperatur in ¬∞C\n",
    "y_data = np.array([14, 19, 25])  # Energieverbrauch in kWh/h\n",
    "\n",
    "print(\"üìã Unsere Datenpunkte (exakt aus Vorlesung 07):\")\n",
    "print(\"Temperatur (¬∞C) | Energieverbrauch (kWh/h)\")\n",
    "print(\"----------------|------------------------\")\n",
    "for i in range(len(x_data)):\n",
    "    print(f\"      {x_data[i]:2d}        |          {y_data[i]:2d}\")\n",
    "\n",
    "# Analytische L√∂sung berechnen (wie im Skript)\n",
    "n = len(x_data)\n",
    "sum_x = np.sum(x_data)      # Œ£x_i = 60\n",
    "sum_y = np.sum(y_data)      # Œ£y_i = 58  \n",
    "sum_xy = np.sum(x_data * y_data)  # Œ£x_i*y_i berechnen\n",
    "sum_x2 = np.sum(x_data**2)  # Œ£x_i¬≤ = 1400\n",
    "\n",
    "print(f\"\\nüßÆ Berechnungen f√ºr Normalgleichungen (wie im Skript):\")\n",
    "print(f\"   n = {n}\")\n",
    "print(f\"   Œ£x_i = {sum_x}\")\n",
    "print(f\"   Œ£y_i = {sum_y}\")\n",
    "print(f\"   Œ£x_i*y_i = {sum_xy}\")\n",
    "print(f\"   Œ£x_i¬≤ = {sum_x2}\")\n",
    "\n",
    "# Normalgleichungen anwenden\n",
    "m_analytical = (n * sum_xy - sum_x * sum_y) / (n * sum_x2 - sum_x**2)\n",
    "b_analytical = (sum_y - m_analytical * sum_x) / n\n",
    "\n",
    "print(f\"\\nüéØ Analytische L√∂sung (Normalgleichungen):\")\n",
    "print(f\"   m = ({n}√ó{sum_xy} - {sum_x}√ó{sum_y}) / ({n}√ó{sum_x2} - {sum_x}¬≤)\")\n",
    "print(f\"   m = ({n*sum_xy} - {sum_x*sum_y}) / ({n*sum_x2} - {sum_x**2})\")\n",
    "print(f\"   m = {n*sum_xy - sum_x*sum_y} / {n*sum_x2 - sum_x**2} = {m_analytical:.3f}\")\n",
    "print(f\"   b = ({sum_y} - {m_analytical:.3f}√ó{sum_x}) / {n} = {b_analytical:.3f}\")\n",
    "\n",
    "mse_analytical = np.mean((y_data - (m_analytical * x_data + b_analytical))**2)\n",
    "print(f\"\\nüìä Optimaler MSE: {mse_analytical:.6f}\")\n",
    "\n",
    "# üîß KONTROLLE: Berechnung mit Library-Funktionen\n",
    "print(f\"\\nüîß KONTROLLE mit Standard-Libraries:\")\n",
    "\n",
    "# Methode 1: numpy.polyfit (Polynom-Fitting, Grad 1 = Gerade)\n",
    "polyfit_coeff = np.polyfit(x_data, y_data, deg=1)\n",
    "m_polyfit, b_polyfit = polyfit_coeff[0], polyfit_coeff[1]\n",
    "mse_polyfit = np.mean((y_data - (m_polyfit * x_data + b_polyfit))**2)\n",
    "\n",
    "print(f\"\\n1Ô∏è‚É£ np.polyfit(deg=1):\")\n",
    "print(f\"   m = {m_polyfit:.6f}\")\n",
    "print(f\"   b = {b_polyfit:.6f}\")\n",
    "print(f\"   MSE = {mse_polyfit:.8f}\")\n",
    "\n",
    "# Methode 2: Least Squares mit numpy.linalg.lstsq\n",
    "X_matrix = np.column_stack([x_data, np.ones(len(x_data))])  # [x, 1] Matrix\n",
    "lstsq_result = np.linalg.lstsq(X_matrix, y_data, rcond=None)\n",
    "m_lstsq, b_lstsq = lstsq_result[0][0], lstsq_result[0][1]\n",
    "mse_lstsq = np.mean((y_data - (m_lstsq * x_data + b_lstsq))**2)\n",
    "\n",
    "print(f\"\\n2Ô∏è‚É£ np.linalg.lstsq (Matrix-L√∂sung):\")\n",
    "print(f\"   m = {m_lstsq:.6f}\")\n",
    "print(f\"   b = {b_lstsq:.6f}\")\n",
    "print(f\"   MSE = {mse_lstsq:.8f}\")\n",
    "\n",
    "# Methode 3: scipy.stats.linregress (falls verf√ºgbar)\n",
    "try:\n",
    "    from scipy.stats import linregress\n",
    "    linreg_result = linregress(x_data, y_data)\n",
    "    m_scipy, b_scipy = linreg_result.slope, linreg_result.intercept\n",
    "    mse_scipy = np.mean((y_data - (m_scipy * x_data + b_scipy))**2)\n",
    "    \n",
    "    print(f\"\\n3Ô∏è‚É£ scipy.stats.linregress:\")\n",
    "    print(f\"   m = {m_scipy:.6f}\")\n",
    "    print(f\"   b = {b_scipy:.6f}\")\n",
    "    print(f\"   MSE = {mse_scipy:.8f}\")\n",
    "    print(f\"   R¬≤ = {linreg_result.rvalue**2:.6f}\")\n",
    "    print(f\"   p-value = {linreg_result.pvalue:.8f}\")\n",
    "except ImportError:\n",
    "    print(f\"\\n3Ô∏è‚É£ scipy.stats.linregress: Nicht verf√ºgbar\")\n",
    "    m_scipy, b_scipy = m_analytical, b_analytical  # Fallback\n",
    "\n",
    "# Vergleichstabelle\n",
    "print(f\"\\nüìä VERGLEICHSTABELLE:\")\n",
    "print(f\"{'Methode':<20} {'m (Steigung)':<15} {'b (Achsenabschnitt)':<20} {'MSE':<15}\")\n",
    "print(f\"{'-'*20} {'-'*15} {'-'*20} {'-'*15}\")\n",
    "print(f\"{'Normalgleichungen':<20} {m_analytical:<15.6f} {b_analytical:<20.6f} {mse_analytical:<15.8f}\")\n",
    "print(f\"{'np.polyfit':<20} {m_polyfit:<15.6f} {b_polyfit:<20.6f} {mse_polyfit:<15.8f}\")\n",
    "print(f\"{'np.linalg.lstsq':<20} {m_lstsq:<15.6f} {b_lstsq:<20.6f} {mse_lstsq:<15.8f}\")\n",
    "try:\n",
    "    print(f\"{'scipy.linregress':<20} {m_scipy:<15.6f} {b_scipy:<20.6f} {mse_scipy:<15.8f}\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Differenzen berechnen\n",
    "diff_m_polyfit = abs(m_analytical - m_polyfit)\n",
    "diff_b_polyfit = abs(b_analytical - b_polyfit)\n",
    "diff_m_lstsq = abs(m_analytical - m_lstsq)\n",
    "diff_b_lstsq = abs(b_analytical - b_lstsq)\n",
    "\n",
    "print(f\"\\n‚úÖ √úBEREINSTIMMUNG:\")\n",
    "print(f\"   np.polyfit:     Œîm = {diff_m_polyfit:.10f}, Œîb = {diff_b_polyfit:.10f}\")\n",
    "print(f\"   np.linalg.lstsq: Œîm = {diff_m_lstsq:.10f}, Œîb = {diff_b_lstsq:.10f}\")\n",
    "\n",
    "if diff_m_polyfit < 1e-10 and diff_b_polyfit < 1e-10:\n",
    "    print(f\"üéØ Alle Methoden liefern IDENTISCHE Ergebnisse!\")\n",
    "    print(f\"üí° Das best√§tigt unsere Normalgleichungen-Implementierung!\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  Kleine numerische Unterschiede (normal bei Floating-Point)\")\n",
    "\n",
    "# Plotten der Datenpunkte mit verschiedenen L√∂sungen\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(x_data, y_data, color='red', s=150, zorder=5, edgecolors='black', linewidth=2)\n",
    "plt.xlabel('Au√üentemperatur (¬∞C)', fontweight='bold')\n",
    "plt.ylabel('Energieverbrauch K√ºhlung (kWh/h)', fontweight='bold')\n",
    "plt.title('K√ºhlanlage: Vergleich verschiedener Berechnungsmethoden', fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xlim(0, 40)\n",
    "plt.ylim(5, 35)\n",
    "\n",
    "# Alle L√∂sungen einzeichnen (sollten identisch sein)\n",
    "x_line = np.linspace(0, 40, 100)\n",
    "y_analytical = m_analytical * x_line + b_analytical\n",
    "y_polyfit = m_polyfit * x_line + b_polyfit\n",
    "y_lstsq = m_lstsq * x_line + b_lstsq\n",
    "\n",
    "plt.plot(x_line, y_analytical, 'b-', linewidth=3, alpha=0.8, \n",
    "         label=f'Normalgleichungen: y = {m_analytical:.3f}x + {b_analytical:.2f}')\n",
    "plt.plot(x_line, y_polyfit, 'g--', linewidth=2, alpha=0.7,\n",
    "         label=f'np.polyfit: y = {m_polyfit:.3f}x + {b_polyfit:.2f}')\n",
    "plt.plot(x_line, y_lstsq, 'r:', linewidth=2, alpha=0.7,\n",
    "         label=f'np.linalg.lstsq: y = {m_lstsq:.3f}x + {b_lstsq:.2f}')\n",
    "\n",
    "# Punkte beschriften\n",
    "for i, (x, y) in enumerate(zip(x_data, y_data)):\n",
    "    plt.annotate(f'({x}¬∞C, {y} kWh/h)', (x, y), xytext=(5, 5), textcoords='offset points', \n",
    "                fontweight='bold', fontsize=10, bbox=dict(boxstyle='round,pad=0.2', facecolor='yellow', alpha=0.7))\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüéØ Frage: Kann Gradientenabstieg die gleiche L√∂sung finden?\")\n",
    "print(\"üí° Erwartung: Klare positive Steigung (mehr K√ºhlenergie bei h√∂herer Temperatur)\")\n",
    "print(\"üîÆ Anwendung: Energieplanung f√ºr verschiedene Wetterbedingungen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d454e49",
   "metadata": {},
   "source": [
    "## üßÆ MSE-Funktion definieren\n",
    "\n",
    "**MSE (Mean Squared Error)** = Mittlerer quadrierter Fehler\n",
    "\n",
    "$$\\text{MSE}(m,b) = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - (mx_i + b))^2$$\n",
    "\n",
    "**Das ist exakt die Kostenfunktion aus der Vorlesung!**\n",
    "\n",
    "F√ºr unsere drei Punkte (10,14), (20,19), (30,25):\n",
    "- **Normalgleichungen**: Finden das Minimum durch $\\frac{\\partial \\text{MSE}}{\\partial m} = 0$ und $\\frac{\\partial \\text{MSE}}{\\partial b} = 0$\n",
    "- **Gradientenabstieg**: Folgt dem Gradienten iterativ bergab zum Minimum\n",
    "\n",
    "**Beide Methoden sollten zum gleichen Ergebnis f√ºhren!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7bc16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mse(m, b, x_data, y_data):\n",
    "    \"\"\"\n",
    "    Berechnet den Mean Squared Error f√ºr gegebene Parameter m und b\n",
    "    \"\"\"\n",
    "    # Vorhersagen: y_hat = mx + b\n",
    "    y_predicted = m * x_data + b\n",
    "    \n",
    "    # Residuen: Differenz zwischen echten und vorhergesagten Werten\n",
    "    residuals = y_data - y_predicted\n",
    "    \n",
    "    # MSE: Mittlerer quadrierter Fehler\n",
    "    mse = np.mean(residuals**2)\n",
    "    \n",
    "    return mse\n",
    "\n",
    "# Test mit der analytischen L√∂sung (Kontrolle)\n",
    "mse_check = calculate_mse(m_analytical, b_analytical, x_data, y_data)\n",
    "print(f\"üîç Kontrolle - MSE der analytischen L√∂sung: {mse_check:.6f}\")\n",
    "print(f\"üìã √úbereinstimmung: {abs(mse_check - mse_analytical) < 1e-10}\")\n",
    "\n",
    "# Test: Verwende den konfigurierten Startpunkt  \n",
    "# (m_guess und b_guess wurden bereits in der Startpunkt-Konfiguration gesetzt)\n",
    "mse_guess = calculate_mse(START_M, START_B, x_data, y_data)\n",
    "\n",
    "print(f\"\\nü§î Konfigurierter Startpunkt: m = {START_M}, b = {START_B}\")\n",
    "print(f\"üìä MSE = {mse_guess:.3f}\")\n",
    "\n",
    "# Berechnung per Hand f√ºr unsere Sch√§tzung (Demonstration)\n",
    "print(\"\\n‚úã Per Hand gerechnet (zur Kontrolle):\")\n",
    "total_squared_error = 0\n",
    "for i, (x, y) in enumerate(zip(x_data, y_data)):\n",
    "    y_pred = START_M * x + START_B\n",
    "    residual = y - y_pred\n",
    "    squared_residual = residual**2\n",
    "    total_squared_error += squared_residual\n",
    "    print(f\"Punkt {i+1}: ({x}¬∞C, {y} kWh/h) ‚Üí Vorhersage {y_pred:.1f} ‚Üí Residuum {residual:.1f} ‚Üí r¬≤ = {squared_residual:.3f}\")\n",
    "\n",
    "manual_mse = total_squared_error / len(x_data)\n",
    "print(f\"\\nüßÆ MSE per Hand: {manual_mse:.3f}\")\n",
    "print(f\"üñ•Ô∏è  MSE per Code: {mse_guess:.3f}\")\n",
    "print(\"‚úÖ Stimmen √ºberein!\")\n",
    "\n",
    "print(f\"\\nüí≠ Die Frage:\")\n",
    "print(f\"   ‚Ä¢ Wie kann der Computer automatisch von MSE={mse_guess:.3f} zu MSE={mse_analytical:.6f} kommen?\")\n",
    "print(f\"   ‚Ä¢ Antwort: Gradientenabstieg!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bb52de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_gradients_correct(m, b, x_data, y_data):\n",
    "    \"\"\"\n",
    "    Berechnet die Gradienten der MSE-Funktion korrekt f√ºr m und b.\n",
    "    \n",
    "    Aus der Vorlesung: MSE(m,b) = 1/n * Œ£(y_i - (mx_i + b))¬≤\n",
    "    \n",
    "    Partielle Ableitungen:\n",
    "    ‚àÇMSE/‚àÇm = -2/n * Œ£[x_i * (y_i - (mx_i + b))]\n",
    "    ‚àÇMSE/‚àÇb = -2/n * Œ£[y_i - (mx_i + b)]\n",
    "    \"\"\"\n",
    "    n = len(x_data)\n",
    "    y_pred = m * x_data + b\n",
    "    residuals = y_data - y_pred\n",
    "    \n",
    "    # Gradient nach m: -2/n * Summe[x_i * (y_i - (mx_i + b))]\n",
    "    grad_m = -2 * np.sum(x_data * residuals) / n\n",
    "    # Gradient nach b: -2/n * Summe[y_i - (mx_i + b)]\n",
    "    grad_b = -2 * np.sum(residuals) / n\n",
    "    \n",
    "    return grad_m, grad_b\n",
    "\n",
    "# Test der Gradienten am optimalen Punkt (sollten ~0 sein)\n",
    "grad_m_opt, grad_b_opt = calculate_gradients_correct(m_analytical, b_analytical, x_data, y_data)\n",
    "print(f\"üéØ Gradienten am Optimum (sollten ‚âà 0 sein):\")\n",
    "print(f\"   ‚àÇMSE/‚àÇm = {grad_m_opt:.8f}\")\n",
    "print(f\"   ‚àÇMSE/‚àÇb = {grad_b_opt:.8f}\")\n",
    "print(f\"‚úÖ Praktisch null - Normalgleichungen haben das Minimum gefunden!\")\n",
    "\n",
    "# Test der Gradienten am schlechten Startpunkt\n",
    "grad_m_start, grad_b_start = calculate_gradients_correct(START_M, START_B, x_data, y_data)\n",
    "print(f\"\\nü§î Gradienten am Startpunkt m={START_M}, b={START_B}:\")\n",
    "print(f\"   ‚àÇMSE/‚àÇm = {grad_m_start:.4f}\")\n",
    "print(f\"   ‚àÇMSE/‚àÇb = {grad_b_start:.4f}\")\n",
    "print(f\"üí° Diese zeigen die Richtung des steilsten Anstiegs!\")\n",
    "print(f\"üèîÔ∏è  F√ºr Abstieg gehen wir in die entgegengesetzte Richtung!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b675e4",
   "metadata": {},
   "source": [
    "## üó∫Ô∏è Die MSE-Landschaft erstellen\n",
    "\n",
    "Jetzt kommt das Spannende! Wir berechnen MSE f√ºr viele verschiedene Kombinationen von **m** (Steigung) und **b** (Achsenabschnitt) und visualisieren das als \"Gebirge\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18dbeabb",
   "metadata": {},
   "source": [
    "## üåÑ Interaktive 3D-MSE-Landschaft\n",
    "\n",
    "**Jetzt wird's spannend!** Wir erstellen eine **interaktive 3D-Visualisierung** der MSE-Landschaft, die du mit der Maus drehen und zoomen kannst!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fcf44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative f√ºr interaktive 3D-Plots - BOKEH ist besser f√ºr Jupyter!\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Bokeh als beste Alternative f√ºr echte Interaktivit√§t in Jupyter\n",
    "try:\n",
    "    from bokeh.plotting import figure, show, output_notebook\n",
    "    from bokeh.models import HoverTool, ColorBar, LinearColorMapper\n",
    "    from bokeh.palettes import Plasma256\n",
    "    from bokeh.layouts import row, column\n",
    "    from bokeh.models import ColumnDataSource\n",
    "    import bokeh.io\n",
    "    \n",
    "    # Bokeh f√ºr Jupyter Notebook aktivieren\n",
    "    output_notebook()\n",
    "    BOKEH_AVAILABLE = True\n",
    "    print(\">>> Bokeh gefunden und f√ºr Jupyter konfiguriert!\")\n",
    "    print(\"*** Bokeh funktioniert deutlich besser als Plotly in Notebooks!\")\n",
    "    \n",
    "except ImportError:\n",
    "    BOKEH_AVAILABLE = False\n",
    "    print(\">>> Bokeh nicht verf√ºgbar - verwende Matplotlib\")\n",
    "    print(\"!!! Installiere Bokeh f√ºr echte Interaktivit√§t: pip install bokeh\")\n",
    "except Exception as e:\n",
    "    BOKEH_AVAILABLE = False\n",
    "    print(f\"!!! Bokeh-Konfigurationsproblem: {e}\")\n",
    "    print(\">>> Verwende Matplotlib als Fallback\")\n",
    "\n",
    "print(\">>> 3D-Visualisierung wird erstellt...\")\n",
    "\n",
    "# Parameter-Bereiche f√ºr 3D-Plot definieren (gr√∂√üerer Bereich f√ºr Startpunkt)\n",
    "m_range_3d = np.linspace(-0.1, 1.2, 60)   # Erweitert um Startpunkt m=0.3 zu erfassen\n",
    "b_range_3d = np.linspace(0, 25, 60)       # Erweitert um Startpunkt b=16.0 zu erfassen\n",
    "\n",
    "# Gitter erstellen\n",
    "M_3d, B_3d = np.meshgrid(m_range_3d, b_range_3d)\n",
    "\n",
    "# MSE f√ºr alle Kombinationen berechnen\n",
    "MSE_3d = np.zeros_like(M_3d)\n",
    "\n",
    "print(f\"\\n>>> Berechne MSE-Landschaft (h√∂here Aufl√∂sung: {len(m_range_3d)}√ó{len(b_range_3d)})...\")\n",
    "for i in range(M_3d.shape[0]):\n",
    "    for j in range(M_3d.shape[1]):\n",
    "        MSE_3d[i, j] = calculate_mse(M_3d[i, j], B_3d[i, j], x_data, y_data)\n",
    "\n",
    "print(\"*** MSE-Landschaft berechnet!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efb581f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üåã INTERAKTIVE MSE-LANDSCHAFT (Bokeh ist die beste L√∂sung f√ºr Jupyter!)\n",
    "# =========================================================================\n",
    "\n",
    "if BOKEH_AVAILABLE:\n",
    "    print(\">>> Erstelle interaktive Bokeh-Visualisierung...\")\n",
    "    \n",
    "    try:\n",
    "        # Daten f√ºr Bokeh vorbereiten (2D Heatmap + Konturen)\n",
    "        # Bokeh macht zwar keine echten 3D-Plots, aber sehr sch√∂ne interaktive 2D-Plots\n",
    "        \n",
    "        # 1. INTERAKTIVE HEATMAP der MSE-Landschaft\n",
    "        # Flatten der Daten f√ºr Bokeh\n",
    "        m_flat = M_3d.flatten()\n",
    "        b_flat = B_3d.flatten()  \n",
    "        mse_flat = MSE_3d.flatten()\n",
    "        \n",
    "        # ColumnDataSource f√ºr Bokeh\n",
    "        source = ColumnDataSource(data=dict(\n",
    "            m=m_flat,\n",
    "            b=b_flat,\n",
    "            mse=mse_flat\n",
    "        ))\n",
    "        \n",
    "        # Color mapper f√ºr MSE-Werte\n",
    "        color_mapper = LinearColorMapper(palette=Plasma256, \n",
    "                                       low=mse_flat.min(), \n",
    "                                       high=mse_flat.max())\n",
    "        \n",
    "        # Hauptplot erstellen\n",
    "        p = figure(width=600, height=500,\n",
    "                  title=\"Interaktive MSE-Energielandschaft\",\n",
    "                  x_axis_label=\"Steigung m\",\n",
    "                  y_axis_label=\"Y-Achsenabschnitt b\",\n",
    "                  toolbar_location=\"above\")\n",
    "        \n",
    "        # Heatmap/Scatter plot\n",
    "        scatter = p.scatter('m', 'b', size=8, source=source,\n",
    "                          color={'field': 'mse', 'transform': color_mapper},\n",
    "                          alpha=0.8)\n",
    "        \n",
    "        # Optimum markieren\n",
    "        p.scatter([m_analytical], [b_analytical], size=20, color='red', \n",
    "                 marker='star', line_color='white', line_width=2, \n",
    "                 legend_label=f'* Optimum ({m_analytical:.3f}, {b_analytical:.3f})')\n",
    "        \n",
    "        # Startpunkt markieren  \n",
    "        p.scatter([START_M], [START_B], size=15, color='lime', marker='circle',\n",
    "                 line_color='black', line_width=2,\n",
    "                 legend_label=f'> Start ({START_M}, {START_B})')\n",
    "        \n",
    "        # Hover-Tool f√ºr Interaktivit√§t\n",
    "        hover = HoverTool(tooltips=[\n",
    "            (\"Steigung m\", \"@m{0.000}\"),\n",
    "            (\"Y-Achsenabschnitt b\", \"@b{0.000}\"), \n",
    "            (\"MSE\", \"@mse{0.000000}\")\n",
    "        ])\n",
    "        p.add_tools(hover)\n",
    "        \n",
    "        # Color bar hinzuf√ºgen\n",
    "        color_bar = ColorBar(color_mapper=color_mapper, width=8, location=(0,0))\n",
    "        p.add_layout(color_bar, 'right')\n",
    "        \n",
    "        # 2. ZUS√ÑTZLICHER QUERSCHNITT-PLOT\n",
    "        mse_slice = [calculate_mse(m, b_analytical, x_data, y_data) for m in m_range_3d]\n",
    "        \n",
    "        p2 = figure(width=600, height=300,\n",
    "                   title=f\"MSE-Querschnitt bei b={b_analytical:.2f}\",\n",
    "                   x_axis_label=\"Steigung m\",\n",
    "                   y_axis_label=\"MSE\")\n",
    "        \n",
    "        p2.line(m_range_3d, mse_slice, line_width=3, color='purple', \n",
    "               legend_label='MSE(m)')\n",
    "        p2.line([m_analytical, m_analytical], [0, max(mse_slice)], \n",
    "               line_width=2, color='red', line_dash='dashed',\n",
    "               legend_label=f'Optimum m={m_analytical:.3f}')\n",
    "        p2.line([START_M, START_M], [0, max(mse_slice)],\n",
    "               line_width=2, color='green', line_dash='dashed', \n",
    "               legend_label=f'Start m={START_M}')\n",
    "        \n",
    "        # Beide Plots anzeigen\n",
    "        layout = column(p, p2)\n",
    "        show(layout)\n",
    "        \n",
    "        print(\"*** INTERAKTIVE BOKEH-VISUALISIERUNG AKTIV!\")\n",
    "        print(\"=\" * 60)\n",
    "        print(\">>> INTERAKTIVE FEATURES:\")\n",
    "        print(\"   ‚Ä¢ Hover √ºber Punkte ‚Üí MSE-Werte anzeigen\")\n",
    "        print(\"   ‚Ä¢ Pan-Tool ‚Üí Verschieben der Ansicht\")\n",
    "        print(\"   ‚Ä¢ Zoom-Tool ‚Üí Hinein-/Herauszoomen\")\n",
    "        print(\"   ‚Ä¢ Reset-Tool ‚Üí Zur√ºck zur urspr√ºnglichen Ansicht\")\n",
    "        print()\n",
    "        print(\">>> Was du siehst:\")\n",
    "        print(\"   ‚Ä¢ Roter Stern = Optimum (Tiefster MSE-Wert)\")\n",
    "        print(\"   ‚Ä¢ Gr√ºner Kreis = Startsch√§tzung\")\n",
    "        print(\"   ‚Ä¢ Farbverlauf = MSE-Landschaft (dunkel = niedrig, hell = hoch)\")\n",
    "        print(\"   ‚Ä¢ Unterer Plot = Querschnitt durch die Landschaft\")\n",
    "        print(\"   ‚Ä¢ >>> Gradientenabstieg w√ºrde vom gr√ºnen zum roten Punkt laufen!\")\n",
    "        \n",
    "    except Exception as bokeh_error:\n",
    "        print(f\"!!! Bokeh-Fehler: {bokeh_error}\")\n",
    "        print(\">>> Verwende Matplotlib als Fallback...\")\n",
    "        BOKEH_AVAILABLE = False\n",
    "\n",
    "# HAUPTVISUALISIERUNG: 3D MSE-LANDSCHAFT\n",
    "print(\"*** Erstelle gro√üe 3D-MSE-Landschaft mit Startpunkt...\")\n",
    "\n",
    "# Gro√üe 3D-Visualisierung mit Fokus auf 3D-Plot\n",
    "fig = plt.figure(figsize=(20, 8))\n",
    "\n",
    "# 3D Surface Plot (gr√∂√üer und zentraler)\n",
    "ax1 = fig.add_subplot(121, projection='3d')\n",
    "surf = ax1.plot_surface(M_3d, B_3d, MSE_3d, \n",
    "                      cmap='viridis', alpha=0.8, linewidth=0, antialiased=True,\n",
    "                      rstride=1, cstride=1)\n",
    "\n",
    "# Optimum und Startpunkt markieren\n",
    "start_mse = calculate_mse(START_M, START_B, x_data, y_data)\n",
    "ax1.scatter([m_analytical], [b_analytical], [mse_analytical], \n",
    "           color='red', s=300, alpha=1.0, label='* Optimum', edgecolors='white', linewidth=2)\n",
    "ax1.scatter([START_M], [START_B], [start_mse], \n",
    "           color='lime', s=250, alpha=1.0, label='> Start', edgecolors='black', linewidth=2)\n",
    "\n",
    "# Sch√∂nere Achsenbeschriftung\n",
    "ax1.set_xlabel('Steigung m', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel('Y-Achsenabschnitt b', fontsize=12, fontweight='bold')\n",
    "ax1.set_zlabel('MSE', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('3D MSE-Landschaft (Erweitert)', fontsize=14, fontweight='bold')\n",
    "ax1.legend(fontsize=11)\n",
    "\n",
    "# Colorbar f√ºr 3D-Plot\n",
    "fig.colorbar(surf, ax=ax1, shrink=0.5, aspect=30)\n",
    "\n",
    "# Bessere Ansicht einstellen (um 90¬∞ gedreht f√ºr bessere Perspektive)\n",
    "ax1.view_init(elev=20, azim=135)\n",
    "\n",
    "# Konturkarte mit mehr Details\n",
    "ax2 = fig.add_subplot(122)\n",
    "contour = ax2.contourf(M_3d, B_3d, MSE_3d, levels=25, cmap='viridis', alpha=0.8)\n",
    "contour_lines = ax2.contour(M_3d, B_3d, MSE_3d, levels=15, colors='white', alpha=0.6, linewidths=0.8)\n",
    "ax2.clabel(contour_lines, inline=True, fontsize=8, fmt='%.2f')\n",
    "\n",
    "# Punkte markieren\n",
    "ax2.plot(m_analytical, b_analytical, 'r*', markersize=20, label='* Optimum', \n",
    "         markeredgecolor='white', markeredgewidth=2)\n",
    "ax2.plot(START_M, START_B, 'o', color='lime', markersize=15, label='> Start',\n",
    "         markeredgecolor='black', markeredgewidth=2)\n",
    "\n",
    "ax2.set_xlabel('Steigung m', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('Y-Achsenabschnitt b', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('MSE-Konturen (von oben)', fontsize=14, fontweight='bold')\n",
    "ax2.legend(fontsize=11)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Achsenbereiche erweitern f√ºr bessere √úbersicht\n",
    "ax2.set_xlim(m_range_3d.min() - 0.05, m_range_3d.max() + 0.05)\n",
    "ax2.set_ylim(b_range_3d.min() - 1, b_range_3d.max() + 1)\n",
    "\n",
    "# Colorbar f√ºr Konturkarte\n",
    "plt.colorbar(contour, ax=ax2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"*** GRO√üE 3D MSE-LANDSCHAFT ERSTELLT!\")\n",
    "print(\"=\" * 60)\n",
    "print(\">>> Was du siehst:\")\n",
    "print(\"   ‚Ä¢ Links: 3D-Oberfl√§che der MSE-Landschaft (drehbar im interaktiven Modus)\")\n",
    "print(\"   ‚Ä¢ Rechts: Konturkarte von oben (H√∂henlinien mit MSE-Werten)\")\n",
    "print()\n",
    "print(\"!!! INTERPRETATION:\")\n",
    "print(f\"   ‚Ä¢ Roter Stern = Optimum bei m={m_analytical:.3f}, b={b_analytical:.3f}\")\n",
    "print(f\"   ‚Ä¢ Gr√ºner Kreis = Startpunkt bei m={START_M}, b={START_B}\")\n",
    "print(f\"   ‚Ä¢ MSE-Bereich: {MSE_3d.min():.3f} bis {MSE_3d.max():.1f}\")\n",
    "print(\"   ‚Ä¢ Tiefe T√§ler = Niedrige MSE (besser)\")\n",
    "print(\"   ‚Ä¢ Hohe Berge = Hohe MSE (schlechter)\")\n",
    "print()\n",
    "print(\">>> Gradientenabstieg w√ºrde vom gr√ºnen Punkt bergab zum roten Stern laufen!\")\n",
    "\n",
    "print(f\"\\n!!! EMPFEHLUNG f√ºr echte Interaktivit√§t:\")\n",
    "print(f\"   pip install bokeh\")  \n",
    "print(f\"   Bokeh funktioniert viel besser als Plotly in Jupyter Notebooks!\")\n",
    "print(f\"   Mit Bokeh bekommst du echte Mouse-Over-Effekte und Zoom-Funktionen!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda96b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üèîÔ∏è ALTERNATIVE: NOCH GR√ñ√üERE 3D-LANDSCHAFT\n",
    "# =============================================\n",
    "\n",
    "# F√ºr eine noch bessere √úbersicht eine extra gro√üe Visualisierung\n",
    "print(\"*** Erstelle maximale 3D-MSE-Landschaft...\")\n",
    "\n",
    "fig = plt.figure(figsize=(16, 12))\n",
    "\n",
    "# Gro√üer 3D-Plot\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Surface mit noch mehr Details\n",
    "surf = ax.plot_surface(M_3d, B_3d, MSE_3d, \n",
    "                      cmap='viridis', alpha=0.9, linewidth=0, antialiased=True,\n",
    "                      rstride=1, cstride=1, shade=True)\n",
    "\n",
    "# Optimum und Startpunkt extra gro√ü markieren\n",
    "start_mse = calculate_mse(START_M, START_B, x_data, y_data)\n",
    "ax.scatter([m_analytical], [b_analytical], [mse_analytical], \n",
    "          color='red', s=400, alpha=1.0, label='* Optimum', \n",
    "          edgecolors='white', linewidth=3, depthshade=False)\n",
    "ax.scatter([START_M], [START_B], [start_mse], \n",
    "          color='lime', s=350, alpha=1.0, label='> Start', \n",
    "          edgecolors='black', linewidth=3, depthshade=False)\n",
    "\n",
    "# Sch√∂ne Achsenbeschriftung\n",
    "ax.set_xlabel('Steigung m', fontsize=14, fontweight='bold', labelpad=10)\n",
    "ax.set_ylabel('Y-Achsenabschnitt b', fontsize=14, fontweight='bold', labelpad=10)\n",
    "ax.set_zlabel('MSE', fontsize=14, fontweight='bold', labelpad=10)\n",
    "ax.set_title('3D MSE-Landschaft - Komplette √úbersicht', fontsize=16, fontweight='bold', pad=20)\n",
    "\n",
    "# Legende gr√∂√üer\n",
    "ax.legend(fontsize=12, loc='upper right')\n",
    "\n",
    "# Colorbar\n",
    "cbar = fig.colorbar(surf, ax=ax, shrink=0.6, aspect=40, pad=0.1)\n",
    "cbar.set_label('MSE-Wert', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Optimale 3D-Ansicht (um 90¬∞ gedreht f√ºr bessere Perspektive)\n",
    "ax.view_init(elev=25, azim=135)\n",
    "\n",
    "# Gitter f√ºr bessere Orientierung\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"*** MAXIMALE 3D-VISUALISIERUNG FERTIG!\")\n",
    "print(\"=\" * 60)\n",
    "print(\">>> Parameter-Bereiche:\")\n",
    "print(f\"   ‚Ä¢ Steigung m: {m_range_3d.min():.1f} bis {m_range_3d.max():.1f}\")\n",
    "print(f\"   ‚Ä¢ Y-Achsenabschnitt b: {b_range_3d.min():.1f} bis {b_range_3d.max():.1f}\")\n",
    "print(f\"   ‚Ä¢ MSE-Bereich: {MSE_3d.min():.3f} bis {MSE_3d.max():.1f}\")\n",
    "print()\n",
    "print(\">>> Wichtige Punkte:\")\n",
    "print(f\"   ‚Ä¢ Optimum: m={m_analytical:.3f}, b={b_analytical:.3f}, MSE={mse_analytical:.6f}\")\n",
    "print(f\"   ‚Ä¢ Start: m={START_M}, b={START_B}, MSE={start_mse:.3f}\")\n",
    "print(f\"   ‚Ä¢ Verbesserung: {start_mse/mse_analytical:.1f}x niedriger MSE beim Optimum!\")\n",
    "print()\n",
    "print(\"!!! Diese Landschaft zeigt perfekt, wie Gradientenabstieg funktioniert:\")\n",
    "print(\"   1. Start auf dem hohen 'Berg' (gr√ºner Punkt)\")\n",
    "print(\"   2. Folge dem steilsten Abstieg (Gradientenrichtung)\")\n",
    "print(\"   3. Erreiche das tiefste Tal (rotes Optimum)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3590e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîÑ Zur√ºck zu statischen Plots f√ºr den Rest des Notebooks\n",
    "%matplotlib inline\n",
    "\n",
    "print(\">>> Matplotlib auf statische Plots zur√ºckgesetzt f√ºr weitere Visualisierungen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbb5895",
   "metadata": {},
   "source": [
    "## üö∂‚Äç‚ôÇÔ∏è Gradientenabstieg Schritt f√ºr Schritt\n",
    "\n",
    "Jetzt simulieren wir, wie der Computer den Weg bergab findet! Wir starten von unserer Sch√§tzung aus und folgen dem steilsten Abstieg.\n",
    "\n",
    "‚ö†Ô∏è **Wichtig**: Die **Lernrate Œ±** ist kritisch! Zu gro√ü ‚Üí Divergenz, zu klein ‚Üí sehr langsam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636e27cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# F√ºr eine stabile Demonstration f√ºgen wir diskret einige zus√§tzliche Punkte hinzu\n",
    "x_demo = np.array([8, 10, 12, 15, 18, 20, 22, 25, 27, 30, 32, 35])\n",
    "y_demo = np.array([12.5, 14, 15.2, 16.8, 18.1, 19, 20.5, 22.3, 23.8, 25, 26.1, 28.2])\n",
    "\n",
    "# WICHTIG: Analytische L√∂sung f√ºr die erweiterten Punkte berechnen\n",
    "n_demo = len(x_demo)\n",
    "sum_x_demo = np.sum(x_demo)\n",
    "sum_y_demo = np.sum(y_demo)\n",
    "sum_xy_demo = np.sum(x_demo * y_demo)\n",
    "sum_x2_demo = np.sum(x_demo**2)\n",
    "\n",
    "m_demo_optimal = (n_demo * sum_xy_demo - sum_x_demo * sum_y_demo) / (n_demo * sum_x2_demo - sum_x_demo**2)\n",
    "b_demo_optimal = (sum_y_demo - m_demo_optimal * sum_x_demo) / n_demo\n",
    "mse_demo_optimal = calculate_mse(m_demo_optimal, b_demo_optimal, x_demo, y_demo)\n",
    "\n",
    "print(\"üìä ANALYTISCHE L√ñSUNG f√ºr die erweiterten Punkte:\")\n",
    "print(f\"   Anzahl Punkte: {n_demo}\")\n",
    "print(f\"   Optimale Steigung: m = {m_demo_optimal:.6f}\")\n",
    "print(f\"   Optimaler Y-Achsenabschnitt: b = {b_demo_optimal:.6f}\")\n",
    "print(f\"   Optimaler MSE: {mse_demo_optimal:.8f}\")\n",
    "\n",
    "print(f\"\\nüîç Vergleich Original vs. Erweitert:\")\n",
    "print(f\"   Original (3 Punkte): m = {m_analytical:.6f}, b = {b_analytical:.6f}\")\n",
    "print(f\"   Erweitert ({n_demo} Punkte): m = {m_demo_optimal:.6f}, b = {b_demo_optimal:.6f}\")\n",
    "\n",
    "def gradient_descent_simple(x_data, y_data, start_m=0.3, start_b=16.0, learning_rate=0.01, max_iterations=200):\n",
    "    \"\"\"Einfacher Gradientenabstieg f√ºr Demonstrationszwecke\"\"\"\n",
    "    m, b = start_m, start_b\n",
    "    history = {'m': [m], 'b': [b], 'mse': []}\n",
    "    \n",
    "    for i in range(max_iterations):\n",
    "        # MSE berechnen\n",
    "        mse = calculate_mse(m, b, x_data, y_data)\n",
    "        history['mse'].append(mse)\n",
    "        \n",
    "        # Gradienten berechnen\n",
    "        grad_m, grad_b = calculate_gradients_correct(m, b, x_data, y_data)\n",
    "        \n",
    "        # Parameter aktualisieren\n",
    "        m = m - learning_rate * grad_m\n",
    "        b = b - learning_rate * grad_b\n",
    "        \n",
    "        # Historie speichern\n",
    "        history['m'].append(m)\n",
    "        history['b'].append(b)\n",
    "        \n",
    "        # Fortschritt anzeigen (alle 1000 Iterationen)\n",
    "        if (i + 1) % 1000 == 0:\n",
    "            print(f\"Iteration {i+1:5d}: m = {m:.6f}, b = {b:.6f}, MSE = {mse:.8f}\")\n",
    "    \n",
    "    # Finale MSE\n",
    "    final_mse = calculate_mse(m, b, x_data, y_data)\n",
    "    history['mse'].append(final_mse)\n",
    "    \n",
    "    return history\n",
    "\n",
    "print(f\"\\nüöÄ Gradientenabstieg ist bereit!\")\n",
    "print(f\"üìä Ziel: m = {m_demo_optimal:.6f}, b = {b_demo_optimal:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cbcb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INFO: Startpunkt-Konfiguration wurde bereits fr√ºher im Notebook definiert\n",
    "# Die Variablen START_M und START_B sind bereits gesetzt und werden hier nur referenziert\n",
    "\n",
    "print(\"=== STARTPUNKT F√úR GRADIENTENABSTIEG ===\")\n",
    "print(f\"Verwendeter Startpunkt: m = {START_M}, b = {START_B}\")\n",
    "\n",
    "# Erweiterte Validierung f√ºr den Gradientenabstieg\n",
    "if 'x_demo' in locals():\n",
    "    start_mse_value = calculate_mse(START_M, START_B, x_demo, y_demo)\n",
    "    print(f\"MSE am Startpunkt: {start_mse_value:.4f}\")\n",
    "    \n",
    "    if 'mse_demo_optimal' in locals():\n",
    "        print(f\"Ziel-MSE (optimal): {mse_demo_optimal:.6f}\")\n",
    "        print(f\"Verbesserungspotential: {start_mse_value/mse_demo_optimal:.1f}x\")\n",
    "\n",
    "# Validierung des Startpunkts\n",
    "if START_M < -1.0 or START_M > 2.0:\n",
    "    print(\"!!! WARNUNG: Steigung au√üerhalb des sinnvollen Bereichs (-1.0 bis 2.0)\")\n",
    "if START_B < -10.0 or START_B > 40.0:\n",
    "    print(\"!!! WARNUNG: Y-Achsenabschnitt au√üerhalb des sinnvollen Bereichs (-10 bis 40)\")\n",
    "\n",
    "print(f\"\\n>>> Bereit f√ºr Gradientenabstieg von ({START_M}, {START_B}) zum Optimum!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856603ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß™ EXPERIMENTIER-BEREICH: √Ñndere die Lernrate hier!\n",
    "# ===============================================================\n",
    "\n",
    "LEARNING_RATE = 0.0015  # ‚ö†Ô∏è OPTIMAL GEFUNDEN! \n",
    "# Funktioniert: 0.0015 mit 20000 Iterationen\n",
    "# Andere Werte zum Testen: 0.001, 0.002, 0.005\n",
    "\n",
    "print(\"üéØ Starte Gradientenabstieg...\")\n",
    "print(f\"üìç Startpunkt: m = {START_M}, b = {START_B}\")\n",
    "print(f\"üéØ ZIEL (korrekt f√ºr erweiterte Daten): m = {m_demo_optimal:.6f}, b = {b_demo_optimal:.6f}\")\n",
    "print(f\"üîß Lernrate: {LEARNING_RATE}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Gradientenabstieg ausf√ºhren\n",
    "history = gradient_descent_simple(x_demo, y_demo, start_m=START_M, start_b=START_B, \n",
    "                                learning_rate=LEARNING_RATE, max_iterations=20000)\n",
    "\n",
    "# Finale Ergebnisse\n",
    "final_m = history['m'][-1]\n",
    "final_b = history['b'][-1]\n",
    "final_mse = history['mse'][-1]\n",
    "\n",
    "print(\"-\" * 70)\n",
    "print(\"üéâ FERTIG!\")\n",
    "print(f\"üìä Ergebnis: m = {final_m:.6f}, b = {final_b:.6f}\")\n",
    "print(f\"üìà Finale MSE: {final_mse:.8f}\")\n",
    "\n",
    "# Vergleich mit analytischer L√∂sung (KORREKT f√ºr erweiterte Daten)\n",
    "print(f\"‚úÖ Optimal MSE: {mse_demo_optimal:.8f}\")\n",
    "print(f\"üìä MSE-Differenz: {abs(final_mse - mse_demo_optimal):.8f}\")\n",
    "print(f\"üìä Parameter-Differenz: Œîm = {abs(final_m - m_demo_optimal):.6f}, Œîb = {abs(final_b - b_demo_optimal):.6f}\")\n",
    "\n",
    "if abs(final_mse - mse_demo_optimal) < 0.001:\n",
    "    print(\"üéâ PERFEKT! Gradientenabstieg hat das Optimum erreicht!\")\n",
    "elif abs(final_mse - mse_demo_optimal) < 0.01:\n",
    "    print(\"‚úÖ SEHR GUT! Gradientenabstieg ist sehr nah am Optimum!\")\n",
    "elif abs(final_mse - mse_demo_optimal) < 0.1:\n",
    "    print(\"üëç GUT! Gradientenabstieg konvergiert zum Optimum!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è ACHTUNG! M√∂glicherweise divergiert oder Lernrate zu gro√ü/klein!\")\n",
    "    \n",
    "# Konvergenz-Check\n",
    "if len(history['mse']) > 10:\n",
    "    recent_change = abs(history['mse'][-1] - history['mse'][-10])\n",
    "    if recent_change < 1e-6:\n",
    "        print(\"‚úÖ Konvergiert stabil\")\n",
    "    elif recent_change > 1000:\n",
    "        print(\"üö® DIVERGENZ! Lernrate zu gro√ü!\")\n",
    "    else:\n",
    "        print(\"üìà Noch am konvergieren...\")\n",
    "\n",
    "print(f\"\\nüí° TIPP: Experimentiere mit verschiedenen Lernraten!\")\n",
    "print(f\"   ‚Ä¢ Zu gro√ü (z.B. 0.1): Divergenz oder Oszillation\")\n",
    "print(f\"   ‚Ä¢ Zu klein (z.B. 0.0001): Sehr langsame Konvergenz\")\n",
    "print(f\"   ‚Ä¢ Optimal (z.B. 0.01): Schnelle, stabile Konvergenz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdad4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisierung der Konvergenz\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Plot 1: MSE-Verlauf\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(history['mse'], 'purple', linewidth=2, marker='o', markersize=3)\n",
    "plt.axhline(y=mse_demo_optimal, color='red', linestyle='--', alpha=0.7, \n",
    "           label=f'Optimum: {mse_demo_optimal:.6f}')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('MSE')\n",
    "plt.title('MSE-Minimierung')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.yscale('log')  # Log-Skala f√ºr bessere Sichtbarkeit\n",
    "\n",
    "# Plot 2: Parameter-Entwicklung m\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(history['m'], 'blue', linewidth=2, marker='o', markersize=3, label='Steigung m')\n",
    "plt.axhline(y=m_demo_optimal, color='red', linestyle='--', alpha=0.7, \n",
    "           label=f'Optimum: {m_demo_optimal:.4f}')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Steigung m')\n",
    "plt.title('Konvergenz der Steigung')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Parameter-Entwicklung b\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(history['b'], 'green', linewidth=2, marker='o', markersize=3, label='Y-Achsenabschnitt b')\n",
    "plt.axhline(y=b_demo_optimal, color='red', linestyle='--', alpha=0.7, \n",
    "           label=f'Optimum: {b_demo_optimal:.4f}')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Y-Achsenabschnitt b')\n",
    "plt.title('Konvergenz des Y-Achsenabschnitts')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üìä Die Plots zeigen die schrittweise Verbesserung der Parameter!\")\n",
    "print(\"üí° MSE ist auf logarithmischer Skala f√ºr bessere Sichtbarkeit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2211c6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finale Vergleichstabelle und Visualisierung\n",
    "comparison_data = {\n",
    "    'Methode': ['Startsch√§tzung', 'Gradientenabstieg', 'Analytisch (optimal)'],\n",
    "    'Steigung m': [START_M, final_m, m_demo_optimal],\n",
    "    'Achsenabschnitt b': [START_B, final_b, b_demo_optimal],\n",
    "    'MSE': [calculate_mse(START_M, START_B, x_demo, y_demo), final_mse, mse_demo_optimal]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(comparison_data)\n",
    "print(\"ERGEBNISVERGLEICH (f√ºr erweiterte Daten):\")\n",
    "print(\"=\" * 70)\n",
    "print(df.to_string(index=False, float_format='%.6f'))\n",
    "\n",
    "# Visualisierung der drei Geraden\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Datenpunkte\n",
    "plt.scatter(x_demo, y_demo, color='red', s=100, zorder=5, edgecolors='black', \n",
    "           linewidth=1, label='Demonstrationsdaten', alpha=0.8)\n",
    "\n",
    "# Geraden\n",
    "x_line = np.linspace(5, 40, 100)\n",
    "y_start = START_M * x_line + START_B\n",
    "y_gradient = final_m * x_line + final_b\n",
    "y_optimal = m_demo_optimal * x_line + b_demo_optimal\n",
    "\n",
    "plt.plot(x_line, y_start, 'b:', linewidth=3, alpha=0.7,\n",
    "         label=f'Start: y = {START_M}x + {START_B} (MSE={comparison_data[\"MSE\"][0]:.4f})')\n",
    "plt.plot(x_line, y_gradient, 'g--', linewidth=3, \n",
    "         label=f'Gradientenabstieg: y = {final_m:.4f}x + {final_b:.4f} (MSE={final_mse:.4f})')\n",
    "plt.plot(x_line, y_optimal, 'r-', linewidth=3, alpha=0.8,\n",
    "         label=f'Optimal: y = {m_demo_optimal:.4f}x + {b_demo_optimal:.4f} (MSE={mse_demo_optimal:.4f})')\n",
    "\n",
    "plt.xlabel('Au√üentemperatur (¬∞C)', fontweight='bold')\n",
    "plt.ylabel('Energieverbrauch (kWh/h)', fontweight='bold')\n",
    "plt.title('Gradientenabstieg vs. Analytische L√∂sung', fontweight='bold', fontsize=14)\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xlim(5, 40)\n",
    "plt.ylim(10, 30)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Erfolgsauswertung\n",
    "if abs(final_mse - mse_demo_optimal) < 0.001:\n",
    "    print(\"\\nüéâ PERFEKTER ERFOLG! Gradientenabstieg hat die optimale L√∂sung gefunden!\")\n",
    "    print(\"üí° Der Computer kann automatisch die beste Gerade durch die Punkte finden!\")\n",
    "elif abs(final_mse - mse_demo_optimal) < 0.01:\n",
    "    print(\"\\n‚úÖ SEHR GUTER ERFOLG! Gradientenabstieg ist sehr nah an der optimalen L√∂sung!\")\n",
    "    print(\"üí° Mit mehr Iterationen oder angepasster Lernrate w√§re perfekte Konvergenz m√∂glich!\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Bitte Lernrate anpassen! Aktuell noch nicht optimal konvergiert.\")\n",
    "    print(\"üí° Versuchen Sie verschiedene Lernraten in der vorherigen Zelle!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lecture_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
