{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65adeae7",
   "metadata": {},
   "source": [
    "# Cluster in Residuen - Das verr√§terische Muster\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/klar74/WS2025_lecture/blob/main/Vorlesung_12/cluster_in_residuen_demo.ipynb)\n",
    "\n",
    "**Lernziel:** Verstehen, wie fehlende kategoriale Variablen zu Clustern in Residuenplots f√ºhren und warum das ein starkes Indiz f√ºr Modellverbesserungen ist.\n",
    "\n",
    "**Aus VL12:** Cluster-Muster in Residuenplots zeigen getrennte Gruppen von Datenpunkten und sind ein starkes Indiz f√ºr eine **fehlende kategoriale Variable** im Modell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff128c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import seaborn as sns\n",
    "\n",
    "# Stil f√ºr bessere Plots\n",
    "plt.style.use('default')\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"‚úì Bibliotheken erfolgreich importiert\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840f6b50",
   "metadata": {},
   "source": [
    "## Szenario: Geh√§lter basierend auf Berufserfahrung\n",
    "\n",
    "**Das Problem:** Wir modellieren Geh√§lter nur mit \"Jahren Berufserfahrung\", ignorieren aber \"Ausbildungsniveau\".\n",
    "\n",
    "**Was passiert:** Es entstehen zwei getrennte Gruppen (Cluster) in den Residuen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c24bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulierte Gehaltsdaten mit versteckter kategorialer Variable\n",
    "n_samples = 200\n",
    "\n",
    "# Berufserfahrung (Jahre)\n",
    "years_experience = np.random.uniform(0, 20, n_samples)\n",
    "\n",
    "# Kategoriale Variable: Ausbildung (50% ohne Studium, 50% mit Studium)\n",
    "education = np.random.choice(['Ohne Studium', 'Mit Studium'], n_samples, p=[0.5, 0.5])\n",
    "\n",
    "# ZWEI GETRENNTE LINIEN: Verschiedene Grundgeh√§lter je nach Ausbildung\n",
    "salary = np.where(\n",
    "    education == 'Ohne Studium',\n",
    "    35000 + 1500 * years_experience + np.random.normal(0, 3000, n_samples),  # Niedrigeres Grundgehalt\n",
    "    55000 + 2500 * years_experience + np.random.normal(0, 4000, n_samples)   # H√∂heres Grundgehalt\n",
    ")\n",
    "\n",
    "# DataFrame erstellen\n",
    "df = pd.DataFrame({\n",
    "    'years_experience': years_experience,\n",
    "    'education': education,\n",
    "    'salary': salary\n",
    "})\n",
    "\n",
    "print(f\"Datensatz erstellt: {len(df)} Personen\")\n",
    "print(f\"Ausbildungsverteilung:\")\n",
    "print(df['education'].value_counts())\n",
    "print(f\"\\nDurchschnittsgeh√§lter:\")\n",
    "print(df.groupby('education')['salary'].mean().round(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4916ae75",
   "metadata": {},
   "source": [
    "## In den Daten \"stecken zwei Linien\"\n",
    "\n",
    "Schauen wir uns die Daten zuerst an, **bevor** wir das problematische Modell bauen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c08b32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisierung: Die \"zwei getrennten Linien\" sichtbar machen\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Daten nach Ausbildung getrennt plotten\n",
    "for education_level in df['education'].unique():\n",
    "    data = df[df['education'] == education_level]\n",
    "    color = 'blue' if education_level == 'Ohne Studium' else 'red'\n",
    "    \n",
    "    plt.scatter(data['years_experience'], data['salary'], \n",
    "               alpha=0.6, color=color, s=50, label=education_level)\n",
    "    \n",
    "    # Trendlinie f√ºr jede Gruppe\n",
    "    z = np.polyfit(data['years_experience'], data['salary'], 1)\n",
    "    p = np.poly1d(z)\n",
    "    x_trend = np.linspace(data['years_experience'].min(), data['years_experience'].max(), 100)\n",
    "    plt.plot(x_trend, p(x_trend), color=color, linewidth=3, alpha=0.8)\n",
    "\n",
    "plt.xlabel('Jahre Berufserfahrung')\n",
    "plt.ylabel('Gehalt (‚Ç¨)')\n",
    "plt.title('ZWEI GETRENNTE LINIEN: Gehalt vs. Berufserfahrung\\n(nach Ausbildung getrennt dargestellt)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Annotationen\n",
    "plt.annotate('H√∂here Linie:\\nMit Studium', xy=(15, 95000), xytext=(12, 105000),\n",
    "            arrowprops=dict(arrowstyle='->', color='red'),\n",
    "            fontsize=12, color='red', weight='bold')\n",
    "\n",
    "plt.annotate('Niedrigere Linie:\\nOhne Studium', xy=(15, 65000), xytext=(5, 50000),\n",
    "            arrowprops=dict(arrowstyle='->', color='blue'),\n",
    "            fontsize=12, color='blue', weight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üìä ERKL√ÑRUNG DER 'ZWEI GETRENNTEN LINIEN':\")\n",
    "print(\"‚Ä¢ Blaue Linie: Ohne Studium - niedrigeres Grundgehalt, langsamerer Anstieg\")\n",
    "print(\"‚Ä¢ Rote Linie: Mit Studium - h√∂heres Grundgehalt, steilerer Anstieg\")\n",
    "print(\"‚Ä¢ Beide Gruppen folgen linearen Trends, aber mit verschiedenen Parametern\")\n",
    "print(\"‚Ä¢ Ein einfaches Modell 'sieht' nur eine Mischung aus beiden Gruppen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28884c51",
   "metadata": {},
   "source": [
    "## Problematisches Modell: Ohne kategoriale Variable\n",
    "\n",
    "Jetzt modellieren wir **nur** mit Berufserfahrung und ignorieren die Ausbildung:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5dc095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCHLECHTES MODELL: Nur Berufserfahrung, Ausbildung ignoriert\n",
    "X_bad = df[['years_experience']]  # Nur eine Variable!\n",
    "y = df['salary']\n",
    "\n",
    "# Lineares Modell trainieren\n",
    "model_bad = LinearRegression()\n",
    "model_bad.fit(X_bad, y)\n",
    "\n",
    "# Vorhersagen und Residuen berechnen\n",
    "y_pred_bad = model_bad.predict(X_bad)\n",
    "residuals_bad = y - y_pred_bad\n",
    "\n",
    "print(\"üö® SCHLECHTES MODELL (ohne Ausbildung):\")\n",
    "print(f\"R¬≤ Score: {model_bad.score(X_bad, y):.3f}\")\n",
    "print(f\"Mittlerer absoluter Fehler: {np.mean(np.abs(residuals_bad)):.0f} ‚Ç¨\")\n",
    "print(f\"Modell: Gehalt = {model_bad.intercept_:.0f} + {model_bad.coef_[0]:.0f} √ó Jahre\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bec2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisierung des schlechten Modells\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Links: Modell-Fit\n",
    "ax1.scatter(df['years_experience'], df['salary'], alpha=0.6, color='gray', s=30)\n",
    "x_line = np.linspace(0, 20, 100)\n",
    "y_line = model_bad.intercept_ + model_bad.coef_[0] * x_line\n",
    "ax1.plot(x_line, y_line, color='green', linewidth=3, label='Einfache Regressionslinie')\n",
    "\n",
    "ax1.set_xlabel('Jahre Berufserfahrung')\n",
    "ax1.set_ylabel('Gehalt (‚Ç¨)')\n",
    "ax1.set_title('Schlechtes Modell: Eine Linie f√ºr alle\\n(Ignoriert Ausbildungsunterschiede)')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Rechts: RESIDUENPLOT - Hier sehen wir die Cluster!\n",
    "colors = ['blue' if edu == 'Ohne Studium' else 'red' for edu in df['education']]\n",
    "ax2.scatter(y_pred_bad, residuals_bad, c=colors, alpha=0.7, s=40)\n",
    "ax2.axhline(y=0, color='black', linestyle='--', alpha=0.8)\n",
    "ax2.set_xlabel('Vorhersage (‚Ç¨)')\n",
    "ax2.set_ylabel('Residuen (‚Ç¨)')\n",
    "ax2.set_title('üö® CLUSTER IN RESIDUEN!\\n(Verr√§terisches Muster)')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Legende f√ºr Residuenplot\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [Patch(facecolor='blue', label='Ohne Studium'),\n",
    "                   Patch(facecolor='red', label='Mit Studium')]\n",
    "ax2.legend(handles=legend_elements)\n",
    "\n",
    "# Cluster markieren\n",
    "ax2.annotate('Cluster 1:\\nNegative Residuen\\n(Ohne Studium)', \n",
    "            xy=(60000, -15000), xytext=(45000, -25000),\n",
    "            arrowprops=dict(arrowstyle='->', color='blue'),\n",
    "            fontsize=10, color='blue', weight='bold')\n",
    "\n",
    "ax2.annotate('Cluster 2:\\nPositive Residuen\\n(Mit Studium)', \n",
    "            xy=(80000, 20000), xytext=(95000, 30000),\n",
    "            arrowprops=dict(arrowstyle='->', color='red'),\n",
    "            fontsize=10, color='red', weight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üîç WAS SEHEN WIR IM RESIDUENPLOT?\")\n",
    "print(\"‚Ä¢ CLUSTER 1 (blau): Systematisch negative Residuen ‚Üí Modell √ºbersch√§tzt\")\n",
    "print(\"‚Ä¢ CLUSTER 2 (rot): Systematisch positive Residuen ‚Üí Modell untersch√§tzt\")\n",
    "print(\"‚Ä¢ Die Cluster entsprechen den Ausbildungsgruppen!\")\n",
    "print(\"‚Ä¢ Das ist das 'verr√§terische Muster' - es verr√§t die fehlende Variable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e0309d",
   "metadata": {},
   "source": [
    "## L√∂sung: Dummy-Variablen hinzuf√ºgen\n",
    "\n",
    "Jetzt f√ºgen wir die fehlende kategoriale Variable als **Dummy-Variable** hinzu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c0aa41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GUTES MODELL: Mit Dummy-Variable f√ºr Ausbildung\n",
    "df_with_dummy = df.copy()\n",
    "\n",
    "# Dummy-Variable erstellen (One-Hot-Encoding)\n",
    "df_with_dummy['ist_studium'] = (df['education'] == 'Mit Studium').astype(int)\n",
    "\n",
    "print(\"üìä DUMMY-VARIABLE ERKL√ÑRT:\")\n",
    "print(\"Original kategoriale Variable:\")\n",
    "print(df[['education']].head())\n",
    "print(\"\\nAls Dummy-Variable:\")\n",
    "print(df_with_dummy[['education', 'ist_studium']].head())\n",
    "print(\"\\n‚Ä¢ ist_studium = 1 ‚Üí Mit Studium\")\n",
    "print(\"‚Ä¢ ist_studium = 0 ‚Üí Ohne Studium (Referenzkategorie)\")\n",
    "\n",
    "# Neues Modell mit beiden Variablen\n",
    "X_good = df_with_dummy[['years_experience', 'ist_studium']]\n",
    "model_good = LinearRegression()\n",
    "model_good.fit(X_good, y)\n",
    "\n",
    "# Vorhersagen und Residuen\n",
    "y_pred_good = model_good.predict(X_good)\n",
    "residuals_good = y - y_pred_good\n",
    "\n",
    "print(f\"\\n‚úÖ GUTES MODELL (mit Ausbildung):\")\n",
    "print(f\"R¬≤ Score: {model_good.score(X_good, y):.3f}\")\n",
    "print(f\"Mittlerer absoluter Fehler: {np.mean(np.abs(residuals_good)):.0f} ‚Ç¨\")\n",
    "print(f\"\\nModell-Gleichung:\")\n",
    "print(f\"Gehalt = {model_good.intercept_:.0f} + {model_good.coef_[0]:.0f} √ó Jahre + {model_good.coef_[1]:.0f} √ó ist_studium\")\n",
    "print(f\"\\nInterpretation:\")\n",
    "print(f\"‚Ä¢ Grundgehalt ohne Studium: {model_good.intercept_:.0f} ‚Ç¨\")\n",
    "print(f\"‚Ä¢ Gehaltssteigerung pro Jahr: {model_good.coef_[0]:.0f} ‚Ç¨\")\n",
    "print(f\"‚Ä¢ Studiums-Bonus: {model_good.coef_[1]:.0f} ‚Ç¨ extra\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b251f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vergleich: Residuenplots vorher vs. nachher\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 7))\n",
    "\n",
    "# Links: Schlechtes Modell (mit Clustern)\n",
    "colors = ['blue' if edu == 'Ohne Studium' else 'red' for edu in df['education']]\n",
    "ax1.scatter(y_pred_bad, residuals_bad, c=colors, alpha=0.7, s=40)\n",
    "ax1.axhline(y=0, color='black', linestyle='--', alpha=0.8)\n",
    "ax1.set_xlabel('Vorhersage (‚Ç¨)')\n",
    "ax1.set_ylabel('Residuen (‚Ç¨)')\n",
    "ax1.set_title('üö® VORHER: Cluster-Muster\\n(Fehlende Variable)')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_ylim(-30000, 30000)\n",
    "\n",
    "# Cluster hervorheben\n",
    "#from matplotlib.patches import Ellipse\n",
    "#ellipse1 = Ellipse((65000, -12000), 20000, 18000, alpha=0.2, color='blue')\n",
    "#ellipse2 = Ellipse((75000, 15000), 25000, 20000, alpha=0.2, color='red')\n",
    "#ax1.add_patch(ellipse1)\n",
    "#ax1.add_patch(ellipse2)\n",
    "ax1.text(65000, -12000, 'Cluster 1', ha='center', va='center', weight='bold', color='blue')\n",
    "ax1.text(75000, 15000, 'Cluster 2', ha='center', va='center', weight='bold', color='red')\n",
    "\n",
    "# Rechts: Gutes Modell (ohne Cluster)\n",
    "ax2.scatter(y_pred_good, residuals_good, c=colors, alpha=0.7, s=40)\n",
    "ax2.axhline(y=0, color='black', linestyle='--', alpha=0.8)\n",
    "ax2.set_xlabel('Vorhersage (‚Ç¨)')\n",
    "ax2.set_ylabel('Residuen (‚Ç¨)')\n",
    "ax2.set_title('‚úÖ NACHHER: Zuf√§llige Streuung\\n(Mit Dummy-Variable)')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.set_ylim(-30000, 30000)\n",
    "\n",
    "# Legende\n",
    "legend_elements = [Patch(facecolor='blue', label='Ohne Studium'),\n",
    "                   Patch(facecolor='red', label='Mit Studium')]\n",
    "ax1.legend(handles=legend_elements, loc='upper left')\n",
    "ax2.legend(handles=legend_elements, loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üéØ VERBESSERUNG DURCH DUMMY-VARIABLEN:\")\n",
    "print(f\"‚Ä¢ R¬≤ vorher: {model_bad.score(X_bad, y):.3f} ‚Üí nachher: {model_good.score(X_good, y):.3f}\")\n",
    "print(f\"‚Ä¢ Fehler vorher: {np.mean(np.abs(residuals_bad)):.0f}‚Ç¨ ‚Üí nachher: {np.mean(np.abs(residuals_good)):.0f}‚Ç¨\")\n",
    "print(f\"‚Ä¢ Cluster verschwunden: Residuen jetzt zuf√§llig um 0 verteilt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d9b4a1",
   "metadata": {},
   "source": [
    "## Warum funktionieren Dummy-Variablen?\n",
    "\n",
    "Das Modell lernt jetzt **separate Grundniveaus** f√ºr jede Kategorie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696d0e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisierung: Wie das gute Modell funktioniert\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Daten nach Ausbildung plotten\n",
    "for education_level in df['education'].unique():\n",
    "    data = df[df['education'] == education_level]\n",
    "    color = 'blue' if education_level == 'Ohne Studium' else 'red'\n",
    "    \n",
    "    plt.scatter(data['years_experience'], data['salary'], \n",
    "               alpha=0.6, color=color, s=50, label=f'{education_level} (Daten)')\n",
    "\n",
    "# Modell-Vorhersagen f√ºr beide Gruppen\n",
    "x_range = np.linspace(0, 20, 100)\n",
    "\n",
    "# F√ºr \"Ohne Studium\" (ist_studium = 0)\n",
    "X_ohne = np.column_stack([x_range, np.zeros(len(x_range))])\n",
    "y_ohne = model_good.predict(X_ohne)\n",
    "plt.plot(x_range, y_ohne, color='blue', linewidth=3, linestyle='--', \n",
    "         label='Modell: Ohne Studium')\n",
    "\n",
    "# F√ºr \"Mit Studium\" (ist_studium = 1)\n",
    "X_mit = np.column_stack([x_range, np.ones(len(x_range))])\n",
    "y_mit = model_good.predict(X_mit)\n",
    "plt.plot(x_range, y_mit, color='red', linewidth=3, linestyle='--', \n",
    "         label='Modell: Mit Studium')\n",
    "\n",
    "plt.xlabel('Jahre Berufserfahrung')\n",
    "plt.ylabel('Gehalt (‚Ç¨)')\n",
    "plt.title('‚úÖ Gutes Modell: Separate Linien durch Dummy-Variablen\\nModell lernt verschiedene Grundniveaus')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Annotationen der Unterschiede\n",
    "#plt.annotate(f'Studiums-Bonus:\\n{model_good.coef_[1]:.0f} ‚Ç¨ extra', \n",
    "#            xy=(10, 80000), xytext=(15, 90000),\n",
    "#            arrowprops=dict(arrowstyle='<->', color='green', lw=2),\n",
    "#            fontsize=12, color='green', weight='bold',\n",
    "#            bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üß† WIE DUMMY-VARIABLEN FUNKTIONIEREN:\")\n",
    "print(\"\\nDas Modell berechnet:\")\n",
    "print(f\"‚Ä¢ Ohne Studium: Gehalt = {model_good.intercept_:.0f} + {model_good.coef_[0]:.0f} √ó Jahre + {model_good.coef_[1]:.0f} √ó 0\")\n",
    "print(f\"                      = {model_good.intercept_:.0f} + {model_good.coef_[0]:.0f} √ó Jahre\")\n",
    "print(f\"\\n‚Ä¢ Mit Studium:  Gehalt = {model_good.intercept_:.0f} + {model_good.coef_[0]:.0f} √ó Jahre + {model_good.coef_[1]:.0f} √ó 1\")\n",
    "print(f\"                      = {model_good.intercept_ + model_good.coef_[1]:.0f} + {model_good.coef_[0]:.0f} √ó Jahre\")\n",
    "print(f\"\\n‚ûú Zwei parallele Linien mit {model_good.coef_[1]:.0f}‚Ç¨ Abstand\")\n",
    "print(f\"‚ûú Systematische Gruppenunterschiede werden erkl√§rt\")\n",
    "print(f\"‚ûú Residuen werden zuf√§llig ‚Üí Cluster verschwinden\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4ea816",
   "metadata": {},
   "source": [
    "## Zusammenfassung: Cluster als Diagnosewerkzeug\n",
    "\n",
    "**Was wir gelernt haben:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f382426",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üéØ CLUSTER IN RESIDUEN - ZUSAMMENFASSUNG:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"\\nüîç WAS SIND CLUSTER IN RESIDUEN?\")\n",
    "print(\"‚Ä¢ Getrennte Gruppen von Datenpunkten im Residuenplot\")\n",
    "print(\"‚Ä¢ Ein Cluster systematisch √ºber 0, der andere systematisch unter 0\")\n",
    "print(\"‚Ä¢ Zeigen, dass das Modell verschiedene Gruppen unterschiedlich behandelt\")\n",
    "\n",
    "print(\"\\n‚ùì WAS BEDEUTEN 'ZWEI GETRENNTE LINIEN'?\")\n",
    "print(\"‚Ä¢ Verschiedene Gruppen folgen verschiedenen linearen Beziehungen\")\n",
    "print(\"‚Ä¢ Unterschiedliche Grundniveaus (Achsenabschnitte)\")\n",
    "print(\"‚Ä¢ Eventuell auch unterschiedliche Steigungen\")\n",
    "print(\"‚Ä¢ Ein einfaches Modell 'sieht' nur den Durchschnitt aus beiden\")\n",
    "\n",
    "print(\"\\nüö® WANN ENTSTEHEN CLUSTER?\")\n",
    "print(\"‚Ä¢ Fehlende kategoriale Variable im Modell\")\n",
    "print(\"‚Ä¢ Das Modell kann systematische Gruppenunterschiede nicht erkl√§ren\")\n",
    "print(\"‚Ä¢ Residuen zeigen die '√ºbrig gebliebene' Gruppenstruktur\")\n",
    "\n",
    "print(\"\\n‚úÖ WIE L√ñST MAN DAS PROBLEM?\")\n",
    "print(\"‚Ä¢ Dummy-Variablen f√ºr kategoriale Features hinzuf√ºgen\")\n",
    "print(\"‚Ä¢ One-Hot-Encoding: Text ‚Üí bin√§re Zahlen (0/1)\")\n",
    "print(\"‚Ä¢ Modell lernt separate Grundniveaus f√ºr jede Kategorie\")\n",
    "print(\"‚Ä¢ Cluster verschwinden ‚Üí zuf√§llige Residuen um 0\")\n",
    "\n",
    "print(\"\\nüéì PRAKTISCHE ANWENDUNG:\")\n",
    "print(\"‚Ä¢ Residuenplot nach kategorialen Variablen f√§rben\")\n",
    "print(\"‚Ä¢ Cluster = Hinweis auf vergessene kategoriale Variable\")\n",
    "print(\"‚Ä¢ Systematische Verbesserung statt zuf√§lliges Probieren\")\n",
    "print(\"‚Ä¢ Modell-Diagnostik ist wichtiger als Algorithmus-Optimierung!\")\n",
    "\n",
    "print(\"\\nüí° MERKSATZ:\")\n",
    "print('\"Cluster in Residuen verraten fehlende kategoriale Variablen\"')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lecture_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
