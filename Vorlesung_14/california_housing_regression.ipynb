{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4c24253",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/klar74/WS2025_lecture/blob/main/Vorlesung_14/california_housing_regression.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec9bb62",
   "metadata": {},
   "source": [
    "# California Housing - Lineare Regression\n",
    "\n",
    "Dieses Notebook führt euch durch eine komplette Machine Learning Pipeline mit dem California Housing Datensatz.\n",
    "\n",
    "## Was wir machen:\n",
    "1. **Daten laden** und verstehen\n",
    "2. **Train/Test Split** für ehrliche Evaluierung  \n",
    "3. **Lineares Modell** trainieren\n",
    "4. **Performance bewerten** mit Metriken\n",
    "5. **Ergebnisse visualisieren** mit Grafiken\n",
    "\n",
    "Wir führen das zwei Mal durch, erst auf unbereinigten Originaldaten, dann auf bereinigten Daten, und vergleichen die beiden Ergebnisse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f41829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schritt 1: Bibliotheken importieren\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "print(\"Alle Bibliotheken erfolgreich importiert!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf8bf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schritt 2: Daten laden\n",
    "print(\"Lade California Housing Datensatz...\")\n",
    "california = fetch_california_housing()\n",
    "\n",
    "# Als pandas DataFrame für bessere Handhabung\n",
    "X = pd.DataFrame(california.data, columns=california.feature_names)\n",
    "y = pd.Series(california.target, name='HouseValue')\n",
    "\n",
    "print(f\"Datensatz geladen: {X.shape[0]} Regionen, {X.shape[1]} Features\")\n",
    "print(f\"Features: {list(california.feature_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f9be39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schritt 3: Daten verstehen\n",
    "print(\"Erste 5 Datensaetze:\")\n",
    "display(X.head())\n",
    "\n",
    "print(f\"\\nHauspreise - Erste 5 Werte:\")\n",
    "print(y.head().values)\n",
    "\n",
    "print(f\"\\nPreis-Statistiken:\")\n",
    "print(f\"   Durchschnitt: ${y.mean():.2f} (x100k) = ${y.mean()*100:.0f}k\")\n",
    "print(f\"   Minimum: ${y.min():.2f} (x100k) = ${y.min()*100:.0f}k\")  \n",
    "print(f\"   Maximum: ${y.max():.2f} (x100k) = ${y.max()*100:.0f}k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ccd5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schritt 3b: Dataset-Eigenart verstehen - Preiskappung bei $500k\n",
    "print(\"WICHTIGER HINWEIS - Dataset-Eigenart:\")\n",
    "print(f\"   Maximum im Dataset: ${y.max():.5f} (x100k) = ${y.max()*100:.0f}k\")\n",
    "\n",
    "# Korrekte Analyse: 5.0 UND 5.00001 sind beide gekappte Werte\n",
    "capped_at_500k = np.sum(y >= 5.0)\n",
    "\n",
    "print(f\"   Werte bei genau $500.000k: {capped_at_500k}\")\n",
    "print(f\"   Werte >= $490k und < $500k: {np.sum((y >= 4.9) & (y < 5.0))} von {len(y)} ({np.sum((y >= 4.9) & (y < 5.0))/len(y)*100:.1f}%)\")\n",
    "\n",
    "# Visualisierung des Kappungseffekts\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(y, bins=50, alpha=0.7, edgecolor='black')\n",
    "plt.axvline(5.00001, color='red', linestyle='--', linewidth=2, alpha=0.7, label='Kappung bei $500k (992 Häuser)')\n",
    "plt.xlabel('Hauswerte (x100k $)')\n",
    "plt.ylabel('Haeufigkeit')\n",
    "plt.title('Verteilung der Hauswerte mit Kappung bei $500.000')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nQUELLEN & HINTERGRUND:\")\n",
    "print(f\"   Original-Studie: Pace & Barry (1997), Statistics and Probability Letters\")\n",
    "print(f\"   Datenquelle: US Census 1990, California Block Groups\")\n",
    "print(f\"   Preprocessing: Haeuser >$500k wurden auf $500k 'gekappt'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f779baa",
   "metadata": {},
   "source": [
    "## Modell trainieren mit dem unbereinigten Originaldatensatz\n",
    "\n",
    "**Multiple Lineare Regression:**\n",
    "\n",
    "Die mathematische Formel für multiple lineare Regression lautet:\n",
    "\n",
    "$$\\hat{y} = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + ... + \\beta_p x_p$$\n",
    "\n",
    "**Für den California Housing Datensatz:**\n",
    "$$\\text{HouseValue} = \\beta_0 + \\beta_1 \\cdot \\text{MedInc} + \\beta_2 \\cdot \\text{HouseAge} + \\beta_3 \\cdot \\text{AveRooms} + \\beta_4 \\cdot \\text{AveBedrms} + \\beta_5 \\cdot \\text{Population} + \\beta_6 \\cdot \\text{AveOccup} + \\beta_7 \\cdot \\text{Latitude} + \\beta_8 \\cdot \\text{Longitude}$$\n",
    "\n",
    "**Wobei:**\n",
    "- $\\hat{y}$ = vorhergesagter Hauswert (×100k $)\n",
    "- $\\beta_0$ = Intercept (Basis-Hauspreis)\n",
    "- $\\beta_1, ..., \\beta_8$ = Koeffizienten für die 8 Features\n",
    "- $x_1, ..., x_8$ = die 8 Features (MedInc, HouseAge, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7894589b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schritt 4: Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2,      # 20% für Test\n",
    "    random_state=42     # Für reproduzierbare Ergebnisse\n",
    ")\n",
    "\n",
    "print(f\"Training: {X_train.shape[0]} Regionen\")\n",
    "print(f\"Test: {X_test.shape[0]} Regionen\")\n",
    "print(f\"Verhaeltnis: {X_train.shape[0]/X_test.shape[0]:.1f}:1 (Train:Test)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b19b106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schritt 4b: Feature-Skalierung (Optional)\n",
    "# StandardScaler normalisiert Features auf Mittelwert=0, Standardabweichung=1\n",
    "# Das kann bei linearer Regression helfen, wenn Features sehr unterschiedliche Skalen haben\n",
    "\n",
    "USE_SCALING = True  # Setze auf True, um Skalierung zu aktivieren\n",
    "\n",
    "if USE_SCALING:\n",
    "    print(\"Skaliere Features mit StandardScaler...\")\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    # Scaler nur auf Trainingsdaten fitten (wichtig für ehrliche Evaluierung!)\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Zurück zu DataFrame für bessere Lesbarkeit\n",
    "    X_train = pd.DataFrame(X_train_scaled, columns=X.columns, index=X_train.index)\n",
    "    X_test = pd.DataFrame(X_test_scaled, columns=X.columns, index=X_test.index)\n",
    "    \n",
    "    print(\"Feature-Skalierung abgeschlossen!\")\n",
    "    print(f\"   Beispiel - Durchschnitt nach Skalierung: {X_train.mean().round(3).values}\")\n",
    "    print(f\"   Beispiel - Std nach Skalierung: {X_train.std().round(3).values}\")\n",
    "else:\n",
    "    print(\"Feature-Skalierung übersprungen (USE_SCALING = False)\")\n",
    "    print(\"   Hinweis: Lineare Regression funktioniert oft auch ohne Skalierung gut\")\n",
    "    print(\"   Bei großen Unterschieden in Feature-Skalen kann Skalierung helfen.\")\n",
    "    print(\"   Bei Interpretation der Koeffizienten ist Skalierung wichtig.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35149b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schritt 5: Modell trainieren\n",
    "model = LinearRegression()\n",
    "\n",
    "print(\"Trainiere das Modell...\")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Modell trainiert!\")\n",
    "print(f\"Basis-Hauspreis: ${model.intercept_:.2f} (x100k)\")\n",
    "\n",
    "# Die wichtigsten Features zeigen\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Koeffizient': model.coef_\n",
    "}).sort_values('Koeffizient', key=abs, ascending=False)\n",
    "\n",
    "print(f\"\\nTop 5 wichtigste Features:\")\n",
    "for i, (_, row) in enumerate(feature_importance.head().iterrows(), 1):\n",
    "    print(f\"   {i}. {row['Feature']}: {row['Koeffizient']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5090a214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schritt 6: Vorhersagen und Bewertung\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Performance-Metriken berechnen\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Modell-Performance:\")\n",
    "print(f\"   MSE:  {mse:.2f} x(100k$)^2 Durchschnittsfehler\")\n",
    "print(f\"   RMSE: {rmse:.2f} (x100k$) = ${rmse*100:.0f}k Durchschnittsfehler\")  \n",
    "print(f\"   R-Quadrat-Score: {r2:.3f} = {r2*100:.1f}% der Variation erklaert\")\n",
    "\n",
    "# Beispiel-Vorhersagen zeigen\n",
    "print(f\"\\nBeispiel-Vorhersagen:\")\n",
    "for i in range(5):\n",
    "    actual = y_test.iloc[i] * 100  # In Einheiten 100k umrechnen\n",
    "    predicted = y_pred[i] * 100\n",
    "    error = abs(actual - predicted)\n",
    "    print(f\"   Tatsächlich: ${actual:.0f}k, Vorhersage: ${predicted:.0f}k, Fehler: ${error:.0f}k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5faf950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schritt 7: Ergebnisse visualisieren\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Grafik 1: Vorhersage vs. Realität\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(y_test, y_pred, alpha=0.6, s=30)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2, label='Ideale Linie (y = ŷ)')\n",
    "plt.xlabel('Tatsaechliche Preise (x100k $)')\n",
    "plt.ylabel('Vorhergesagte Preise (x100k $)')\n",
    "plt.title('Vorhersage vs. Realitaet')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Grafik 2: Fehler-Verteilung\n",
    "plt.subplot(1, 2, 2)\n",
    "errors = (y_test - y_pred) * 100  # In 100k Dollar\n",
    "plt.hist(errors, bins=50, alpha=0.7, edgecolor='black', color='orange')\n",
    "plt.xlabel('Vorhersagefehler (100k $)')\n",
    "plt.ylabel('Haeufigkeit')\n",
    "plt.title('Verteilung der Vorhersagefehler')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.axvline(0, color='red', linestyle='--', alpha=0.8, label='Kein Fehler')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Durchschnittlicher Absolut-Fehler: ${np.mean(np.abs(errors)):.0f}k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e906f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schritt 8: Residuenplot - Analyse der Vorhersagefehler\n",
    "plt.figure(figsize=(10, 6))\n",
    "residuals = y_test - y_pred\n",
    "plt.scatter(y_pred, residuals, alpha=0.6, s=30, color='blue')\n",
    "plt.axhline(y=0, color='red', linestyle='--', linewidth=2, label='Ideale Linie (Residuen = 0)')\n",
    "plt.xlabel('Vorhergesagte Preise (x100k $)')\n",
    "plt.ylabel('Residuen (x100k $)')\n",
    "plt.title('Residuen vs. Vorhersagewerte')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(\"RESIDUENANALYSE:\")\n",
    "print(f\"   Mittelwert der Residuen: {np.mean(residuals):.6f} (sollte ca. 0 sein)\")\n",
    "print(f\"   Standardabweichung: {np.std(residuals):.4f}\")\n",
    "print(f\"   Min/Max Residuen: {np.min(residuals):.2f} / {np.max(residuals):.2f}\")\n",
    "print(\"\\nINTERPRETATION:\")\n",
    "print(\"   Gute Modelle: Residuen zufaellig um 0 verteilt\")\n",
    "print(\"   Probleme: Systematische Muster in den Residuen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9648b18a",
   "metadata": {},
   "source": [
    "## Vergleichsanalyse: Bereinigter Datensatz\n",
    "\n",
    "**Experiment:** Was passiert, wenn wir die gekappten Werte entfernen?\n",
    "- Entfernen aller Häuser mit Werten >= $500k\n",
    "- Auch das ist nicht optimal, da es den Datensatz durch das komplette Fehlen der höchsten Preise auchv verzerrt\n",
    "- Gleiche Analyse durchfuehren\n",
    "- Vergleich der Modell-Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ba312b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schritt 9: Bereinigten Datensatz erstellen\n",
    "print(\"Erstelle bereinigten Datensatz...\")\n",
    "\n",
    "# Originaldaten sichern\n",
    "X_original = X.copy()\n",
    "y_original = y.copy()\n",
    "\n",
    "# Filter: Entferne alle Werte >= 5.0 (entspricht $500k)\n",
    "clean_mask = y < 5.0\n",
    "X_clean = X[clean_mask].copy()\n",
    "y_clean = y[clean_mask].copy()\n",
    "\n",
    "print(f\"DATENSATZ-VERGLEICH:\")\n",
    "print(f\"   Original: {len(y_original)} Regionen\")\n",
    "print(f\"   Bereinigt: {len(y_clean)} Regionen\")\n",
    "print(f\"   Entfernt: {len(y_original) - len(y_clean)} gekappte Haeuser ({(len(y_original) - len(y_clean))/len(y_original)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nPREIS-STATISTIKEN BEREINIGT:\")\n",
    "print(f\"   Durchschnitt: ${y_clean.mean():.2f} (x100k) = ${y_clean.mean()*100:.0f}k\")\n",
    "print(f\"   Minimum: ${y_clean.min():.2f} (x100k) = ${y_clean.min()*100:.0f}k\")  \n",
    "print(f\"   Maximum: ${y_clean.max():.2f} (x100k) = ${y_clean.max()*100:.0f}k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c9f473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schritt 9b: Feature-Skalierung für bereinigten Datensatz (Optional)\n",
    "# StandardScaler für den bereinigten Datensatz - unabhängig vom Original-Datensatz\n",
    "\n",
    "USE_SCALING_CLEAN = True  # Setze auf True, um Skalierung für bereinigten Datensatz zu aktivieren\n",
    "\n",
    "if USE_SCALING_CLEAN:\n",
    "    print(\"Skaliere Features des bereinigten Datensatzes mit StandardScaler...\")\n",
    "    scaler_clean = StandardScaler()\n",
    "    \n",
    "    # Features vor dem Train/Test Split skalieren\n",
    "    X_clean_scaled = scaler_clean.fit_transform(X_clean)\n",
    "    \n",
    "    # Zurück zu DataFrame für bessere Lesbarkeit\n",
    "    X_clean = pd.DataFrame(X_clean_scaled, columns=X_clean.columns, index=X_clean.index)\n",
    "    \n",
    "    print(\"Feature-Skalierung (bereinigt) abgeschlossen!\")\n",
    "    print(f\"   Durchschnitt nach Skalierung: {X_clean.mean().round(3).values}\")\n",
    "    print(f\"   Std nach Skalierung: {X_clean.std().round(3).values}\")\n",
    "    \n",
    "    print(\"\\nWICHTIG: Bereinigter Datensatz wird separat skaliert!\")\n",
    "    print(\"   Original-Datensatz und bereinigter Datensatz haben unterschiedliche Skalierung\")\n",
    "else:\n",
    "    print(\"Feature-Skalierung für bereinigten Datensatz übersprungen (USE_SCALING_CLEAN = False)\")\n",
    "    print(\"   Hinweis: Für Vergleichbarkeit oft besser, beide Datensätze gleich zu behandeln\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383eb2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schritt 10: Train/Test Split für bereinigten Datensatz\n",
    "X_train_clean, X_test_clean, y_train_clean, y_test_clean = train_test_split(\n",
    "    X_clean, y_clean, \n",
    "    test_size=0.2,      # 20% für Test\n",
    "    random_state=42     # Für reproduzierbare Ergebnisse\n",
    ")\n",
    "\n",
    "print(f\"Training (bereinigt): {X_train_clean.shape[0]} Regionen\")\n",
    "print(f\"Test (bereinigt): {X_test_clean.shape[0]} Regionen\")\n",
    "print(f\"Verhaeltnis: {X_train_clean.shape[0]/X_test_clean.shape[0]:.1f}:1 (Train:Test)\")\n",
    "\n",
    "# Visualisierung: Vergleich der Preisverteilungen\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(y_original, bins=50, alpha=0.7, edgecolor='black', color='red', label='Original')\n",
    "plt.axvline(5.0, color='red', linestyle='--', linewidth=2, label='Kappung bei $500k')\n",
    "plt.xlabel('Hauswerte (x100k $)')\n",
    "plt.ylabel('Haeufigkeit')\n",
    "plt.title('Original Datensatz (mit Kappung)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(y_clean, bins=50, alpha=0.7, edgecolor='black', color='green', label='Bereinigt')\n",
    "plt.xlabel('Hauswerte (x100k $)')\n",
    "plt.ylabel('Haeufigkeit')\n",
    "plt.title('Bereinigter Datensatz (ohne Kappung)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58123f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schritt 11: Modell auf bereinigten Daten trainieren\n",
    "model_clean = LinearRegression()\n",
    "\n",
    "print(\"Trainiere das Modell auf bereinigten Daten...\")\n",
    "model_clean.fit(X_train_clean, y_train_clean)\n",
    "\n",
    "print(f\"Bereinigtes Modell trainiert!\")\n",
    "print(f\"Basis-Hauspreis (bereinigt): ${model_clean.intercept_:.2f} (x100k)\")\n",
    "\n",
    "# Die wichtigsten Features zeigen\n",
    "feature_importance_clean = pd.DataFrame({\n",
    "    'Feature': X_clean.columns,\n",
    "    'Koeffizient_Original': model.coef_,\n",
    "    'Koeffizient_Bereinigt': model_clean.coef_\n",
    "}).sort_values('Koeffizient_Bereinigt', key=abs, ascending=False)\n",
    "\n",
    "print(f\"\\nVergleich der Feature-Wichtigkeit:\")\n",
    "print(f\"{'Feature':<12} {'Original':<10} {'Bereinigt':<10} {'Differenz':<10}\")\n",
    "print(\"-\" * 50)\n",
    "for _, row in feature_importance_clean.head().iterrows():\n",
    "    diff = row['Koeffizient_Bereinigt'] - row['Koeffizient_Original']\n",
    "    print(f\"{row['Feature']:<12} {row['Koeffizient_Original']:<10.3f} {row['Koeffizient_Bereinigt']:<10.3f} {diff:<10.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3aef41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schritt 12: Vorhersagen und Bewertung (bereinigter Datensatz)\n",
    "y_pred_clean = model_clean.predict(X_test_clean)\n",
    "\n",
    "# Performance-Metriken berechnen\n",
    "mse_clean = mean_squared_error(y_test_clean, y_pred_clean)\n",
    "rmse_clean = np.sqrt(mse_clean)\n",
    "r2_clean = r2_score(y_test_clean, y_pred_clean)\n",
    "\n",
    "print(f\"PERFORMANCE-VERGLEICH:\")\n",
    "print(f\"                    Original     Bereinigt    Verbesserung\")\n",
    "print(f\"   RMSE:           ${rmse:.2f}        ${rmse_clean:.2f}       {((rmse-rmse_clean)/rmse*100):+.1f}%\")\n",
    "print(f\"   R-Quadrat-Score:  {r2:.3f}        {r2_clean:.3f}       {((r2_clean-r2)/r2*100):+.1f}%\")\n",
    "\n",
    "# Beispiel-Vorhersagen zeigen\n",
    "print(f\"\\nBeispiel-Vorhersagen (bereinigter Datensatz):\")\n",
    "for i in range(5):\n",
    "    actual = y_test_clean.iloc[i] * 100  # In normale Tausend Dollar umrechnen\n",
    "    predicted = y_pred_clean[i] * 100\n",
    "    error = abs(actual - predicted)\n",
    "    print(f\"   Tatsächlich: ${actual:.0f}k, Vorhersage: ${predicted:.0f}k, Fehler: ${error:.0f}k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a780d1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schritt 13: Visualisierung bereinigter Datensatz\n",
    "plt.figure(figsize=(15, 4))\n",
    "\n",
    "# Grafik 1: Vorhersage vs. Realität (Original)\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.scatter(y_test, y_pred, alpha=0.6, s=30, color='red', label='Original')\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'b--', lw=2)\n",
    "plt.xlabel('Tatsächliche Preise (×100k $)')\n",
    "plt.ylabel('Vorhergesagte Preise (×100k $)')\n",
    "plt.title(f'Original Datensatz\\nR² = {r2:.3f}')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Grafik 2: Vorhersage vs. Realität (Bereinigt)\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.scatter(y_test_clean, y_pred_clean, alpha=0.6, s=30, color='green', label='Bereinigt')\n",
    "plt.plot([y_test_clean.min(), y_test_clean.max()], [y_test_clean.min(), y_test_clean.max()], 'b--', lw=2)\n",
    "plt.xlabel('Tatsächliche Preise (×100k $)')\n",
    "plt.ylabel('Vorhergesagte Preise (×100k $)')\n",
    "plt.title(f'Bereinigter Datensatz\\nR² = {r2_clean:.3f}')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Grafik 3: Fehler-Verteilungen im Vergleich\n",
    "plt.subplot(1, 3, 3)\n",
    "errors_original = (y_test - y_pred) * 100\n",
    "errors_clean = (y_test_clean - y_pred_clean) * 100\n",
    "plt.hist(errors_original, bins=30, alpha=0.5, color='red', label=f'Original (σ={np.std(errors_original):.0f}k)', density=True)\n",
    "plt.hist(errors_clean, bins=30, alpha=0.5, color='green', label=f'Bereinigt (σ={np.std(errors_clean):.0f}k)', density=True)\n",
    "plt.xlabel('Vorhersagefehler (Tausend $)')\n",
    "plt.ylabel('Dichte')\n",
    "plt.title('Fehlerverteilung im Vergleich')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.axvline(0, color='black', linestyle='--', alpha=0.8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Durchschnittlicher Absolut-Fehler:\")\n",
    "print(f\"   Original: ${np.mean(np.abs(errors_original)):.0f}k\")\n",
    "print(f\"   Bereinigt: ${np.mean(np.abs(errors_clean)):.0f}k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b908d99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schritt 14: Residuenplot-Vergleich (Original vs. Bereinigt)\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Residuen berechnen\n",
    "residuals_original = y_test - y_pred\n",
    "residuals_clean = y_test_clean - y_pred_clean\n",
    "\n",
    "# Vergleich der Residuenplots\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(y_pred, residuals_original, alpha=0.6, s=30, color='red')\n",
    "plt.axhline(y=0, color='black', linestyle='--', linewidth=2)\n",
    "plt.xlabel('Vorhergesagte Preise (x100k $)')\n",
    "plt.ylabel('Residuen (x100k $)')\n",
    "plt.title('Residuen Original Datensatz')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(y_pred_clean, residuals_clean, alpha=0.6, s=30, color='green')\n",
    "plt.axhline(y=0, color='black', linestyle='--', linewidth=2)\n",
    "plt.xlabel('Vorhergesagte Preise (x100k $)')\n",
    "plt.ylabel('Residuen (x100k $)')\n",
    "plt.title('Residuen Bereinigter Datensatz')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"RESIDUENANALYSE VERGLEICH:\")\n",
    "print(f\"                         Original        Bereinigt       Verbesserung\")\n",
    "print(f\"   Mittelwert:          {np.mean(residuals_original):8.6f}     {np.mean(residuals_clean):8.6f}     {((np.mean(residuals_clean)-np.mean(residuals_original))/abs(np.mean(residuals_original))*100):+.1f}%\")\n",
    "print(f\"   Standardabweichung:   {np.std(residuals_original):7.4f}      {np.std(residuals_clean):7.4f}      {((np.std(residuals_clean)-np.std(residuals_original))/np.std(residuals_original)*100):+.1f}%\")\n",
    "print(f\"   Min Residuen:        {np.min(residuals_original):8.2f}     {np.min(residuals_clean):8.2f}\")\n",
    "print(f\"   Max Residuen:        {np.max(residuals_clean):8.2f}     {np.max(residuals_clean):8.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08abe636",
   "metadata": {},
   "source": [
    "## Geschafft!\n",
    "\n",
    "**Was wir erreicht haben:**\n",
    "- Komplette ML-Pipeline von Daten bis Vorhersage\n",
    "\n",
    "**Was wir gelernt haben:**\n",
    "- **MedInc** (Einkommen) und **Lage** (Latitude/Longitude) sind wichtige Faktoren fuer Hauspreise\n",
    "- **Lineare Regression** ist ein guter Startpunkt fuer Preisvorhersagen\n",
    "- **Train/Test Split** ist essentiell fuer ehrliche Modell-Bewertung\n",
    "\n",
    "**Wichtige Dataset-Eigenart:**\n",
    "- **Preiskappung bei $500k**: 992 Häuser (4.8%) wurden ursprünglich bei $500k gekappt\n",
    "- **Quellen**: Pace & Barry (1997), \"Sparse Spatial Autoregressions\", Statistics and Probability Letters\n",
    "- **Effekt auf Vorhersagen**: \n",
    "  - Künstliche Häufung bei der Kappungsgrenze verfälscht Vorhersagen\n",
    "\n",
    "**Mögliche nächste Schritte:**\n",
    "- Probiert andere Algorithmen aus (Random Forest, XGBoost)\n",
    "- Feature Engineering: Neue Features aus bestehenden ableiten"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lecture_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
