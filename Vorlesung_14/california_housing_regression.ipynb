{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ec9bb62",
   "metadata": {},
   "source": [
    "# California Housing - Lineare Regression\n",
    "\n",
    "Dieses Notebook f√ºhrt euch durch eine komplette Machine Learning Pipeline mit dem California Housing Datensatz.\n",
    "\n",
    "## Was wir machen:\n",
    "1. **Daten laden** und verstehen\n",
    "2. **Train/Test Split** f√ºr ehrliche Evaluierung  \n",
    "3. **Lineares Modell** trainieren\n",
    "4. **Performance bewerten** mit Metriken\n",
    "5. **Ergebnisse visualisieren** mit Grafiken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f41829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schritt 1: Bibliotheken importieren\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "print(\"Alle Bibliotheken erfolgreich importiert! üéâ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf8bf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schritt 2: Daten laden\n",
    "print(\"Lade California Housing Datensatz...\")\n",
    "california = fetch_california_housing()\n",
    "\n",
    "# Als pandas DataFrame f√ºr bessere Handhabung\n",
    "X = pd.DataFrame(california.data, columns=california.feature_names)\n",
    "y = pd.Series(california.target, name='HouseValue')\n",
    "\n",
    "print(f\"‚úÖ Datensatz geladen: {X.shape[0]} Regionen, {X.shape[1]} Features\")\n",
    "print(f\"üìä Features: {list(california.feature_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f9be39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schritt 3: Daten verstehen\n",
    "print(\"üîç Erste 5 Datens√§tze:\")\n",
    "display(X.head())\n",
    "\n",
    "print(f\"\\nüí∞ Hauspreise - Erste 5 Werte:\")\n",
    "print(y.head().values)\n",
    "\n",
    "print(f\"\\nüìà Preis-Statistiken:\")\n",
    "print(f\"   Durchschnitt: ${y.mean():.2f} (√ó100k) = ${y.mean()*100:.0f}k\")\n",
    "print(f\"   Minimum: ${y.min():.2f} (√ó100k) = ${y.min()*100:.0f}k\")  \n",
    "print(f\"   Maximum: ${y.max():.2f} (√ó100k) = ${y.max()*100:.0f}k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ccd5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schritt 3b: Dataset-Eigenart verstehen - Preiskappung bei $500k\n",
    "print(\"üö® WICHTIGER HINWEIS - Dataset-Eigenart:\")\n",
    "print(f\"   Maximum im Dataset: ${y.max():.5f} (√ó100k) = ${y.max()*100:.0f}k\")\n",
    "print(f\"   Werte bei genau $500k: {np.sum(y == 5.0)} von {len(y)} ({np.sum(y == 5.0)/len(y)*100:.1f}%)\")\n",
    "print(f\"   Werte ‚â• $490k: {np.sum(y >= 4.9)} von {len(y)} ({np.sum(y >= 4.9)/len(y)*100:.1f}%)\")\n",
    "\n",
    "# Visualisierung des Kappungseffekts\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(y, bins=50, alpha=0.7, edgecolor='black')\n",
    "plt.axvline(5.0, color='red', linestyle='--', linewidth=2, label='Kappung bei $500k')\n",
    "plt.xlabel('Hauswerte (√ó100k $)')\n",
    "plt.ylabel('H√§ufigkeit')\n",
    "plt.title('Verteilung der Hauswerte mit Kappung')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(y[y >= 4.5], bins=20, alpha=0.7, edgecolor='black', color='orange')\n",
    "plt.axvline(5.0, color='red', linestyle='--', linewidth=2, label='Kappung bei $500k')\n",
    "plt.xlabel('Hauswerte (√ó100k $)')\n",
    "plt.ylabel('H√§ufigkeit')\n",
    "plt.title('Zoom: Teure H√§user (‚â•$450k)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüìö QUELLEN & HINTERGRUND:\")\n",
    "print(f\"   üìÑ Original-Studie: Pace & Barry (1997), Statistics and Probability Letters\")\n",
    "print(f\"   üèõÔ∏è Datenquelle: US Census 1990, California Block Groups\")\n",
    "print(f\"   ‚öôÔ∏è Preprocessing: H√§user >$500k wurden auf genau $500k 'gekappt'\")\n",
    "print(f\"   üéØ Grund: Datenschutz & Ausrei√üer-Reduktion in der Originalerhebung\")\n",
    "print(f\"   üìä Effekt: K√ºnstliche H√§ufung bei $500k verf√§lscht teure Vorhersagen!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7894589b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schritt 4: Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2,      # 20% f√ºr Test\n",
    "    random_state=42     # F√ºr reproduzierbare Ergebnisse\n",
    ")\n",
    "\n",
    "print(f\"üöÇ Training: {X_train.shape[0]} Regionen\")\n",
    "print(f\"üß™ Test: {X_test.shape[0]} Regionen\")\n",
    "print(f\"‚öñÔ∏è Verh√§ltnis: {X_train.shape[0]/X_test.shape[0]:.1f}:1 (Train:Test)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35149b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schritt 5: Modell trainieren\n",
    "model = LinearRegression()\n",
    "\n",
    "print(\"ü§ñ Trainiere das Modell...\")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(f\"‚úÖ Modell trainiert!\")\n",
    "print(f\"üè† Basis-Hauspreis: ${model.intercept_:.2f} (√ó100k)\")\n",
    "\n",
    "# Die wichtigsten Features zeigen\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Koeffizient': model.coef_\n",
    "}).sort_values('Koeffizient', key=abs, ascending=False)\n",
    "\n",
    "print(f\"\\n‚≠ê Top 5 wichtigste Features:\")\n",
    "for i, (_, row) in enumerate(feature_importance.head().iterrows(), 1):\n",
    "    print(f\"   {i}. {row['Feature']}: {row['Koeffizient']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5090a214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schritt 6: Vorhersagen und Bewertung\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Performance-Metriken berechnen\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"üìä Modell-Performance:\")\n",
    "print(f\"   RMSE: ${rmse:.2f} (√ó100k) = ${rmse*100:.0f}k Durchschnittsfehler\")  \n",
    "print(f\"   R¬≤-Score: {r2:.3f} = {r2*100:.1f}% der Variation erkl√§rt\")\n",
    "\n",
    "# Beispiel-Vorhersagen zeigen\n",
    "print(f\"\\nüéØ Beispiel-Vorhersagen:\")\n",
    "for i in range(5):\n",
    "    actual = y_test.iloc[i] * 100  # In normale Tausend Dollar umrechnen\n",
    "    predicted = y_pred[i] * 100\n",
    "    error = abs(actual - predicted)\n",
    "    print(f\"   Tats√§chlich: ${actual:.0f}k, Vorhersage: ${predicted:.0f}k, Fehler: ${error:.0f}k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5faf950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schritt 7: Ergebnisse visualisieren\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Grafik 1: Vorhersage vs. Realit√§t\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(y_test, y_pred, alpha=0.6, s=30)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2, label='Ideale Linie (y = ≈∑)')\n",
    "plt.xlabel('Tats√§chliche Preise (√ó100k $)')\n",
    "plt.ylabel('Vorhergesagte Preise (√ó100k $)')\n",
    "plt.title('Vorhersage vs. Realit√§t')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Grafik 2: Fehler-Verteilung\n",
    "plt.subplot(1, 2, 2)\n",
    "errors = (y_test - y_pred) * 100  # In Tausend Dollar\n",
    "plt.hist(errors, bins=30, alpha=0.7, edgecolor='black', color='orange')\n",
    "plt.xlabel('Vorhersagefehler (Tausend $)')\n",
    "plt.ylabel('H√§ufigkeit')\n",
    "plt.title('Verteilung der Vorhersagefehler')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.axvline(0, color='red', linestyle='--', alpha=0.8, label='Kein Fehler')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"üìà Durchschnittlicher Absolut-Fehler: ${np.mean(np.abs(errors)):.0f}k\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08abe636",
   "metadata": {},
   "source": [
    "## üéâ Geschafft!\n",
    "\n",
    "**Was wir erreicht haben:**\n",
    "- ‚úÖ Komplette ML-Pipeline von Daten bis Vorhersage\n",
    "- ‚úÖ R¬≤-Score von ~0.60-0.67 (60-67% der Variation erkl√§rt)\n",
    "- ‚úÖ Durchschnittsfehler von ~65-75k Dollar bei Hauspreisen\n",
    "\n",
    "**Was wir gelernt haben:**\n",
    "- üè† **MedInc** (Einkommen) ist der wichtigste Faktor f√ºr Hauspreise\n",
    "- üìç **Lage** (Latitude/Longitude) ist auch sehr wichtig\n",
    "- üî¢ **Lineare Regression** ist ein guter Startpunkt f√ºr Preisvorhersagen\n",
    "- üìä **Train/Test Split** ist essentiell f√ºr ehrliche Modell-Bewertung\n",
    "\n",
    "**‚ö†Ô∏è Wichtige Dataset-Eigenart:**\n",
    "- **Preiskappung bei $500k**: Das Dataset wurde in der Originalerhebung (US Census 1990) bei $500k gekappt\n",
    "- **Quellen**: Pace & Barry (1997), \"Sparse Spatial Autoregressions\", Statistics and Probability Letters\n",
    "- **Effekt auf Vorhersagen**: \n",
    "  - Modelle k√∂nnen keine H√§user >$500k korrekt vorhersagen\n",
    "  - K√ºnstliche H√§ufung bei $500k verf√§lscht teure Immobilien-Prognosen\n",
    "  - In der Realit√§t w√ºrden moderne Datasets h√∂here Preise enthalten\n",
    "\n",
    "**N√§chste Schritte:**\n",
    "- Probiert andere Algorithmen aus (Random Forest, XGBoost)\n",
    "- Feature Engineering: Neue Features aus bestehenden ableiten\n",
    "- Hyperparameter-Tuning f√ºr bessere Performance\n",
    "- **Moderne Datasets**: Verwende aktuellere Immobiliendaten ohne Kappung!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lecture_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
