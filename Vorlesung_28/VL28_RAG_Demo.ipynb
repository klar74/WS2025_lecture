{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a698b31",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/klar74/WS2025_lecture/blob/main/Vorlesung_28/VL28_RAG_Demo.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c463b38c",
   "metadata": {},
   "source": [
    "# VL28 Notebook 3: RAG Demo\n",
    "## Retrieval-Augmented Generation (ohne API-Keys!)\n",
    "\n",
    "In diesem Notebook lernen wir:\n",
    "- Was RAG ist: LLM + externe Dokumente\n",
    "- Wie man eine einfache Vektor-Datenbank baut\n",
    "- Semantic Search mit Sentence-Transformers\n",
    "- Warum RAG Halluzinationen reduziert\n",
    "- **Alles lokal, kein OpenAI/API-Key n√∂tig!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73340710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation (nur einmal ausf√ºhren)\n",
    "# !pip install sentence-transformers numpy scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf01477",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d778a7d",
   "metadata": {},
   "source": [
    "## 1. Das Problem: LLMs haben begrenztes Wissen\n",
    "\n",
    "**Beispiel-Szenario:** Firmen-Handbuch mit internen Regeln\n",
    "- LLM kennt diese Dokumente nicht (waren nicht im Training)\n",
    "- LLM k√∂nnte Antworten \"erfinden\" (Halluzination)\n",
    "\n",
    "**RAG-L√∂sung:** \n",
    "1. **Retrieval**: Finde relevante Dokumente\n",
    "2. **Augmentation**: F√ºge Dokumente zum Prompt hinzu\n",
    "3. **Generation**: LLM antwortet basierend auf Dokumenten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0030eb37",
   "metadata": {},
   "source": [
    "## 2. Schritt 1: Dokumente vorbereiten\n",
    "\n",
    "Wir simulieren ein Firmen-Handbuch mit Urlaubsregeln, Arbeitszeiten, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cdfc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beispiel-Dokumente (Firmen-Handbuch)\n",
    "dokumente = [\n",
    "    {\n",
    "        \"id\": \"DOC001\",\n",
    "        \"titel\": \"Urlaubsregelung\",\n",
    "        \"text\": \"Mitarbeiter haben Anspruch auf 30 Tage Urlaub pro Jahr. Urlaub muss mindestens 2 Wochen im Voraus beantragt werden.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"DOC002\", \n",
    "        \"titel\": \"Arbeitszeiten\",\n",
    "        \"text\": \"Die regul√§re Arbeitszeit betr√§gt 40 Stunden pro Woche, Montag bis Freitag von 9:00 bis 17:00 Uhr. Gleitzeit ist m√∂glich zwischen 7:00 und 19:00 Uhr.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"DOC003\",\n",
    "        \"titel\": \"Homeoffice-Regelung\", \n",
    "        \"text\": \"Mitarbeiter k√∂nnen bis zu 3 Tage pro Woche im Homeoffice arbeiten. Dienstags ist Pr√§senzpflicht f√ºr Team-Meetings.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"DOC004\",\n",
    "        \"titel\": \"Krankheit\",\n",
    "        \"text\": \"Bei Krankheit muss der Vorgesetzte am ersten Tag telefonisch informiert werden. Ab dem 3. Tag ist ein √§rztliches Attest erforderlich.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"DOC005\",\n",
    "        \"titel\": \"Weiterbildung\",\n",
    "        \"text\": \"Jeder Mitarbeiter hat ein j√§hrliches Weiterbildungsbudget von 2000 Euro. Schulungen m√ºssen mit der Personalabteilung abgestimmt werden.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"Anzahl Dokumente: {len(dokumente)}\")\n",
    "for doc in dokumente:\n",
    "    print(f\"  - {doc['id']}: {doc['titel']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f637590",
   "metadata": {},
   "source": [
    "## 3. Schritt 2: Embeddings erstellen (Vektor-Datenbank)\n",
    "\n",
    "Wir nutzen **Sentence-Transformers** um jeden Dokumententext in einen Vektor umzuwandeln."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f84a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deutsches Sentence-Transformer Modell laden\n",
    "model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
    "print(\"‚úì Embedding-Modell geladen!\")\n",
    "\n",
    "# Alle Dokumente in Vektoren umwandeln\n",
    "doc_texte = [doc[\"text\"] for doc in dokumente]\n",
    "doc_embeddings = model.encode(doc_texte)\n",
    "\n",
    "print(f\"\\nEmbeddings erstellt:\")\n",
    "print(f\"  Shape: {doc_embeddings.shape}\")\n",
    "print(f\"  (5 Dokumente, jeweils 384-dimensionaler Vektor)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cec613",
   "metadata": {},
   "source": [
    "## 4. Schritt 3: Semantic Search (Retrieval)\n",
    "\n",
    "Wenn ein User eine Frage stellt, suchen wir die relevantesten Dokumente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286f8e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def suche_dokumente(frage, top_k=2):\n",
    "    \"\"\"\n",
    "    Findet die relevantesten Dokumente f√ºr eine Frage.\n",
    "    \n",
    "    Args:\n",
    "        frage: User-Frage als String\n",
    "        top_k: Anzahl der zur√ºckzugebenden Dokumente\n",
    "    \n",
    "    Returns:\n",
    "        Liste der relevantesten Dokumente\n",
    "    \"\"\"\n",
    "    # Frage in Vektor umwandeln\n",
    "    frage_embedding = model.encode([frage])\n",
    "    \n",
    "    # √Ñhnlichkeit zu allen Dokumenten berechnen\n",
    "    similarities = cosine_similarity(frage_embedding, doc_embeddings)[0]\n",
    "    \n",
    "    # Top K Indizes finden\n",
    "    top_indices = np.argsort(similarities)[-top_k:][::-1]\n",
    "    \n",
    "    # Ergebnisse zusammenstellen\n",
    "    results = []\n",
    "    for idx in top_indices:\n",
    "        results.append({\n",
    "            \"dokument\": dokumente[idx],\n",
    "            \"relevanz\": similarities[idx]\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Test: Verschiedene Fragen\n",
    "fragen = [\n",
    "    \"Wie viele Urlaubstage habe ich?\",\n",
    "    \"Kann ich von zu Hause arbeiten?\",\n",
    "    \"Was muss ich bei Krankheit tun?\",\n",
    "    \"Wie viel Geld gibt es f√ºr Fortbildung?\"\n",
    "]\n",
    "\n",
    "for frage in fragen:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Frage: {frage}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    results = suche_dokumente(frage, top_k=2)\n",
    "    \n",
    "    for i, result in enumerate(results, 1):\n",
    "        doc = result[\"dokument\"]\n",
    "        relevanz = result[\"relevanz\"]\n",
    "        print(f\"\\n{i}. {doc['titel']} (Relevanz: {relevanz:.3f})\")\n",
    "        print(f\"   {doc['text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0682a86",
   "metadata": {},
   "source": [
    "**Beobachtung:**\n",
    "- Semantic Search findet Dokumente basierend auf **Bedeutung**, nicht nur Keywords\n",
    "- \"Urlaubstage\" findet \"Urlaubsregelung\" (obwohl \"Tage\" nicht im Titel steht)\n",
    "- \"von zu Hause arbeiten\" findet \"Homeoffice-Regelung\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c561866",
   "metadata": {},
   "source": [
    "## 5. Schritt 4: RAG-Prompt konstruieren\n",
    "\n",
    "Jetzt bauen wir einen Prompt, der dem LLM die relevanten Dokumente gibt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9f1e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def erstelle_rag_prompt(frage, top_k=2):\n",
    "    \"\"\"\n",
    "    Erstellt einen RAG-Prompt mit Kontext-Dokumenten.\n",
    "    \"\"\"\n",
    "    # Relevante Dokumente finden\n",
    "    results = suche_dokumente(frage, top_k)\n",
    "    \n",
    "    # Kontext zusammenbauen\n",
    "    kontext = \"\\n\\n\".join([\n",
    "        f\"Dokument {i+1} ({r['dokument']['titel']}):\\n{r['dokument']['text']}\"\n",
    "        for i, r in enumerate(results)\n",
    "    ])\n",
    "    \n",
    "    # Prompt konstruieren\n",
    "    prompt = f\"\"\"Du bist ein hilfreicher Assistent, der Fragen basierend auf Firmen-Dokumenten beantwortet.\n",
    "\n",
    "WICHTIG: Beantworte die Frage NUR basierend auf den folgenden Dokumenten. \n",
    "Wenn die Antwort nicht in den Dokumenten steht, sage das deutlich.\n",
    "\n",
    "KONTEXT:\n",
    "{kontext}\n",
    "\n",
    "FRAGE: {frage}\n",
    "\n",
    "ANTWORT:\"\"\"\n",
    "    \n",
    "    return prompt, results\n",
    "\n",
    "# Beispiel\n",
    "frage = \"Wie viele Tage Urlaub stehen mir zu?\"\n",
    "prompt, docs = erstelle_rag_prompt(frage)\n",
    "\n",
    "print(\"RAG-Prompt:\")\n",
    "print(\"=\"*60)\n",
    "print(prompt)\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nVerwendete Dokumente:\")\n",
    "for doc in docs:\n",
    "    print(f\"  - {doc['dokument']['titel']} (Relevanz: {doc['relevanz']:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e4e819",
   "metadata": {},
   "source": [
    "## 6. Simulation: Mit vs. Ohne RAG\n",
    "\n",
    "**Ohne RAG:** LLM k√∂nnte halluzinieren oder veraltete Infos geben\n",
    "\n",
    "**Mit RAG:** LLM hat die echten Dokumente und kann daraus zitieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92babe92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weitere Beispiele\n",
    "test_fragen = [\n",
    "    \"Muss ich bei Krankheit ein Attest vorlegen?\",\n",
    "    \"Wann muss ich ins B√ºro kommen?\",\n",
    "    \"Wie hoch ist mein Weiterbildungsbudget?\",\n",
    "]\n",
    "\n",
    "for frage in test_fragen:\n",
    "    print(f\"\\n{'#'*60}\")\n",
    "    print(f\"FRAGE: {frage}\")\n",
    "    print(f\"{'#'*60}\")\n",
    "    \n",
    "    prompt, docs = erstelle_rag_prompt(frage, top_k=1)\n",
    "    \n",
    "    print(\"\\nüîç Gefundene Dokumente:\")\n",
    "    for doc in docs:\n",
    "        print(f\"   ‚Üí {doc['dokument']['titel']} (Relevanz: {doc['relevanz']:.3f})\")\n",
    "        print(f\"     {doc['dokument']['text'][:100]}...\")\n",
    "    \n",
    "    print(\"\\n‚úÖ ERWARTETE ANTWORT (basierend auf Dokument):\")\n",
    "    # Hier w√ºrde normalerweise ein LLM antworten\n",
    "    # Wir simulieren die ideale Antwort\n",
    "    if \"Attest\" in frage:\n",
    "        print(\"   Ja, ab dem 3. Krankheitstag ist ein √§rztliches Attest erforderlich.\")\n",
    "    elif \"B√ºro\" in frage or \"ins B√ºro\" in frage.lower():\n",
    "        print(\"   Dienstags besteht Pr√§senzpflicht f√ºr Team-Meetings. Ansonsten ist Homeoffice m√∂glich.\")\n",
    "    elif \"Weiterbildung\" in frage or \"Budget\" in frage:\n",
    "        print(\"   Das j√§hrliche Weiterbildungsbudget betr√§gt 2000 Euro pro Mitarbeiter.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b26375",
   "metadata": {},
   "source": [
    "## 7. Vorteile von RAG visualisieren\n",
    "\n",
    "Vergleich: Wie relevant sind die gefundenen Dokumente?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82466ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Alle Fragen durchgehen und Relevanz-Scores sammeln\n",
    "fragen_test = [\n",
    "    \"Urlaubstage\",\n",
    "    \"Homeoffice\", \n",
    "    \"Krankheit\",\n",
    "    \"Weiterbildung\",\n",
    "    \"Arbeitszeit\"\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(1, len(fragen_test), figsize=(15, 3))\n",
    "\n",
    "for i, frage in enumerate(fragen_test):\n",
    "    results = suche_dokumente(frage, top_k=len(dokumente))\n",
    "    relevanz_scores = [r[\"relevanz\"] for r in results]\n",
    "    titel = [r[\"dokument\"][\"titel\"][:15] for r in results]\n",
    "    \n",
    "    axes[i].barh(range(len(titel)), relevanz_scores, color='steelblue')\n",
    "    axes[i].set_yticks(range(len(titel)))\n",
    "    axes[i].set_yticklabels(titel, fontsize=8)\n",
    "    axes[i].set_xlabel('Relevanz', fontsize=8)\n",
    "    axes[i].set_title(frage, fontsize=10)\n",
    "    axes[i].set_xlim(0, 1)\n",
    "\n",
    "plt.suptitle(\"Retrieval-Qualit√§t: Semantic Search findet relevante Dokumente\", fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c92d73",
   "metadata": {},
   "source": [
    "## üéØ Takeaway\n",
    "\n",
    "**RAG l√∂st fundamentale LLM-Probleme:**\n",
    "- ‚úÖ **Kein veraltetes Wissen**: Dokumente sind immer aktuell\n",
    "- ‚úÖ **Weniger Halluzinationen**: LLM antwortet basierend auf echten Quellen\n",
    "- ‚úÖ **Firmen-spezifisches Wissen**: Interne Dokumente, die nie √∂ffentlich waren\n",
    "- ‚úÖ **Nachvollziehbarkeit**: Man sieht, welche Dokumente verwendet wurden\n",
    "\n",
    "**Wie RAG funktioniert:**\n",
    "1. **Embedding-Modell** wandelt Dokumente in Vektoren um (Vektor-DB)\n",
    "2. **Semantic Search** findet relevante Dokumente zur Frage\n",
    "3. **Prompt-Augmentation** f√ºgt Dokumente zum Kontext hinzu\n",
    "4. **LLM** generiert Antwort basierend auf Dokumenten\n",
    "\n",
    "**RAG in der Praxis:**\n",
    "- Kundensupport-Bots (Produkthandb√ºcher)\n",
    "- Firmen-Wikis und Dokumentensuche\n",
    "- Juristische/Medizinische Q&A (Compliance!)\n",
    "- Code-Assistenten (eigener Codebase als Kontext)\n",
    "\n",
    "**Wichtig:** RAG ersetzt kein echtes Verst√§ndnis, aber es macht LLMs **verl√§sslicher und n√ºtzlicher**!\n",
    "\n",
    "---\n",
    "\n",
    "## üéì Ende der VL28 Notebooks\n",
    "\n",
    "**Was wir gelernt haben:**\n",
    "1. **Word Embeddings**: Bedeutung durch Vektorraum (aber statisch)\n",
    "2. **BERT**: Kontextabh√§ngige Embeddings (Bank = Geldinstitut vs. Sitzm√∂bel)\n",
    "3. **RAG**: LLMs mit externem Wissen erweitern\n",
    "\n",
    "**Alles ohne API-Keys!** Hugging Face + Sentence-Transformers = kostenlos und lokal nutzbar."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lecture_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
