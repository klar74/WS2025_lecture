{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84888b96",
   "metadata": {},
   "source": [
    "# k-Means Initialisierung - Warum Startpunkte wichtig sind\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/klar74/WS2025_lecture/blob/main/Vorlesung_19/kmeans_initialization_experiment.ipynb)\n",
    "\n",
    "In diesem Notebook experimentieren wir mit **schwierigen Clustern** und sehen, warum die **Initialisierung** bei k-Means so wichtig ist.\n",
    "\n",
    "**Das Problem:** k-Means kann bei ungÃ¼nstigen Startpunkten in **lokalen Minima** stecken bleiben und schlechte Ergebnisse liefern.\n",
    "\n",
    "**Heute experimentieren wir:**\n",
    "1. ğŸ¯ Schwierige Cluster erstellen (realistisch!)\n",
    "2. ğŸ² Verschiedene Initialisierungen ausprobieren\n",
    "3. ğŸ”„ Bedeutung von `n_init` verstehen\n",
    "4. ğŸ§ª Selbst experimentieren und Unterschiede sehen\n",
    "\n",
    "**Interaktiv:** Ihr kÃ¶nnt verschiedene `random_state` Werte ausprobieren und sehen, wie unterschiedlich die Ergebnisse werden!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b1d0a5",
   "metadata": {},
   "source": [
    "## 1. Bibliotheken importieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9ceb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score, silhouette_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# FÃ¼r reproduzierbare Plots\n",
    "plt.style.use('default')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "print(\"ğŸ¯ k-Means Initialisierungs-Experiment geladen!\")\n",
    "print(\"Heute lernen wir, warum Startpunkte so wichtig sind!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10420947",
   "metadata": {},
   "source": [
    "## 2. Schwierige Cluster erstellen\n",
    "\n",
    "Wir erstellen **absichtlich schwierige Daten** mit drei Ã¼berlappenden Clustern. Das ist realistischer als perfekt getrennte Cluster!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a642e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BananenfÃ¶rmige Cluster - realistisch und schwierig fÃ¼r k-Means!\n",
    "np.random.seed(42)\n",
    "\n",
    "# Cluster 1: Obere Banane (gebogen nach oben)\n",
    "t1 = np.linspace(0, np.pi, 100)\n",
    "cluster1_x = 3 * t1 + np.random.normal(0, 0.3, 100)\n",
    "cluster1_y = 2 * np.sin(t1) + 2 + np.random.normal(0, 0.2, 100)\n",
    "cluster1 = np.column_stack([cluster1_x, cluster1_y])\n",
    "\n",
    "# Cluster 2: Untere Banane (gebogen nach unten)  \n",
    "t2 = np.linspace(0, np.pi, 100)\n",
    "cluster2_x = 3 * t2 + np.random.normal(0, 0.3, 100)\n",
    "cluster2_y = -2 * np.sin(t2) - 2 + np.random.normal(0, 0.2, 100)\n",
    "cluster2 = np.column_stack([cluster2_x, cluster2_y])\n",
    "\n",
    "# Cluster 3: Seitliche Banane (gebogen nach rechts)\n",
    "t3 = np.linspace(-np.pi/2, np.pi/2, 80)\n",
    "cluster3_x = 2 * np.cos(t3) - 2 + np.random.normal(0, 0.2, 80)\n",
    "cluster3_y = 3 * t3 + np.random.normal(0, 0.3, 80)\n",
    "cluster3 = np.column_stack([cluster3_x, cluster3_y])\n",
    "\n",
    "X = np.vstack([cluster1, cluster2, cluster3])\n",
    "y_true = np.hstack([np.zeros(100), np.ones(100), np.full(80, 2)])\n",
    "\n",
    "print(f\"ğŸ“Š BANANENFÃ–RMIGE CLUSTER - schwierig aber lÃ¶sbar fÃ¼r k-Means:\")\n",
    "print(f\"   â€¢ {len(X)} Datenpunkte\")  \n",
    "print(f\"   â€¢ Cluster 1: Obere Banane (100 Punkte)\")\n",
    "print(f\"   â€¢ Cluster 2: Untere Banane (100 Punkte)\")\n",
    "print(f\"   â€¢ Cluster 3: Seitliche Banane (80 Punkte)\")\n",
    "print(f\"   â€¢ Gebogene Cluster sind schwierig - Initialisierung wird kritisch!\")\n",
    "\n",
    "# Echte Cluster visualisieren\n",
    "plt.figure(figsize=(10, 6))\n",
    "colors = ['red', 'blue', 'green']\n",
    "for i in range(3):\n",
    "    cluster_points = X[y_true == i]\n",
    "    plt.scatter(cluster_points[:, 0], cluster_points[:, 1], \n",
    "               c=colors[i], alpha=0.6, s=50, \n",
    "               label=f'Echter Cluster {i+1}')\n",
    "\n",
    "plt.title('BANANENFÃ–RMIGE CLUSTER - Eine realistische Herausforderung!', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(\"ğŸ‘ï¸ Beobachtung: BananenfÃ¶rmige Cluster sind realistisch und herausfordernd!\")\n",
    "print(\"k-Means bevorzugt runde Cluster - gebogene Formen sind schwieriger!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20674391",
   "metadata": {},
   "source": [
    "## 3. Das Problem demonstrieren: Schlechte vs. gute Initialisierung\n",
    "\n",
    "Zuerst zeigen wir, dass k-Means bei ungÃ¼nstigen Startpunkten schlechte Ergebnisse liefern kann."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec4bd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feste schlechte und gute Startzentren fÃ¼r konsistente Demonstration\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Schlechte Initialisierung - ungÃ¼nstig verteilte Zentren\n",
    "start_centers_bad = np.array([\n",
    "    [3.9, -0.8],   # UngÃ¼nstige Verteilung der Start-Zentren\n",
    "    [-2.0, -3.9],  # â†’ fÃ¼hrt zu schlechter Clusteraufteilung\n",
    "    [-1.9, 1.2]    # â†’ k-Means findet lokales Minimum\n",
    "])\n",
    "kmeans_bad = KMeans(n_clusters=3, init=start_centers_bad, n_init=1, random_state=0)\n",
    "labels_bad = kmeans_bad.fit_predict(X)\n",
    "centers_bad = kmeans_bad.cluster_centers_\n",
    "\n",
    "# Gute Initialisierung - strategisch platzierte Start-Zentren\n",
    "start_centers_good = np.array([\n",
    "    [4.5, 2.0],    # Mitte der oberen Banane  \n",
    "    [4.5, -2.0],   # Mitte der unteren Banane\n",
    "    [-1.0, 0.0]    # Mitte der seitlichen Banane\n",
    "])\n",
    "kmeans_good = KMeans(n_clusters=3, init=start_centers_good, n_init=1, random_state=0)\n",
    "labels_good = kmeans_good.fit_predict(X)\n",
    "centers_good = kmeans_good.cluster_centers_\n",
    "\n",
    "# Plot 1: Schlechte Initialisierung\n",
    "# Einfache LÃ¶sung: Cluster nach Zentren-Position sortieren fÃ¼r Konsistenz\n",
    "centers_bad_sorted = np.argsort(centers_bad[:, 0])  # Nach x-Koordinate sortieren\n",
    "for i, cluster_idx in enumerate(centers_bad_sorted):\n",
    "    cluster_points = X[labels_bad == cluster_idx]\n",
    "    ax1.scatter(cluster_points[:, 0], cluster_points[:, 1], \n",
    "               c=colors[i], alpha=0.6, s=30)\n",
    "ax1.scatter(centers_bad[:, 0], centers_bad[:, 1], \n",
    "           c='black', marker='x', s=200, linewidths=3, label='Finale Zentren')\n",
    "ax1.scatter(start_centers_bad[:, 0], start_centers_bad[:, 1], \n",
    "           c='black', marker='s', s=100, alpha=0.8, label='Start-Zentren')\n",
    "ax1.set_title('Schlechte Initialisierung\\n(fÃ¤llt in lokales Minimum)', fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Gute Initialisierung\n",
    "centers_good_sorted = np.argsort(centers_good[:, 0])  # Nach x-Koordinate sortieren\n",
    "for i, cluster_idx in enumerate(centers_good_sorted):\n",
    "    cluster_points = X[labels_good == cluster_idx]\n",
    "    ax2.scatter(cluster_points[:, 0], cluster_points[:, 1], \n",
    "               c=colors[i], alpha=0.6, s=30)\n",
    "ax2.scatter(centers_good[:, 0], centers_good[:, 1], \n",
    "           c='black', marker='x', s=200, linewidths=3, label='Finale Zentren')\n",
    "ax2.scatter(start_centers_good[:, 0], start_centers_good[:, 1], \n",
    "           c='black', marker='s', s=100, alpha=0.8, label='Start-Zentren')\n",
    "ax2.set_title('Gute Initialisierung\\n(findet globales Minimum)', fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# QualitÃ¤t vergleichen\n",
    "ari_bad = adjusted_rand_score(y_true, labels_bad)\n",
    "ari_good = adjusted_rand_score(y_true, labels_good)\n",
    "sil_bad = silhouette_score(X, labels_bad)\n",
    "sil_good = silhouette_score(X, labels_good)\n",
    "\n",
    "print(\"ğŸ“Š QualitÃ¤tsvergleich:\")\n",
    "print(f\"Schlechte Init: ARI = {ari_bad:.3f}, Silhouette = {sil_bad:.3f}\")\n",
    "print(f\"Gute Init:      ARI = {ari_good:.3f}, Silhouette = {sil_good:.3f}\")\n",
    "print(f\"Verbesserung:   ARI = +{ari_good-ari_bad:.3f}, Silhouette = +{sil_good-sil_bad:.3f}\")\n",
    "print()\n",
    "print(\"ğŸ’¡ Erkenntnisse:\")\n",
    "print(\"   â€¢ BananenfÃ¶rmige Cluster zeigen warum Initialisierung wichtig ist!\")\n",
    "print(\"   â€¢ Schlechte Initialisierung: Alle Zentren in einer Banane gefangen\")\n",
    "print(\"   â€¢ k-Means teilt dann andere Bananen willkÃ¼rlich auf\")  \n",
    "print(\"   â€¢ Gute Initialisierung: Ein Zentrum pro Banane â†’ bessere LÃ¶sung\")\n",
    "print(\"   â€¢ Gebogene Strukturen bleiben schwierig, aber lÃ¶sbar\")\n",
    "print(\"   â€¢ Das zeigt: Initialisierung kann entscheidend sein!\")\n",
    "print(\"   â€¢ Realistisches Beispiel: Kundensegmente, Bildregionen, etc.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8416e874",
   "metadata": {},
   "source": [
    "## 4. Die Rettung: n_init Parameter\n",
    "\n",
    "**Das Problem:** Eine einzelne zufÃ¤llige Initialisierung kann Pech haben.  \n",
    "**Die LÃ¶sung:** `n_init` fÃ¼hrt k-Means mehrmals mit verschiedenen Startpunkten aus und wÃ¤hlt das beste Ergebnis!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d59f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_init Experiment\n",
    "print(\"ğŸ”„ n_init Experiment - Mehrere Versuche = bessere Ergebnisse\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "n_init_values = [1, 5, 10, 20, 50]\n",
    "results = []\n",
    "\n",
    "for n_init in n_init_values:\n",
    "    # k-Means mit verschiedenen n_init Werten\n",
    "    kmeans = KMeans(n_clusters=3, n_init=n_init, random_state=42)\n",
    "    labels = kmeans.fit_predict(X)\n",
    "    \n",
    "    # QualitÃ¤t messen\n",
    "    ari = adjusted_rand_score(y_true, labels)\n",
    "    silhouette = silhouette_score(X, labels)\n",
    "    inertia = kmeans.inertia_\n",
    "    \n",
    "    results.append({\n",
    "        'n_init': n_init,\n",
    "        'ari': ari,\n",
    "        'silhouette': silhouette,\n",
    "        'inertia': inertia,\n",
    "        'labels': labels,\n",
    "        'centers': kmeans.cluster_centers_\n",
    "    })\n",
    "    \n",
    "    print(f\"n_init={n_init:2d}: ARI={ari:.3f}, Silhouette={silhouette:.3f}, Inertia={inertia:.1f}\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ğŸ‘ï¸ Beobachtung: Mit hÃ¶herem n_init werden die Ergebnisse stabiler und besser!\")\n",
    "\n",
    "# Bestes Ergebnis visualisieren\n",
    "best_result = max(results, key=lambda x: x['ari'])\n",
    "print(f\"\\nğŸ† Bestes Ergebnis bei n_init={best_result['n_init']}\")\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Plot 1: n_init=1 (schlechtes Ergebnis)\n",
    "plt.subplot(1, 3, 1)\n",
    "worst_result = min(results, key=lambda x: x['ari'])\n",
    "# Einfache Sortierung fÃ¼r Konsistenz\n",
    "centers_sorted = np.argsort(worst_result['centers'][:, 0])\n",
    "for i, cluster_idx in enumerate(centers_sorted):\n",
    "    cluster_points = X[worst_result['labels'] == cluster_idx]\n",
    "    plt.scatter(cluster_points[:, 0], cluster_points[:, 1], \n",
    "               c=colors[i], alpha=0.6, s=30)\n",
    "plt.scatter(worst_result['centers'][:, 0], worst_result['centers'][:, 1], \n",
    "           c='black', marker='x', s=150, linewidths=2)\n",
    "plt.title(f'n_init={worst_result[\"n_init\"]}\\nARI={worst_result[\"ari\"]:.3f}', fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: n_init=10 (mittleres Ergebnis)\n",
    "plt.subplot(1, 3, 2)\n",
    "mid_result = [r for r in results if r['n_init'] == 10][0]\n",
    "centers_sorted = np.argsort(mid_result['centers'][:, 0])\n",
    "for i, cluster_idx in enumerate(centers_sorted):\n",
    "    cluster_points = X[mid_result['labels'] == cluster_idx]\n",
    "    plt.scatter(cluster_points[:, 0], cluster_points[:, 1], \n",
    "               c=colors[i], alpha=0.6, s=30)\n",
    "plt.scatter(mid_result['centers'][:, 0], mid_result['centers'][:, 1], \n",
    "           c='black', marker='x', s=150, linewidths=2)\n",
    "plt.title(f'n_init={mid_result[\"n_init\"]}\\nARI={mid_result[\"ari\"]:.3f}', fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Bestes Ergebnis\n",
    "plt.subplot(1, 3, 3) \n",
    "centers_sorted = np.argsort(best_result['centers'][:, 0])\n",
    "for i, cluster_idx in enumerate(centers_sorted):\n",
    "    cluster_points = X[best_result['labels'] == cluster_idx]\n",
    "    plt.scatter(cluster_points[:, 0], cluster_points[:, 1], \n",
    "               c=colors[i], alpha=0.6, s=30)\n",
    "plt.scatter(best_result['centers'][:, 0], best_result['centers'][:, 1], \n",
    "           c='black', marker='x', s=150, linewidths=2)\n",
    "plt.title(f'n_init={best_result[\"n_init\"]}\\nARI={best_result[\"ari\"]:.3f}', fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6803a4",
   "metadata": {},
   "source": [
    "## 5. ğŸ§ª EXPERIMENTIER-SECTION: Jetzt seid ihr dran!\n",
    "\n",
    "**Aufgabe:** Probiert verschiedene `random_state` Werte aus und seht, wie unterschiedlich die Ergebnisse werden kÃ¶nnen!\n",
    "\n",
    "**Anleitung:**\n",
    "1. Ã„ndert die `random_state` Werte in der Liste unten\n",
    "2. FÃ¼hrt die Zelle aus und schaut euch die Ergebnisse an\n",
    "3. Probiert verschiedene Werte aus: 1, 7, 13, 42, 99, 123, 999...\n",
    "4. Beobachtet: Welche Werte geben gute/schlechte Ergebnisse?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c964e8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ§ª EXPERIMENTIER-BEREICH - HIER KÃ–NNT IHR EXPERIMENTIEREN!\n",
    "\n",
    "# Diese Werte kÃ¶nnt ihr Ã¤ndern:\n",
    "experiment_random_states = [1, 7, 42, 99, 123]  # â† HIER EXPERIMENTIEREN!\n",
    "experiment_n_init = 1  # â† Erstmal auf 1 lassen, dann auf 10 Ã¤ndern\n",
    "\n",
    "print(\"ğŸ§ª EURE EXPERIMENTE:\")\n",
    "print(f\"Testet random_state Werte: {experiment_random_states}\")\n",
    "print(f\"Mit n_init = {experiment_n_init}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "experiment_results = []\n",
    "\n",
    "for rs in experiment_random_states:\n",
    "    # k-Means mit eurem random_state\n",
    "    kmeans = KMeans(n_clusters=3, random_state=rs, n_init=experiment_n_init)\n",
    "    labels = kmeans.fit_predict(X)\n",
    "    \n",
    "    # QualitÃ¤t messen\n",
    "    ari = adjusted_rand_score(y_true, labels)\n",
    "    silhouette = silhouette_score(X, labels)\n",
    "    \n",
    "    experiment_results.append({\n",
    "        'random_state': rs,\n",
    "        'ari': ari,\n",
    "        'silhouette': silhouette,\n",
    "        'labels': labels,\n",
    "        'centers': kmeans.cluster_centers_\n",
    "    })\n",
    "    \n",
    "    # QualitÃ¤tsbewertung\n",
    "    if ari > 0.8:\n",
    "        quality = \"Exzellent! ğŸŒŸ\"\n",
    "    elif ari > 0.6:\n",
    "        quality = \"Gut! âœ…\"\n",
    "    elif ari > 0.4:\n",
    "        quality = \"OK ğŸ”¶\"\n",
    "    else:\n",
    "        quality = \"Schlecht âŒ\"\n",
    "    \n",
    "    print(f\"random_state={rs:3d}: ARI={ari:.3f}, Silhouette={silhouette:.3f} â†’ {quality}\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Beste und schlechteste Ergebnisse zeigen\n",
    "best_exp = max(experiment_results, key=lambda x: x['ari'])\n",
    "worst_exp = min(experiment_results, key=lambda x: x['ari'])\n",
    "\n",
    "print(f\"ğŸ† Bestes Ergebnis: random_state={best_exp['random_state']} (ARI={best_exp['ari']:.3f})\")\n",
    "print(f\"ğŸ’€ Schlechtestes Ergebnis: random_state={worst_exp['random_state']} (ARI={worst_exp['ari']:.3f})\")\n",
    "print(f\"ğŸ“Š Unterschied: {best_exp['ari'] - worst_exp['ari']:.3f} ARI Punkte!\")\n",
    "\n",
    "# Visualisierung der Experimente\n",
    "n_experiments = len(experiment_results)\n",
    "fig, axes = plt.subplots(1, min(n_experiments, 5), figsize=(4*min(n_experiments, 5), 4))\n",
    "\n",
    "if n_experiments == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for i, result in enumerate(experiment_results):\n",
    "    if i >= 5:  # Maximal 5 Plots\n",
    "        break\n",
    "        \n",
    "    ax = axes[i] if len(axes) > 1 else axes[0]\n",
    "    \n",
    "    # Cluster zeichnen - sortiert fÃ¼r Konsistenz\n",
    "    centers_sorted = np.argsort(result['centers'][:, 0])\n",
    "    for color_idx, cluster_idx in enumerate(centers_sorted):\n",
    "        cluster_points = X[result['labels'] == cluster_idx]\n",
    "        ax.scatter(cluster_points[:, 0], cluster_points[:, 1], \n",
    "                  c=colors[color_idx], alpha=0.6, s=30)\n",
    "    \n",
    "    # Zentren zeichnen\n",
    "    ax.scatter(result['centers'][:, 0], result['centers'][:, 1], \n",
    "              c='black', marker='x', s=150, linewidths=2)\n",
    "    \n",
    "    # Titel mit Bewertung\n",
    "    quality_emoji = \"ğŸŒŸ\" if result['ari'] > 0.8 else \"âœ…\" if result['ari'] > 0.6 else \"ğŸ”¶\" if result['ari'] > 0.4 else \"âŒ\"\n",
    "    ax.set_title(f'random_state={result[\"random_state\"]}\\nARI={result[\"ari\"]:.3f} {quality_emoji}', \n",
    "                fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nğŸ’¡ EXPERIMENTIER-TIPPS:\")\n",
    "print(\"â€¢ Ã„ndert die random_state Werte und fÃ¼hrt die Zelle erneut aus!\")\n",
    "print(\"â€¢ Probiert: 1, 7, 13, 42, 77, 99, 123, 456, 789, 999\")\n",
    "print(\"â€¢ Danach: Setzt experiment_n_init = 10 und schaut den Unterschied!\")\n",
    "print(\"â€¢ Beobachtet: Welche Werte sind stabil gut/schlecht?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83391365",
   "metadata": {},
   "source": [
    "## 6. ğŸ¯ Erweiterte Experimente: Verschiedene Initialisierungsmethoden\n",
    "\n",
    "k-Means bietet verschiedene Initialisierungsmethoden. Probiert sie aus!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9a34cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verschiedene Initialisierungsmethoden testen\n",
    "print(\"ğŸ¯ Verschiedene Initialisierungsmethoden:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "init_methods = ['k-means++', 'random']  # Die zwei wichtigsten Methoden\n",
    "method_results = {}\n",
    "\n",
    "for method in init_methods:\n",
    "    print(f\"\\nğŸ“Š Methode: {method}\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    method_aris = []\n",
    "    method_silhouettes = []\n",
    "    \n",
    "    # 10 Versuche mit verschiedenen random_states\n",
    "    for rs in range(10):\n",
    "        kmeans = KMeans(n_clusters=3, init=method, random_state=rs, n_init=1)\n",
    "        labels = kmeans.fit_predict(X)\n",
    "        \n",
    "        ari = adjusted_rand_score(y_true, labels)\n",
    "        silhouette = silhouette_score(X, labels)\n",
    "        \n",
    "        method_aris.append(ari)\n",
    "        method_silhouettes.append(silhouette)\n",
    "        \n",
    "        print(f\"  Versuch {rs+1:2d}: ARI={ari:.3f}, Silhouette={silhouette:.3f}\")\n",
    "    \n",
    "    # Statistiken berechnen\n",
    "    avg_ari = np.mean(method_aris)\n",
    "    std_ari = np.std(method_aris)\n",
    "    min_ari = np.min(method_aris)\n",
    "    max_ari = np.max(method_aris)\n",
    "    \n",
    "    method_results[method] = {\n",
    "        'aris': method_aris,\n",
    "        'silhouettes': method_silhouettes,\n",
    "        'avg_ari': avg_ari,\n",
    "        'std_ari': std_ari,\n",
    "        'min_ari': min_ari,\n",
    "        'max_ari': max_ari\n",
    "    }\n",
    "    \n",
    "    print(f\"  ğŸ“ˆ Durchschnitt: {avg_ari:.3f} Â± {std_ari:.3f}\")\n",
    "    print(f\"  ğŸ“Š Bereich: {min_ari:.3f} - {max_ari:.3f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ğŸ† VERGLEICH DER METHODEN:\")\n",
    "\n",
    "for method in init_methods:\n",
    "    results = method_results[method]\n",
    "    stability = \"stabil\" if results['std_ari'] < 0.1 else \"instabil\"\n",
    "    quality = \"gut\" if results['avg_ari'] > 0.6 else \"mÃ¤ÃŸig\"\n",
    "    \n",
    "    print(f\"{method:12}: Durchschnitt={results['avg_ari']:.3f}, \"\n",
    "          f\"Streuung={results['std_ari']:.3f} â†’ {quality}, {stability}\")\n",
    "\n",
    "# Visualisierung der Verteilungen\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "for i, method in enumerate(init_methods):\n",
    "    aris = method_results[method]['aris']\n",
    "    plt.hist(aris, alpha=0.7, label=f'{method}', bins=8)\n",
    "plt.xlabel('ARI Score')\n",
    "plt.ylabel('HÃ¤ufigkeit')\n",
    "plt.title('Verteilung der ARI Scores\\n(10 Versuche pro Methode)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "methods = list(method_results.keys())\n",
    "avgs = [method_results[m]['avg_ari'] for m in methods]\n",
    "stds = [method_results[m]['std_ari'] for m in methods]\n",
    "\n",
    "plt.bar(methods, avgs, yerr=stds, capsize=5, alpha=0.7, color=['blue', 'orange'])\n",
    "plt.ylabel('Durchschnittlicher ARI Score')\n",
    "plt.title('Methodenvergleich\\n(Durchschnitt Â± Standardabweichung)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nğŸ’¡ ERKENNTNISSE:\")\n",
    "print(\"â€¢ k-means++: Intelligente Initialisierung, meist bessere und stabilere Ergebnisse\")\n",
    "print(\"â€¢ random: ZufÃ¤llige Initialisierung, mehr VariabilitÃ¤t in der QualitÃ¤t\")\n",
    "print(\"â€¢ Deshalb ist k-means++ der Standard in sklearn!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7895ff78",
   "metadata": {},
   "source": [
    "## 7. ğŸ“š Zusammenfassung: Was haben wir gelernt?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d25fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ“ WICHTIGE ERKENNTNISSE:\")\n",
    "print(\"=\"*50)\n",
    "print()\n",
    "print(\"1ï¸âƒ£ STARTPUNKTE SIND KRITISCH:\")\n",
    "print(\"   â€¢ k-Means ist sensitiv gegenÃ¼ber der Initialisierung\")\n",
    "print(\"   â€¢ Schlechte Startpunkte â†’ lokale Minima â†’ schlechte Ergebnisse\")\n",
    "print(\"   â€¢ Bei Ã¼berlappenden Clustern besonders problematisch\")\n",
    "print()\n",
    "print(\"2ï¸âƒ£ n_init IST EUER FREUND:\")\n",
    "print(f\"   â€¢ n_init=1: Riskant, kann Pech haben\")\n",
    "print(f\"   â€¢ n_init=10 (Standard): Meist ausreichend\")\n",
    "print(f\"   â€¢ n_init=50: Sehr sicher, aber langsamer\")\n",
    "print(\"   â€¢ k-Means wÃ¤hlt automatisch das beste von n_init Versuchen\")\n",
    "print()\n",
    "print(\"3ï¸âƒ£ INITIALISIERUNGS-METHODEN:\")\n",
    "print(\"   â€¢ 'k-means++': Intelligent, meist bessere Ergebnisse (Standard)\")\n",
    "print(\"   â€¢ 'random': ZufÃ¤llig, mehr VariabilitÃ¤t\")\n",
    "print(\"   â€¢ k-means++ ist fast immer die bessere Wahl\")\n",
    "print()\n",
    "print(\"4ï¸âƒ£ RANDOM_STATE EXPERIMENTE:\")\n",
    "print(\"   â€¢ Verschiedene random_states â†’ sehr verschiedene Ergebnisse\")\n",
    "print(\"   â€¢ Manche Werte sind 'glÃ¼cklich', andere 'unglÃ¼cklich'\")\n",
    "print(\"   â€¢ Deshalb nie nur einen einzigen Versuch machen!\")\n",
    "print()\n",
    "print(\"5ï¸âƒ£ PRAKTISCHE TIPPS:\")\n",
    "print(\"   â€¢ Immer n_init >= 10 verwenden\")\n",
    "print(\"   â€¢ Bei wichtigen Anwendungen: n_init=20 oder hÃ¶her\")\n",
    "print(\"   â€¢ init='k-means++' beibehalten (ist Standard)\")\n",
    "print(\"   â€¢ Bei wiederholbaren Ergebnissen: random_state setzen\")\n",
    "print(\"   â€¢ Bei schlechten Ergebnissen: mehr n_init versuchen\")\n",
    "print()\n",
    "print(\"ğŸ† IHR HABT ERFOLGREICH GELERNT:\")\n",
    "print(\"   âœ“ Warum k-Means manchmal schlecht ist\")\n",
    "print(\"   âœ“ Wie man es besser macht\")\n",
    "print(\"   âœ“ Warum Sklearn-Defaults meist gut sind\")\n",
    "print(\"   âœ“ Wie man mit Experimenten besser versteht\")\n",
    "print()\n",
    "print(\"ğŸš€ Jetzt kÃ¶nnt ihr k-Means RICHTIG einsetzen!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lecture_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
