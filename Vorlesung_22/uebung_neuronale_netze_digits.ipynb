{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "220cd849",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/klar74/WS2025_lecture/blob/main/Vorlesung_22/uebung_neuronale_netze_digits.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ff42f9",
   "metadata": {},
   "source": [
    "# √úbung: Neuronale Netze mit Digits Dataset\n",
    "## MLP vs. CNN Vergleich\n",
    "\n",
    "In dieser √úbung schauen wir uns zwei Arten von neuronalen Netzen an:\n",
    "- **Multi-Layer Perceptron (MLP)**: Klassisches neuronales Netz mit vollverbundenen Schichten\n",
    "- **Convolutional Neural Network (CNN)**: Speziell f√ºr Bilddaten entwickelt\n",
    "\n",
    "Wir verwenden den **Digits Dataset**: 8√ó8 Pixel Bilder handgeschriebener Ziffern (0-9)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5d0ed3",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39dd7adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# Scikit-learn f√ºr Digits Dataset und Metriken\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# TensorFlow/Keras f√ºr beide Modelle\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "print(\"Bibliotheken geladen!\")\n",
    "print(f\"TensorFlow Version: {tf.__version__}\")\n",
    "\n",
    "# Reproducibility - alle Seeds setzen f√ºr vollst√§ndige Reproduzierbarkeit\n",
    "SEED = 42\n",
    "random.seed(SEED)           # Python built-in random\n",
    "np.random.seed(SEED)        # NumPy random\n",
    "tf.random.set_seed(SEED)    # TensorFlow random\n",
    "\n",
    "# Zus√§tzliche TensorFlow Determinismus-Einstellungen f√ºr GPU\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "\n",
    "print(f\"Alle Random Seeds auf {SEED} gesetzt f√ºr Reproduzierbarkeit!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5f86c2",
   "metadata": {},
   "source": [
    "## 2. Load and Explore the Digits Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afc2172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Digits Dataset laden\n",
    "digits = load_digits()\n",
    "X, y = digits.data, digits.target\n",
    "\n",
    "print(\"Dataset Informationen:\")\n",
    "print(f\"Anzahl Bilder: {X.shape[0]}\")\n",
    "print(f\"Features pro Bild: {X.shape[1]} (8√ó8 = 64 Pixel)\")\n",
    "print(f\"Bildgr√∂√üe: 8√ó8 Pixel\")\n",
    "print(f\"Anzahl Klassen: {len(np.unique(y))}\")\n",
    "print(f\"Klassen: {np.unique(y)}\")\n",
    "print(f\"Pixel-Werte: {X.min()} bis {X.max()}\")\n",
    "\n",
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining set: {X_train.shape[0]} Bilder\")\n",
    "print(f\"Test set: {X_test.shape[0]} Bilder\")\n",
    "\n",
    "# Einige Beispielbilder anzeigen\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 6))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    # Reshape zu 8x8 f√ºr Visualisierung\n",
    "    image = X_train[i].reshape(8, 8)\n",
    "    ax.imshow(image, cmap='gray')\n",
    "    ax.set_title(f'Label: {y_train[i]}')\n",
    "    ax.axis('off')\n",
    "plt.suptitle('Beispielbilder aus dem Digits Dataset (8√ó8 Pixel)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77555bfe",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5902afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten normalisieren (bereits 0-16 Bereich, normalisieren zu 0-1)\n",
    "X_train = X_train.astype('float32') / 16.0\n",
    "X_test = X_test.astype('float32') / 16.0\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} Bilder\")\n",
    "print(f\"Test set: {X_test.shape[0]} Bilder\")\n",
    "print(f\"Normalisierte Pixel-Werte: {X_train.min():.2f} bis {X_train.max():.2f}\")\n",
    "\n",
    "# Daten f√ºr MLP: bereits flach (64 Features)\n",
    "X_train_mlp = X_train.copy()\n",
    "X_test_mlp = X_test.copy()\n",
    "\n",
    "# Daten f√ºr CNN: Reshape zu 8x8 + Channel-Dimension\n",
    "X_train_cnn = X_train.reshape(-1, 8, 8, 1)\n",
    "X_test_cnn = X_test.reshape(-1, 8, 8, 1)\n",
    "\n",
    "print(f\"\\nMLP Input Shape: {X_train_mlp.shape}\")\n",
    "print(f\"CNN Input Shape: {X_train_cnn.shape}\")\n",
    "\n",
    "# Visualisierung des Unterschieds\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# MLP Sicht: Flacher Vektor\n",
    "axes[0].bar(range(64), X_train_mlp[0])\n",
    "axes[0].set_title('MLP Sicht: 64-dimensionaler Vektor')\n",
    "axes[0].set_xlabel('Pixel Index')\n",
    "axes[0].set_ylabel('Pixel Wert')\n",
    "\n",
    "# CNN Sicht: 8x8 Bild\n",
    "axes[1].imshow(X_train_cnn[0].reshape(8, 8), cmap='gray')\n",
    "axes[1].set_title('CNN Sicht: 8√ó8 Bild')\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.suptitle(f'Gleiche Ziffer ({y_train[0]}), verschiedene Darstellungen')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c667d9",
   "metadata": {},
   "source": [
    "## 4. Multi-Layer Perceptron (MLP) Implementation\n",
    "\n",
    "**Wichtiger Hinweis:** F√ºr einen fairen Vergleich zwischen MLP und CNN verwenden wir Modelle mit √§hnlicher Parameter-Anzahl. Das verhindert, dass ein Modell nur wegen mehr Parametern besser abschneidet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df94370f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP mit Keras\n",
    "print(\"Aufbau MLP Modell...\")\n",
    "\n",
    "mlp_model = keras.Sequential([\n",
    "    keras.Input(shape=(64,)),\n",
    "    layers.Dense(20, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.1),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "mlp_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.0005),  # Gleiche LR wie CNN\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"MLP Architektur:\")\n",
    "mlp_model.summary()\n",
    "print(f\"MLP Parameter: {mlp_model.count_params():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e38cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP trainieren\n",
    "print(\"Training MLP...\")\n",
    "mlp_history = mlp_model.fit(\n",
    "    X_train_mlp, y_train,\n",
    "    epochs=100,  # Erh√∂ht auf 100 Epochen\n",
    "    batch_size=32,\n",
    "    validation_split=0.1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# MLP evaluieren\n",
    "mlp_loss, mlp_accuracy = mlp_model.evaluate(X_test_mlp, y_test, verbose=0)\n",
    "print(f\"\\nMLP Test Genauigkeit: {mlp_accuracy:.4f}\")\n",
    "\n",
    "# Vorhersagen f√ºr sp√§teren Vergleich\n",
    "y_pred_mlp = np.argmax(mlp_model.predict(X_test_mlp, verbose=0), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91a62a8",
   "metadata": {},
   "source": [
    "## 5. Convolutional Neural Network (CNN) Implementation\n",
    "\n",
    "**Architektur-√úberlegungen:** Unser CNN ist jetzt so gestaltet, dass es **weniger Parameter** als das MLP hat. Damit k√∂nnen wir pr√ºfen, ob CNNs auch mit weniger Parametern durch ihre spezialisierte Architektur einen Vorteil bei Bilddaten haben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8248a810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN mit Keras - verbesserte Architektur f√ºr bessere Performance\n",
    "print(\"Aufbau CNN Modell...\")\n",
    "\n",
    "cnn_model = keras.Sequential([\n",
    "    # Expliziter Input Layer (Keras 3.x Style)\n",
    "    keras.Input(shape=(8, 8, 1)),\n",
    "    # Convolutional Block\n",
    "    layers.Conv2D(20, (3, 3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(2, 2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(5, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.1),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Optimizer mit reduzierter Learning Rate\n",
    "cnn_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.0005),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"CNN Architektur:\")\n",
    "cnn_model.summary()\n",
    "print(f\"CNN Parameter: {cnn_model.count_params():,}\")\n",
    "\n",
    "# Parameter-Vergleich\n",
    "mlp_params = mlp_model.count_params()\n",
    "cnn_params = cnn_model.count_params()\n",
    "print(f\"\\n=== PARAMETER-VERGLEICH ===\")\n",
    "print(f\"MLP Parameter: {mlp_params:,}\")\n",
    "print(f\"CNN Parameter: {cnn_params:,}\")\n",
    "print(f\"Verh√§ltnis CNN/MLP: {cnn_params/mlp_params:.2f}√ó\")\n",
    "print(f\"Unterschied: {abs(cnn_params - mlp_params):,} Parameter\")\n",
    "if cnn_params < mlp_params:\n",
    "    print(f\"‚úÖ CNN hat {mlp_params - cnn_params:,} Parameter weniger als MLP ({100*(mlp_params-cnn_params)/mlp_params:.1f}% weniger)\")\n",
    "else:\n",
    "    print(f\"üìà CNN hat {cnn_params - mlp_params:,} Parameter mehr als MLP ({100*(cnn_params-mlp_params)/mlp_params:.1f}% mehr)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b5f208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN trainieren\n",
    "print(\"Training CNN...\")\n",
    "cnn_history = cnn_model.fit(\n",
    "    X_train_cnn, y_train,\n",
    "    epochs=100,  # Erh√∂ht auf 100 Epochen\n",
    "    batch_size=32,\n",
    "    validation_split=0.1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# CNN evaluieren\n",
    "cnn_loss, cnn_accuracy = cnn_model.evaluate(X_test_cnn, y_test, verbose=0)\n",
    "print(f\"\\nCNN Test Genauigkeit: {cnn_accuracy:.4f}\")\n",
    "\n",
    "# Vorhersagen f√ºr Vergleich\n",
    "y_pred_cnn = np.argmax(cnn_model.predict(X_test_cnn, verbose=0), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a0c767",
   "metadata": {},
   "source": [
    "## 6. Model Comparison and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da08e115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vergleich der Modelle\n",
    "print(\"=== MODELL VERGLEICH ===\")\n",
    "print(f\"MLP Genauigkeit:  {mlp_accuracy:.4f}\")\n",
    "print(f\"CNN Genauigkeit:  {cnn_accuracy:.4f}\")\n",
    "print(f\"Unterschied CNN-MLP:     {cnn_accuracy - mlp_accuracy:.4f}\")\n",
    "\n",
    "# Parameter-Anzahl vergleichen\n",
    "mlp_params = mlp_model.count_params()\n",
    "cnn_params = cnn_model.count_params()\n",
    "print(f\"\\nMLP Parameter:    {mlp_params:,}\")\n",
    "print(f\"CNN Parameter:    {cnn_params:,}\")\n",
    "print(f\"Verh√§ltnis CNN/MLP: {cnn_params/mlp_params:.1f}√ó\")\n",
    "\n",
    "# Training History Visualisierung\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(mlp_history.history['loss'], label='MLP Training', alpha=0.7)\n",
    "plt.plot(mlp_history.history['val_loss'], label='MLP Validation', alpha=0.7)\n",
    "plt.plot(cnn_history.history['loss'], label='CNN Training', alpha=0.7)\n",
    "plt.plot(cnn_history.history['val_loss'], label='CNN Validation', alpha=0.7)\n",
    "plt.title('Training Loss Vergleich')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(mlp_history.history['accuracy'], label='MLP Training', alpha=0.7)\n",
    "plt.plot(mlp_history.history['val_accuracy'], label='MLP Validation', alpha=0.7)\n",
    "plt.plot(cnn_history.history['accuracy'], label='CNN Training', alpha=0.7)\n",
    "plt.plot(cnn_history.history['val_accuracy'], label='CNN Validation', alpha=0.7)\n",
    "plt.title('Training Accuracy Vergleich')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "models = ['MLP', 'CNN']\n",
    "accuracies = [mlp_accuracy, cnn_accuracy]\n",
    "colors = ['skyblue', 'lightcoral']\n",
    "bars = plt.bar(models, accuracies, color=colors)\n",
    "plt.title('Test Accuracy Vergleich')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0.8, 1.0)\n",
    "for i, (acc, bar) in enumerate(zip(accuracies, bars)):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., acc + 0.005, \n",
    "             f'{acc:.3f}', ha='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3402b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konfusionsmatrizen vergleichen\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# MLP Konfusionsmatrix\n",
    "cm_mlp = confusion_matrix(y_test, y_pred_mlp)\n",
    "im1 = axes[0].imshow(cm_mlp, interpolation='nearest', cmap='Blues')\n",
    "axes[0].set_title(f'MLP Confusion Matrix\\nAccuracy: {mlp_accuracy:.3f}')\n",
    "axes[0].set_ylabel('True Label')\n",
    "axes[0].set_xlabel('Predicted Label')\n",
    "axes[0].set_xticks(range(10))\n",
    "axes[0].set_yticks(range(10))\n",
    "\n",
    "# CNN Konfusionsmatrix\n",
    "cm_cnn = confusion_matrix(y_test, y_pred_cnn)\n",
    "im2 = axes[1].imshow(cm_cnn, interpolation='nearest', cmap='Blues')\n",
    "axes[1].set_title(f'CNN Confusion Matrix\\nAccuracy: {cnn_accuracy:.3f}')\n",
    "axes[1].set_ylabel('True Label')\n",
    "axes[1].set_xlabel('Predicted Label')\n",
    "axes[1].set_xticks(range(10))\n",
    "axes[1].set_yticks(range(10))\n",
    "\n",
    "# Zahlen in die Matrizen schreiben\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        if cm_mlp[i, j] > 0:\n",
    "            axes[0].text(j, i, str(cm_mlp[i, j]), ha='center', va='center', \n",
    "                        color='white' if cm_mlp[i, j] > cm_mlp.max()/2 else 'black', fontsize=10)\n",
    "        if cm_cnn[i, j] > 0:\n",
    "            axes[1].text(j, i, str(cm_cnn[i, j]), ha='center', va='center',\n",
    "                        color='white' if cm_cnn[i, j] > cm_cnn.max()/2 else 'black', fontsize=10)\n",
    "\n",
    "plt.colorbar(im1, ax=axes[0])\n",
    "plt.colorbar(im2, ax=axes[1])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Detaillierte Klassifikationsberichte\n",
    "print(\"\\n=== MLP Classification Report ===\")\n",
    "print(classification_report(y_test, y_pred_mlp))\n",
    "\n",
    "print(\"\\n=== CNN Classification Report ===\")\n",
    "print(classification_report(y_test, y_pred_cnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72692de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beispiel-Vorhersagen visualisieren - gezielt Fehler zeigen\n",
    "fig, axes = plt.subplots(3, 8, figsize=(16, 8))\n",
    "\n",
    "# Fehleranalyse f√ºr gezielte Auswahl\n",
    "mlp_errors = (y_pred_mlp != y_test)\n",
    "cnn_errors = (y_pred_cnn != y_test)\n",
    "both_correct = (~mlp_errors) & (~cnn_errors)  # Beide richtig\n",
    "mlp_only_wrong = mlp_errors & (~cnn_errors)   # Nur MLP falsch\n",
    "cnn_only_wrong = (~mlp_errors) & cnn_errors   # Nur CNN falsch\n",
    "both_wrong = mlp_errors & cnn_errors          # Beide falsch\n",
    "\n",
    "print(\"=== FEHLERVERTEILUNG ===\")\n",
    "print(f\"Beide richtig: {both_correct.sum()}\")\n",
    "print(f\"Nur MLP falsch: {mlp_only_wrong.sum()}\")\n",
    "print(f\"Nur CNN falsch: {cnn_only_wrong.sum()}\")\n",
    "print(f\"Beide falsch: {both_wrong.sum()}\")\n",
    "\n",
    "# Gezielt interessante Beispiele ausw√§hlen\n",
    "selected_indices = []\n",
    "\n",
    "# 2 Beispiele wo beide richtig sind\n",
    "if both_correct.sum() >= 2:\n",
    "    both_correct_indices = np.where(both_correct)[0]\n",
    "    selected_indices.extend(both_correct_indices[:2])\n",
    "\n",
    "# 2 Beispiele wo nur MLP falsch ist (CNN besser)\n",
    "if mlp_only_wrong.sum() >= 2:\n",
    "    mlp_only_wrong_indices = np.where(mlp_only_wrong)[0]\n",
    "    selected_indices.extend(mlp_only_wrong_indices[:2])\n",
    "\n",
    "# 2 Beispiele wo nur CNN falsch ist (MLP besser)  \n",
    "if cnn_only_wrong.sum() >= 2:\n",
    "    cnn_only_wrong_indices = np.where(cnn_only_wrong)[0]\n",
    "    selected_indices.extend(cnn_only_wrong_indices[:2])\n",
    "\n",
    "# 2 Beispiele wo beide falsch sind\n",
    "if both_wrong.sum() >= 2:\n",
    "    both_wrong_indices = np.where(both_wrong)[0]\n",
    "    selected_indices.extend(both_wrong_indices[:2])\n",
    "\n",
    "# Falls nicht genug Beispiele, f√ºlle mit zuf√§lligen auf\n",
    "while len(selected_indices) < 8:\n",
    "    remaining_indices = np.setdiff1d(np.arange(len(y_test)), selected_indices)\n",
    "    if len(remaining_indices) > 0:\n",
    "        selected_indices.append(np.random.choice(remaining_indices))\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Auf 8 Beispiele beschr√§nken\n",
    "selected_indices = selected_indices[:8]\n",
    "\n",
    "for i, idx in enumerate(selected_indices):\n",
    "    # Originalbild\n",
    "    axes[0, i].imshow(X_test_cnn[idx].reshape(8, 8), cmap='gray')\n",
    "    axes[0, i].set_title(f'True: {y_test[idx]}', fontsize=12, fontweight='bold')\n",
    "    axes[0, i].axis('off')\n",
    "    \n",
    "    # MLP Vorhersage\n",
    "    mlp_pred = y_pred_mlp[idx]\n",
    "    mlp_correct = (mlp_pred == y_test[idx])\n",
    "    mlp_color = 'green' if mlp_correct else 'red'\n",
    "    axes[1, i].text(0.5, 0.5, f'MLP\\n{mlp_pred}', transform=axes[1, i].transAxes,\n",
    "                   ha='center', va='center', fontsize=16, color=mlp_color, weight='bold')\n",
    "    axes[1, i].axis('off')\n",
    "    \n",
    "    # CNN Vorhersage\n",
    "    cnn_pred = y_pred_cnn[idx]\n",
    "    cnn_correct = (cnn_pred == y_test[idx])\n",
    "    cnn_color = 'green' if cnn_correct else 'red'\n",
    "    axes[2, i].text(0.5, 0.5, f'CNN\\n{cnn_pred}', transform=axes[2, i].transAxes,\n",
    "                   ha='center', va='center', fontsize=16, color=cnn_color, weight='bold')\n",
    "    axes[2, i].axis('off')\n",
    "    \n",
    "    # Kategorisierung als Subtitle\n",
    "    if mlp_correct and cnn_correct:\n",
    "        category = \"Beide ‚úì\"\n",
    "        category_color = 'green'\n",
    "    elif not mlp_correct and cnn_correct:\n",
    "        category = \"CNN besser\"\n",
    "        category_color = 'blue'\n",
    "    elif mlp_correct and not cnn_correct:\n",
    "        category = \"MLP besser\"\n",
    "        category_color = 'orange'\n",
    "    else:\n",
    "        category = \"Beide ‚úó\"\n",
    "        category_color = 'red'\n",
    "    \n",
    "    axes[0, i].text(0.5, -0.1, category, transform=axes[0, i].transAxes,\n",
    "                   ha='center', va='top', fontsize=10, color=category_color, weight='bold')\n",
    "\n",
    "axes[0, 0].set_ylabel('Original\\n(8√ó8)', fontsize=14)\n",
    "axes[1, 0].set_ylabel('MLP\\nVorhersage', fontsize=14)\n",
    "axes[2, 0].set_ylabel('CNN\\nVorhersage', fontsize=14)\n",
    "plt.suptitle('Gezielte Beispiele: Gr√ºn = Richtig, Rot = Falsch\\nKategorien zeigen welches Modell besser abschneidet', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Fehleranalyse: Wo macht das CNN weniger Fehler als das MLP?\n",
    "cnn_better = mlp_errors & ~cnn_errors  # MLP falsch, CNN richtig\n",
    "mlp_better = cnn_errors & ~mlp_errors  # CNN falsch, MLP richtig\n",
    "\n",
    "print(f\"\\n=== DETAILLIERTE FEHLERANALYSE ===\")\n",
    "print(f\"MLP Fehler: {mlp_errors.sum()}/{len(y_test)} ({100*mlp_errors.mean():.1f}%)\")\n",
    "print(f\"CNN Fehler: {cnn_errors.sum()}/{len(y_test)} ({100*cnn_errors.mean():.1f}%)\")\n",
    "print(f\"CNN besser als MLP: {cnn_better.sum()} F√§lle\")\n",
    "print(f\"MLP besser als CNN: {mlp_better.sum()} F√§lle\")\n",
    "print(f\"Beide richtig: {both_correct.sum()} F√§lle\")\n",
    "print(f\"Beide falsch: {both_wrong.sum()} F√§lle\")\n",
    "\n",
    "# Zeige konkrete Beispiele wo CNN besser ist\n",
    "if cnn_better.sum() > 0:\n",
    "    print(f\"\\nüìä Beispiele wo CNN richtig liegt, MLP aber falsch:\")\n",
    "    cnn_better_indices = np.where(cnn_better)[0][:5]  # Erste 5 Beispiele\n",
    "    for idx in cnn_better_indices:\n",
    "        print(f\"  Index {idx}: True={y_test[idx]}, MLP={y_pred_mlp[idx]} ‚ùå, CNN={y_pred_cnn[idx]} ‚úÖ\")\n",
    "\n",
    "# Zeige konkrete Beispiele wo MLP besser ist\n",
    "if mlp_better.sum() > 0:\n",
    "    print(f\"\\nüìä Beispiele wo MLP richtig liegt, CNN aber falsch:\")\n",
    "    mlp_better_indices = np.where(mlp_better)[0][:5]  # Erste 5 Beispiele\n",
    "    for idx in mlp_better_indices:\n",
    "        print(f\"  Index {idx}: True={y_test[idx]}, MLP={y_pred_mlp[idx]} ‚úÖ, CNN={y_pred_cnn[idx]} ‚ùå\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6d9f16",
   "metadata": {},
   "source": [
    "## üéØ Fazit und Erkenntnisse\n",
    "\n",
    "**Wichtige Beobachtungen bei 8√ó8 Bildern und vergleichbaren Parameter-Anzahlen:**\n",
    "\n",
    "1. **Fairer Vergleich mit √§hnlichen Parameter-Zahlen**: CNN erreicht sogar mit ca. 20% weniger Parametern vergleichbare Ergebnisse zum MLP.\n",
    "\n",
    "2. **√úberraschung bei kleinen Bildern**: Bei 8√ó8 Bildern ist der Unterschied zwischen MLP und CNN oft minimal - manchmal ist das MLP sogar gleichwertig oder besser!\n",
    "\n",
    "3. **Warum ist das so?**\n",
    "   - Bei nur 64 Pixeln ist die \"r√§umliche Struktur\" weniger komplex\n",
    "   - Ein kleines MLP kann die wenigen relevanten Pixel-Kombinationen direkt lernen\n",
    "   - Die Translation-Invarianz von CNNs ist bei zentrierten 8√ó8 Ziffern weniger wichtig\n",
    "   - Faltung bringt weniger Vorteil bei so kleinen rezeptiven Feldern\n",
    "\n",
    "4. **CNN-Vorteile trotzdem sichtbar:**\n",
    "   - Leicht bessere Robustheit gegen Verschiebungen\n",
    "   - Parameter-Sharing macht das Modell \"strukturierter\"\n",
    "   - Filter sind interpretierbar (k√∂nnen visualisiert werden)\n",
    "\n",
    "5. **Der entscheidende Lerneffekt:**\n",
    "   - **8√ó8 Bilder:** MLP konkurrenzf√§hig\n",
    "   - **28√ó28 MNIST:** CNN w√§re deutlich besser\n",
    "   - **224√ó224 ImageNet:** CNN unverzichtbar, MLP praktisch unm√∂glich\n",
    "\n",
    "**Kernbotschaft:** \n",
    "- **Die Wahl der Architektur h√§ngt von der Bildgr√∂√üe ab**\n",
    "- **Bei sehr kleinen Bildern k√∂nnen MLPs mithalten** - der CNN-Vorteil kommt erst bei \"echten\" Bildgr√∂√üen zum Tragen\n",
    "- **Parameter-Effizienz allein macht noch keinen gro√üen Unterschied** - die r√§umliche Komplexit√§t muss gro√ü genug sein\n",
    "- **Dies erkl√§rt, warum CNNs erst mit gr√∂√üeren Datens√§tzen wie ImageNet wirklich den Durchbruch geschafft haben**\n",
    "\n",
    "**Zum Experimentieren:**\n",
    "- Vergleiche mit MNIST (28√ó28) - dort wird der CNN-Vorteil deutlicher\n",
    "- Teste mit verzerrten oder gedrehten 8√ó8 Bildern\n",
    "- Probiere gr√∂√üere CNN-Filter (5√ó5) bei gleicher Parameter-Anzahl\n",
    "- Implementiere Data Augmentation und schaue, welches Modell mehr profitiert"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lecture_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
