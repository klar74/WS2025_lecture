{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3587d145",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/klar74/WS2025_lecture/blob/main/Vorlesung_22/uebung_neuronale_netze.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd7193f",
   "metadata": {},
   "source": [
    "# √úbung: Neuronale Netze mit MNIST Dataset\n",
    "## MLP vs. CNN Vergleich\n",
    "\n",
    "In dieser √úbung schauen wir uns zwei Arten von neuronalen Netzen an:\n",
    "- **Multi-Layer Perceptron (MLP)**: Klassisches neuronales Netz mit vollverbundenen Schichten\n",
    "- **Convolutional Neural Network (CNN)**: Speziell f√ºr Bilddaten entwickelt\n",
    "\n",
    "Wir verwenden den **MNIST Dataset**: 28√ó28 Pixel Bilder handgeschriebener Ziffern (0-9) - der Klassiker f√ºr Computer Vision!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e44ddb1",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8434dd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# TensorFlow/Keras f√ºr Daten und beide Modelle\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Scikit-learn nur f√ºr Metriken\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(\"Bibliotheken geladen!\")\n",
    "print(f\"TensorFlow Version: {tf.__version__}\")\n",
    "\n",
    "# Reproducibility\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1c7017",
   "metadata": {},
   "source": [
    "## 2. Load and Explore the MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51f2911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST Dataset laden\n",
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "print(\"Dataset Informationen:\")\n",
    "print(f\"Training Bilder: {X_train_full.shape[0]}\")\n",
    "print(f\"Test Bilder: {X_test.shape[0]}\")\n",
    "print(f\"Bildgr√∂√üe: {X_train_full.shape[1]}√ó{X_train_full.shape[2]} Pixel\")\n",
    "print(f\"Anzahl Klassen: {len(np.unique(y_train_full))}\")\n",
    "print(f\"Klassen: {np.unique(y_train_full)}\")\n",
    "print(f\"Pixel-Werte: {X_train_full.min()} bis {X_train_full.max()}\")\n",
    "\n",
    "# F√ºr schnelleres Training: nur Subset verwenden\n",
    "subset_size = 10000  # Statt 60000\n",
    "indices = np.random.choice(len(X_train_full), subset_size, replace=False)\n",
    "X_train = X_train_full[indices]\n",
    "y_train = y_train_full[indices]\n",
    "\n",
    "print(f\"\\nVerwendet f√ºr Training: {len(X_train)} Bilder\")\n",
    "\n",
    "# Einige Beispielbilder anzeigen\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 6))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(X_train[i], cmap='gray')\n",
    "    ax.set_title(f'Label: {y_train[i]}')\n",
    "    ax.axis('off')\n",
    "plt.suptitle('Beispielbilder aus dem MNIST Dataset')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ad3313",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17dff2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten normalisieren\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} Bilder\")\n",
    "print(f\"Test set: {X_test.shape[0]} Bilder\")\n",
    "\n",
    "# Daten f√ºr MLP: flach machen (28√ó28 ‚Üí 784)\n",
    "X_train_mlp = X_train.reshape(-1, 28*28)\n",
    "X_test_mlp = X_test.reshape(-1, 28*28)\n",
    "\n",
    "# Daten f√ºr CNN: Channel-Dimension hinzuf√ºgen\n",
    "X_train_cnn = X_train.reshape(-1, 28, 28, 1)\n",
    "X_test_cnn = X_test.reshape(-1, 28, 28, 1)\n",
    "\n",
    "print(f\"\\nMLP Input Shape: {X_train_mlp.shape}\")\n",
    "print(f\"CNN Input Shape: {X_train_cnn.shape}\")\n",
    "\n",
    "# Test-Subset f√ºr schnellere Evaluation\n",
    "test_subset_size = 2000\n",
    "test_indices = np.random.choice(len(X_test), test_subset_size, replace=False)\n",
    "X_test_mlp = X_test_mlp[test_indices]\n",
    "X_test_cnn = X_test_cnn[test_indices]\n",
    "y_test = y_test[test_indices]\n",
    "\n",
    "print(f\"Test subset f√ºr Evaluation: {len(X_test_mlp)} Bilder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff8fd88",
   "metadata": {},
   "source": [
    "## 4. Multi-Layer Perceptron (MLP) Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08006407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP mit Keras (f√ºr Konsistenz)\n",
    "print(\"Aufbau MLP Modell...\")\n",
    "\n",
    "mlp_model = keras.Sequential([\n",
    "    layers.Dense(128, activation='relu', input_shape=(784,)),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "mlp_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"MLP Architektur:\")\n",
    "mlp_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6b19b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP trainieren\n",
    "print(\"Training MLP...\")\n",
    "mlp_history = mlp_model.fit(\n",
    "    X_train_mlp, y_train,\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    validation_split=0.1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# MLP evaluieren\n",
    "mlp_loss, mlp_accuracy = mlp_model.evaluate(X_test_mlp, y_test, verbose=0)\n",
    "print(f\"\\nMLP Test Genauigkeit: {mlp_accuracy:.4f}\")\n",
    "\n",
    "# Vorhersagen f√ºr sp√§teren Vergleich\n",
    "y_pred_mlp = np.argmax(mlp_model.predict(X_test_mlp, verbose=0), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd4ff88",
   "metadata": {},
   "source": [
    "## 5. Convolutional Neural Network (CNN) Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb43dcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN mit Keras\n",
    "print(\"Aufbau CNN Modell...\")\n",
    "\n",
    "cnn_model = keras.Sequential([\n",
    "    # Erste Convolutional Block\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    layers.MaxPooling2D(2, 2),\n",
    "    \n",
    "    # Zweite Convolutional Block\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(2, 2),\n",
    "    \n",
    "    # Dritte Convolutional Block\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    \n",
    "    # Flatten und Dense Layers\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"CNN Architektur:\")\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8ba137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN trainieren\n",
    "print(\"Training CNN...\")\n",
    "cnn_history = cnn_model.fit(\n",
    "    X_train_cnn, y_train,\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    validation_split=0.1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# CNN evaluieren\n",
    "cnn_loss, cnn_accuracy = cnn_model.evaluate(X_test_cnn, y_test, verbose=0)\n",
    "print(f\"\\nCNN Test Genauigkeit: {cnn_accuracy:.4f}\")\n",
    "\n",
    "# Vorhersagen f√ºr Vergleich\n",
    "y_pred_cnn = np.argmax(cnn_model.predict(X_test_cnn, verbose=0), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714d6fc0",
   "metadata": {},
   "source": [
    "## 6. Model Comparison and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62fd56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vergleich der Modelle\n",
    "print(\"=== MODELL VERGLEICH ===\")\n",
    "print(f\"MLP Genauigkeit:  {mlp_accuracy:.4f}\")\n",
    "print(f\"CNN Genauigkeit:  {cnn_accuracy:.4f}\")\n",
    "print(f\"Verbesserung:     {cnn_accuracy - mlp_accuracy:.4f}\")\n",
    "\n",
    "# Parameter-Anzahl vergleichen\n",
    "mlp_params = mlp_model.count_params()\n",
    "cnn_params = cnn_model.count_params()\n",
    "print(f\"\\nMLP Parameter:    {mlp_params:,}\")\n",
    "print(f\"CNN Parameter:    {cnn_params:,}\")\n",
    "print(f\"Verh√§ltnis CNN/MLP: {cnn_params/mlp_params:.1f}√ó\")\n",
    "\n",
    "# Training History Visualisierung\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(mlp_history.history['loss'], label='MLP Training')\n",
    "plt.plot(mlp_history.history['val_loss'], label='MLP Validation')\n",
    "plt.plot(cnn_history.history['loss'], label='CNN Training')\n",
    "plt.plot(cnn_history.history['val_loss'], label='CNN Validation')\n",
    "plt.title('Training Loss Vergleich')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(mlp_history.history['accuracy'], label='MLP Training')\n",
    "plt.plot(mlp_history.history['val_accuracy'], label='MLP Validation')\n",
    "plt.plot(cnn_history.history['accuracy'], label='CNN Training')\n",
    "plt.plot(cnn_history.history['val_accuracy'], label='CNN Validation')\n",
    "plt.title('Training Accuracy Vergleich')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "models = ['MLP', 'CNN']\n",
    "accuracies = [mlp_accuracy, cnn_accuracy]\n",
    "colors = ['skyblue', 'lightcoral']\n",
    "plt.bar(models, accuracies, color=colors)\n",
    "plt.title('Test Accuracy Vergleich')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0.9, 1.0)\n",
    "for i, acc in enumerate(accuracies):\n",
    "    plt.text(i, acc + 0.002, f'{acc:.3f}', ha='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d31fb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konfusionsmatrizen vergleichen\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# MLP Konfusionsmatrix\n",
    "cm_mlp = confusion_matrix(y_test, y_pred_mlp)\n",
    "im1 = axes[0].imshow(cm_mlp, interpolation='nearest', cmap='Blues')\n",
    "axes[0].set_title(f'MLP Confusion Matrix\\nAccuracy: {mlp_accuracy:.3f}')\n",
    "axes[0].set_ylabel('True Label')\n",
    "axes[0].set_xlabel('Predicted Label')\n",
    "axes[0].set_xticks(range(10))\n",
    "axes[0].set_yticks(range(10))\n",
    "\n",
    "# CNN Konfusionsmatrix\n",
    "cm_cnn = confusion_matrix(y_test, y_pred_cnn)\n",
    "im2 = axes[1].imshow(cm_cnn, interpolation='nearest', cmap='Blues')\n",
    "axes[1].set_title(f'CNN Confusion Matrix\\nAccuracy: {cnn_accuracy:.3f}')\n",
    "axes[1].set_ylabel('True Label')\n",
    "axes[1].set_xlabel('Predicted Label')\n",
    "axes[1].set_xticks(range(10))\n",
    "axes[1].set_yticks(range(10))\n",
    "\n",
    "# Zahlen in die Matrizen schreiben (nur bei kleinen Werten f√ºr Lesbarkeit)\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        if cm_mlp[i, j] > 0:\n",
    "            axes[0].text(j, i, str(cm_mlp[i, j]), ha='center', va='center', \n",
    "                        color='white' if cm_mlp[i, j] > cm_mlp.max()/2 else 'black', fontsize=8)\n",
    "        if cm_cnn[i, j] > 0:\n",
    "            axes[1].text(j, i, str(cm_cnn[i, j]), ha='center', va='center',\n",
    "                        color='white' if cm_cnn[i, j] > cm_cnn.max()/2 else 'black', fontsize=8)\n",
    "\n",
    "plt.colorbar(im1, ax=axes[0])\n",
    "plt.colorbar(im2, ax=axes[1])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff94eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beispiel-Vorhersagen visualisieren\n",
    "fig, axes = plt.subplots(3, 8, figsize=(16, 8))\n",
    "\n",
    "# Nehme 8 zuf√§llige Test-Beispiele\n",
    "np.random.seed(42)\n",
    "sample_indices = np.random.choice(len(X_test_cnn), 8, replace=False)\n",
    "\n",
    "for i, idx in enumerate(sample_indices):\n",
    "    # Originalbild\n",
    "    axes[0, i].imshow(X_test_cnn[idx].reshape(28, 28), cmap='gray')\n",
    "    axes[0, i].set_title(f'True: {y_test[idx]}', fontsize=10)\n",
    "    axes[0, i].axis('off')\n",
    "    \n",
    "    # MLP Vorhersage\n",
    "    mlp_pred = y_pred_mlp[idx]\n",
    "    mlp_color = 'green' if mlp_pred == y_test[idx] else 'red'\n",
    "    axes[1, i].text(0.5, 0.5, f'MLP\\n{mlp_pred}', transform=axes[1, i].transAxes,\n",
    "                   ha='center', va='center', fontsize=14, color=mlp_color, weight='bold')\n",
    "    axes[1, i].axis('off')\n",
    "    \n",
    "    # CNN Vorhersage\n",
    "    cnn_pred = y_pred_cnn[idx]\n",
    "    cnn_color = 'green' if cnn_pred == y_test[idx] else 'red'\n",
    "    axes[2, i].text(0.5, 0.5, f'CNN\\n{cnn_pred}', transform=axes[2, i].transAxes,\n",
    "                   ha='center', va='center', fontsize=14, color=cnn_color, weight='bold')\n",
    "    axes[2, i].axis('off')\n",
    "\n",
    "axes[0, 0].set_ylabel('Original', fontsize=12)\n",
    "axes[1, 0].set_ylabel('MLP Pred.', fontsize=12)\n",
    "axes[2, 0].set_ylabel('CNN Pred.', fontsize=12)\n",
    "plt.suptitle('Beispiel-Vorhersagen: Gr√ºn = Richtig, Rot = Falsch', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Fehleranalyse: Wo macht das CNN weniger Fehler als das MLP?\n",
    "mlp_errors = (y_pred_mlp != y_test)\n",
    "cnn_errors = (y_pred_cnn != y_test)\n",
    "cnn_better = mlp_errors & ~cnn_errors  # MLP falsch, CNN richtig\n",
    "\n",
    "print(f\"\\nFehleranalyse:\")\n",
    "print(f\"MLP Fehler: {mlp_errors.sum()}/{len(y_test)} ({100*mlp_errors.mean():.1f}%)\")\n",
    "print(f\"CNN Fehler: {cnn_errors.sum()}/{len(y_test)} ({100*cnn_errors.mean():.1f}%)\")\n",
    "print(f\"CNN besser als MLP: {cnn_better.sum()} F√§lle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c263a9f",
   "metadata": {},
   "source": [
    "## üéØ Fazit und Erkenntnisse\n",
    "\n",
    "**Wichtige Beobachtungen:**\n",
    "\n",
    "1. **CNNs sind deutlich besser f√ºr Bilder**: Bei MNIST (28√ó28) zeigt sich der CNN-Vorteil klar - typisch 2-4% bessere Accuracy als MLPs.\n",
    "\n",
    "2. **Parameter-Effizienz bei gr√∂√üeren Bildern**: Obwohl das CNN hier mehr Parameter hat, skaliert es bei noch gr√∂√üeren Bildern besser als MLPs.\n",
    "\n",
    "3. **R√§umliche Strukturerkennung**: CNNs erkennen lokale Muster (Striche, Kurven) und kombinieren sie zu komplexeren Formen - perfekt f√ºr handgeschriebene Ziffern.\n",
    "\n",
    "4. **Robustheit**: CNNs sind oft robuster gegen Verschiebungen und kleine Verzerrungen der Bilder.\n",
    "\n",
    "**Typische Ergebnisse:**\n",
    "- **MLP auf MNIST:** ~97-98% Accuracy\n",
    "- **CNN auf MNIST:** ~99%+ Accuracy\n",
    "\n",
    "**Wann welches Modell?**\n",
    "- **MLP**: Tabellarische Daten, kleine Bilder, schnelle Prototypen\n",
    "- **CNN**: Bilder aller Gr√∂√üen, Computer Vision, wenn r√§umliche Struktur wichtig ist\n",
    "\n",
    "**Der Durchbruch:** Erst bei \"echten\" Bildgr√∂√üen (28√ó28 und gr√∂√üer) zeigen CNNs ihre wahre St√§rke. Bei winzigen 8√ó8 Bildern k√∂nnen MLPs noch mithalten.\n",
    "\n",
    "**Zum Experimentieren:**\n",
    "- Ver√§ndere die CNN-Architektur (mehr/weniger Filter, andere Kernel-Gr√∂√üen)\n",
    "- Probiere andere Optimierer aus (SGD mit Momentum)\n",
    "- Teste mit noch gr√∂√üeren Datens√§tzen (CIFAR-10, ImageNet)\n",
    "- Implementiere Data Augmentation (Rotation, Translation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lecture_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
