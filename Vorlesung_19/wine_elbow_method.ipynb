{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6165f627",
   "metadata": {},
   "source": [
    "# Elbow-Methode mit dem Wine-Datensatz\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/klar74/WS2025_lecture/blob/main/Vorlesung_19/wine_elbow_method.ipynb)\n",
    "\n",
    "In diesem Notebook lernen wir die **Elbow-Methode** kennen ‚Äì das wichtigste Verfahren zur Bestimmung der optimalen Anzahl Cluster bei k-Means.\n",
    "\n",
    "**Ziel:** Herausfinden, wie viele Cluster im Wine-Datensatz optimal sind, ohne die echten Labels zu kennen.\n",
    "\n",
    "**Das Szenario:** Stellt euch vor, ihr seid Weinh√§ndler und bekommt 178 Weine ohne Etiketten. Wie viele verschiedene Produzenten/Stile gibt es wohl?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b91142d",
   "metadata": {},
   "source": [
    "## 1. Bibliotheken importieren und Daten laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea5cdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score, adjusted_rand_score\n",
    "\n",
    "# F√ºr sch√∂nere Plots\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"üç∑ Wine-Datensatz Elbow-Methode Notebook geladen!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e25d2f0",
   "metadata": {},
   "source": [
    "## 2. Wine-Datensatz verstehen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc46789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wine-Datensatz aus sklearn laden\n",
    "wine = load_wine()\n",
    "\n",
    "print(\"üìä Wine-Datensatz √úberblick:\")\n",
    "print(f\"Anzahl Weine: {wine.data.shape[0]}\")\n",
    "print(f\"Anzahl chemische Eigenschaften: {wine.data.shape[1]}\")\n",
    "print(f\"Echte Produzenten: {wine.target_names}\")\n",
    "\n",
    "# Echte Verteilung (die wir \"vergessen\" f√ºr k-Means)\n",
    "unique, counts = np.unique(wine.target, return_counts=True)\n",
    "print(\"\\nüè≠ Echte Produzenten-Verteilung:\")\n",
    "for i, (name, count) in enumerate(zip(wine.target_names, counts)):\n",
    "    print(f\"  {name}: {count} Weine\")\n",
    "\n",
    "print(\"\\nüî¨ Chemische Eigenschaften:\")\n",
    "for i, feature in enumerate(wine.feature_names[:5]):\n",
    "    print(f\"  {i+1}. {feature}\")\n",
    "print(\"  ... und 8 weitere\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1c2ec1",
   "metadata": {},
   "source": [
    "## 3. Daten vorbereiten (Skalierung!)\n",
    "\n",
    "**Wichtig:** Der Wine-Datensatz hat sehr unterschiedliche Skalen (Alkohol 11-15% vs. Proline 278-1680 mg/L). Ohne Skalierung w√ºrde k-Means nur die gro√üen Zahlen sehen!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a82d04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skalierungsproblem zeigen\n",
    "print(\"‚ö†Ô∏è Skalierungsproblem demonstrieren:\")\n",
    "print(f\"Alkohol: {wine.data[:, 0].min():.1f} - {wine.data[:, 0].max():.1f} %\")\n",
    "print(f\"Proline: {wine.data[:, 12].min():.0f} - {wine.data[:, 12].max():.0f} mg/L\")\n",
    "print(f\"Faktor-Unterschied: {wine.data[:, 12].max() / wine.data[:, 0].max():.0f}x!\")\n",
    "\n",
    "# Alle Features skalieren\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(wine.data)\n",
    "\n",
    "print(\"\\n‚úÖ Nach StandardScaler:\")\n",
    "print(f\"Mittelwerte (alle ~0): {X_scaled.mean(axis=0)[:3]}\")\n",
    "print(f\"Std-Abweichungen (alle ~1): {X_scaled.std(axis=0)[:3]}\")\n",
    "print(\"‚Üí Jetzt sind alle Features gleichberechtigt!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9546b33",
   "metadata": {},
   "source": [
    "## 4. Elbow-Methode durchf√ºhren\n",
    "\n",
    "Wir probieren verschiedene k-Werte aus (k=1 bis k=10) und schauen, wie sich die **Intra-Cluster-Varianz** (Inertia) entwickelt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1167f1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verschiedene k-Werte testen\n",
    "k_range = range(1, 11)\n",
    "inertias = []\n",
    "silhouette_scores = []\n",
    "\n",
    "print(\"üîç Elbow-Methode l√§uft...\")\n",
    "for k in k_range:\n",
    "    # k-Means f√ºr aktuelles k\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    cluster_labels = kmeans.fit_predict(X_scaled)\n",
    "    \n",
    "    # Inertia speichern\n",
    "    inertias.append(kmeans.inertia_)\n",
    "    \n",
    "    # Silhouette Score (nur f√ºr k >= 2)\n",
    "    if k >= 2:\n",
    "        sil_score = silhouette_score(X_scaled, cluster_labels)\n",
    "        silhouette_scores.append(sil_score)\n",
    "    else:\n",
    "        silhouette_scores.append(0)  # k=1 hat keinen Silhouette Score\n",
    "    \n",
    "    print(f\"k={k}: Inertia={kmeans.inertia_:.2f}, Silhouette={silhouette_scores[-1]:.3f}\")\n",
    "\n",
    "print(\"‚úÖ Elbow-Methode abgeschlossen!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e3a3cf",
   "metadata": {},
   "source": [
    "## 5. Elbow-Plot visualisieren\n",
    "\n",
    "Jetzt schauen wir, wo die Kurve \"abknickt\" ‚Äì das ist unser optimales k!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667ed69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elbow-Plot erstellen\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Plot 1: Inertia (Elbow-Methode)\n",
    "ax1.plot(k_range, inertias, 'bo-', markersize=8, linewidth=2, label='Intra-Cluster-Varianz')\n",
    "ax1.axvline(x=3, color='red', linestyle='--', alpha=0.7, label='k=3 (echte Anzahl)')\n",
    "ax1.set_xlabel('Anzahl Cluster (k)')\n",
    "ax1.set_ylabel('Intra-Cluster-Varianz (Inertia)')\n",
    "ax1.set_title('Elbow-Methode: Wo knickt die Kurve ab?')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Annotationen f√ºr wichtige Punkte\n",
    "ax1.annotate('Starker Abfall', xy=(2, inertias[1]), xytext=(2.5, inertias[1] + 50),\n",
    "            arrowprops=dict(arrowstyle='->', color='orange'), fontsize=10)\n",
    "ax1.annotate('Ellenbogen?\\nk=3', xy=(3, inertias[2]), xytext=(4, inertias[2] + 30),\n",
    "            arrowprops=dict(arrowstyle='->', color='red'), fontsize=10)\n",
    "\n",
    "# Plot 2: Silhouette Score\n",
    "k_range_sil = range(2, 11)  # Silhouette nur f√ºr k >= 2\n",
    "ax2.plot(k_range_sil, silhouette_scores[1:], 'go-', markersize=8, linewidth=2, label='Silhouette Score')\n",
    "ax2.axvline(x=3, color='red', linestyle='--', alpha=0.7, label='k=3 (echte Anzahl)')\n",
    "ax2.set_xlabel('Anzahl Cluster (k)')\n",
    "ax2.set_ylabel('Silhouette Score')\n",
    "ax2.set_title('Silhouette Score: H√∂her = bessere Trennung')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Besten Silhouette Score markieren\n",
    "best_k_sil = k_range_sil[np.argmax(silhouette_scores[1:])]\n",
    "ax2.annotate(f'Maximum\\nk={best_k_sil}', \n",
    "            xy=(best_k_sil, max(silhouette_scores[1:])), \n",
    "            xytext=(best_k_sil + 1, max(silhouette_scores[1:]) + 0.02),\n",
    "            arrowprops=dict(arrowstyle='->', color='green'), fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üëÅÔ∏è Interpretation des Elbow-Plots:\")\n",
    "print(\"‚Ä¢ Links: Suche den 'Ellenbogen' - wo die Kurve stark abflacht\")\n",
    "print(\"‚Ä¢ Rechts: Silhouette Score als zus√§tzliche Best√§tigung\")\n",
    "print(f\"‚Ä¢ Elbow-Methode deutet auf k={3} hin\")\n",
    "print(f\"‚Ä¢ Silhouette Score ist maximal bei k={best_k_sil}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9b27ee",
   "metadata": {},
   "source": [
    "## 6. Detailanalyse: k=2, k=3, k=4 vergleichen\n",
    "\n",
    "Schauen wir uns die \"Kandidaten\" genauer an:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2281fb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailvergleich f√ºr k=2, 3, 4\n",
    "candidate_ks = [2, 3, 4]\n",
    "results = {}\n",
    "\n",
    "print(\"üî¨ Detailanalyse der Kandidaten:\")\n",
    "print(f\"{'k':<3} {'Inertia':<10} {'Silhouette':<12} {'ARI':<8} {'Interpretation':<15}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for k in candidate_ks:\n",
    "    # k-Means anwenden\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    labels = kmeans.fit_predict(X_scaled)\n",
    "    \n",
    "    # Metriken berechnen\n",
    "    inertia = kmeans.inertia_\n",
    "    silhouette = silhouette_score(X_scaled, labels)\n",
    "    ari = adjusted_rand_score(wine.target, labels)  # Vergleich mit echten Labels\n",
    "    \n",
    "    # Cluster-Gr√∂√üen\n",
    "    unique_labels, counts = np.unique(labels, return_counts=True)\n",
    "    \n",
    "    results[k] = {\n",
    "        'inertia': inertia,\n",
    "        'silhouette': silhouette,\n",
    "        'ari': ari,\n",
    "        'cluster_sizes': counts\n",
    "    }\n",
    "    \n",
    "    # Qualit√§tsbewertung\n",
    "    if ari > 0.8:\n",
    "        quality = \"Exzellent\"\n",
    "    elif ari > 0.6:\n",
    "        quality = \"Sehr gut\"\n",
    "    elif ari > 0.4:\n",
    "        quality = \"Gut\"\n",
    "    else:\n",
    "        quality = \"M√§√üig\"\n",
    "    \n",
    "    print(f\"{k:<3} {inertia:<10.2f} {silhouette:<12.3f} {ari:<8.3f} {quality:<15}\")\n",
    "    print(f\"    Cluster-Gr√∂√üen: {counts}\")\n",
    "\n",
    "print(\"\\nüí° Erkenntnisse:\")\n",
    "print(\"‚Ä¢ k=2: Einfache Teilung, aber √ºbersieht Feinstrukturen\")\n",
    "print(\"‚Ä¢ k=3: Bester Kompromiss - findet echte Produzenten gut (ARI={results[3]['ari']:.3f})\")\n",
    "print(\"‚Ä¢ k=4: √úberfitting - teilt echte Cluster unn√∂tig auf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea25b464",
   "metadata": {},
   "source": [
    "## 7. Finale Entscheidung: k=3 anwenden\n",
    "\n",
    "Basierend auf Elbow-Methode und Silhouette Score w√§hlen wir k=3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b192687d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finales k-Means mit k=3\n",
    "print(\"üèÜ Finales k-Means Clustering mit k=3:\")\n",
    "kmeans_final = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
    "final_labels = kmeans_final.fit_predict(X_scaled)\n",
    "final_centers = kmeans_final.cluster_centers_\n",
    "\n",
    "# Ergebnisse analysieren\n",
    "final_ari = adjusted_rand_score(wine.target, final_labels)\n",
    "final_silhouette = silhouette_score(X_scaled, final_labels)\n",
    "\n",
    "print(\"üìä Finale Bewertung:\")\n",
    "print(\"‚Ä¢ Adjusted Rand Index: {final_ari:.3f} (1.0 = perfekt)\")\n",
    "print(\"‚Ä¢ Silhouette Score: {final_silhouette:.3f} (1.0 = perfekt getrennt)\")\n",
    "\n",
    "# Cluster-Gr√∂√üen vs. echte Verteilung\n",
    "print(\"\\nüìà Cluster-Verteilung:\")\n",
    "unique_final, counts_final = np.unique(final_labels, return_counts=True)\n",
    "print(\"k-Means gefunden:\")\n",
    "for cluster, count in zip(unique_final, counts_final):\n",
    "    print(f\"  Cluster {cluster}: {count} Weine\")\n",
    "\n",
    "print(\"\\nEchte Produzenten:\")\n",
    "unique_real, counts_real = np.unique(wine.target, return_counts=True)\n",
    "for i, (name, count) in enumerate(zip(wine.target_names, counts_real)):\n",
    "    print(f\"  {name}: {count} Weine\")\n",
    "\n",
    "print(\"\\nüéØ Fazit:\")\n",
    "if final_ari > 0.8:\n",
    "    print(\"‚úÖ Exzellent! k-Means hat die echten Produzenten sehr gut gefunden.\")\n",
    "elif final_ari > 0.6:\n",
    "    print(\"‚úÖ Sehr gut! k-Means findet die Hauptstrukturen.\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è M√§√üig. Die Daten sind komplexer als erwartet.\")\n",
    "\n",
    "print(\"Die Elbow-Methode hat uns erfolgreich zu k=3 gef√ºhrt! üöÄ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32caa797",
   "metadata": {},
   "source": [
    "## 8. Bonus: Confusion Matrix - Wer wurde wie zugeordnet?\n",
    "\n",
    "Schauen wir genauer, welche Weine k-Means welchem Cluster zugeordnet hat:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1e41dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix zwischen k-Means und echten Labels\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Einfache Zuordnung: F√ºr jeden k-Means Cluster das h√§ufigste echte Label finden\n",
    "print(\"üîç k-Means Cluster zu echten Labels zuordnen...\")\n",
    "cluster_to_label = {}\n",
    "\n",
    "for cluster in range(3):\n",
    "    # Alle Weine in diesem k-Means Cluster\n",
    "    cluster_mask = final_labels == cluster\n",
    "    cluster_true_labels = wine.target[cluster_mask]\n",
    "    \n",
    "    # H√§ufigstes echtes Label in diesem Cluster\n",
    "    unique_labels, counts = np.unique(cluster_true_labels, return_counts=True)\n",
    "    most_common_label = unique_labels[np.argmax(counts)]\n",
    "    \n",
    "    cluster_to_label[cluster] = most_common_label\n",
    "    print(f\"  k-Means Cluster {cluster} ‚Üí {wine.target_names[most_common_label]} ({max(counts)}/{len(cluster_true_labels)} Weine)\")\n",
    "\n",
    "# Labels entsprechend zuordnen\n",
    "final_labels_mapped = np.array([cluster_to_label[label] for label in final_labels])\n",
    "\n",
    "# Confusion Matrix mit zugeordneten Labels\n",
    "cm = confusion_matrix(wine.target, final_labels_mapped)\n",
    "\n",
    "# Visualisierung\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "           xticklabels=wine.target_names,\n",
    "           yticklabels=wine.target_names)\n",
    "plt.xlabel('k-Means Vorhersage (zugeordnet)')\n",
    "plt.ylabel('Echte Produzenten')\n",
    "plt.title('Confusion Matrix: k-Means vs. Echte Labels (zugeordnet)')\n",
    "plt.show()\n",
    "\n",
    "print(\"üßê Confusion Matrix Interpretation:\")\n",
    "print(\"‚Ä¢ Zeilen: Echte Produzenten\")\n",
    "print(\"‚Ä¢ Spalten: k-Means Cluster\") \n",
    "print(\"‚Ä¢ Diagonale: Korrekt zugeordnete Weine\")\n",
    "print(\"‚Ä¢ Off-Diagonale: 'Verwechslungen'\")\n",
    "\n",
    "# Genauigkeit pro Produzent\n",
    "print(\"\\nüìä Zuordnungsqualit√§t pro Produzent:\")\n",
    "for i, producer in enumerate(wine.target_names):\n",
    "    correct = cm[i, i] if i < len(cm) else 0\n",
    "    total = sum(cm[i, :]) if i < len(cm) else 0\n",
    "    accuracy = correct / total if total > 0 else 0\n",
    "    print(f\"  {producer}: {correct}/{total} = {accuracy:.2%} korrekt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cc4884",
   "metadata": {},
   "source": [
    "## 9. Zusammenfassung: Was haben wir gelernt?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3673a2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üéì Wichtige Erkenntnisse aus der Elbow-Methode:\")\n",
    "print()\n",
    "print(\"1Ô∏è‚É£ Elbow-Methode Vorgehen:\")\n",
    "print(\"   ‚Ä¢ Verschiedene k-Werte testen (k=1,2,3,...)\")\n",
    "print(\"   ‚Ä¢ Intra-Cluster-Varianz plotten\")\n",
    "print(\"   ‚Ä¢ 'Ellenbogen' suchen - wo Verbesserung stark abnimmt\")\n",
    "print()\n",
    "print(\"2Ô∏è‚É£ Zus√§tzliche Metriken nutzen:\")\n",
    "print(\"   ‚Ä¢ Silhouette Score f√ºr Cluster-Qualit√§t\")\n",
    "print(\"   ‚Ä¢ Bei bekannten Labels: ARI f√ºr Vergleich\")\n",
    "print(\"   ‚Ä¢ Cluster-Gr√∂√üen sollten sinnvoll sein\")\n",
    "print()\n",
    "print(\"3Ô∏è‚É£ Praktische Tipps:\")\n",
    "print(\"   ‚Ä¢ Immer zuerst skalieren! (StandardScaler)\")\n",
    "print(\"   ‚Ä¢ Mehrere random_state testen\")\n",
    "print(\"   ‚Ä¢ Domain-Wissen einbeziehen\")\n",
    "print(\"   ‚Ä¢ Visualisierung hilft beim Verstehen\")\n",
    "print()\n",
    "print(\"4Ô∏è‚É£ Unser Ergebnis:\")\n",
    "print(\"   ‚Ä¢ Elbow-Methode ‚Üí k=3 optimal\")\n",
    "print(\"   ‚Ä¢ ARI = {final_ari:.3f} (sehr gute √úbereinstimmung)\")\n",
    "print(\"   ‚Ä¢ k-Means fand die 3 Produzenten ohne Labels!\")\n",
    "print()\n",
    "print(\"üöÄ Die Elbow-Methode ist ein m√§chtiges Werkzeug zur\")\n",
    "print(\"   automatischen Bestimmung der optimalen Cluster-Anzahl!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lecture_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
