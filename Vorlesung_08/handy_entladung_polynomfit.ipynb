{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ“± Was ist Overfitting? - Ein Smartphone-Beispiel\n",
    "\n",
    "Hey! ğŸ‘‹ Willkommen zu deinem ersten Data Science Experiment!\n",
    "\n",
    "## ğŸ¤” Stell dir vor...\n",
    "\n",
    "Du hast ein **neues Smartphone** und willst wissen: *\"Wie lange hÃ¤lt mein Akku?\"*\n",
    "\n",
    "Du misst ein paar Mal die Akku-Entladung und willst daraus **vorhersagen**, wie sich der Akku in Zukunft verhÃ¤lt.\n",
    "\n",
    "**Aber Achtung!** ğŸš¨ Es gibt einen Fehler, den fast alle AnfÃ¤nger machen...\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ Was lernst du heute?\n",
    "\n",
    "âœ… Was **Overfitting** bedeutet (in einfachen Worten!)  \n",
    "âœ… Warum **\"perfekte\" Ergebnisse oft schlecht** sind  \n",
    "âœ… Wie du **gute von schlechten** Modellen unterscheidest  \n",
    " \n",
    "**Python-Kenntnisse:** Keine nÃ¶tig! ğŸ˜Š"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸš€ Los geht's! (Keine Panik - alles erklÃ¤rt!)\n",
    "\n",
    "Zuerst laden wir die \"Werkzeuge\" - das macht Python automatisch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Das sind unsere \"Werkzeuge\" fÃ¼r heute\n",
    "import numpy as np                    # FÃ¼r Zahlen und Berechnungen\n",
    "import matplotlib.pyplot as plt       # FÃ¼r schÃ¶ne Diagramme\n",
    "\n",
    "# Einstellungen fÃ¼r schÃ¶ne Diagramme\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "# Sorgt dafÃ¼r, dass wir alle die gleichen \"zufÃ¤lligen\" Daten bekommen\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"ğŸ‰ Alles bereit! Jetzt kann's losgehen!\")\n",
    "print(\"ğŸ’¡ Tipp: Klicke einfach auf 'Run' fÃ¼r jede Zelle\")\n",
    "print(\"\\nğŸ”§ Unsere wichtigsten Werkzeuge heute:\")\n",
    "print(\"   ğŸ“ np.polyfit() = Findet mathematische Kurven durch Punkte\")\n",
    "print(\"   ğŸ“Š plt.plot() = Zeichnet schÃ¶ne Diagramme\")\n",
    "print(\"   ğŸ§® np.polyval() = Macht Vorhersagen mit den Kurven\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“± Schritt 1: Deine Smartphone-Daten sammeln\n",
    "\n",
    "Stell dir vor: Du hast dein Handy **8 Stunden lang** benutzt und **9 Mal** den Akku-Stand gemessen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deine Messungen: Wann hast du gemessen? (in Stunden)\n",
    "zeit_stunden = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8])\n",
    "\n",
    "# Deine Messungen: Wie viel Akku war noch da? (in Prozent)\n",
    "akku_prozent = np.array([100, 89, 76, 61, 52, 38, 28, 15, 8])\n",
    "\n",
    "# addiere Rauschen (um es realistischer zu machen)\n",
    "akku_prozent = akku_prozent + np.random.normal(0, 5, size=akku_prozent.shape)\n",
    "akku_prozent = np.clip(akku_prozent, 0, 100)  #\n",
    "\n",
    "print(\"ğŸ“Š Deine Messungen:\")\n",
    "print(\"Stunde | Akku\")\n",
    "print(\"-------|------\")\n",
    "for i in range(len(zeit_stunden)):\n",
    "    print(f\"  {zeit_stunden[i]:2.0f}   | {akku_prozent[i]:3.0f}%\")\n",
    "\n",
    "print(\"\\nğŸ¤” Frage: Kannst du daraus vorhersagen, wie lange dein Akku morgen hÃ¤lt?\")\n",
    "print(\"ğŸ’­ Genau das versuchen wir mit dem Computer herauszufinden!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š Schritt 2: Lass uns deine Daten anschauen!\n",
    "\n",
    "Ein Bild sagt mehr als 1000 Zahlen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstelle ein schÃ¶nes Diagramm deiner Messungen\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(zeit_stunden, akku_prozent, color='#FF6B6B', s=100, \n",
    "           edgecolors='black', linewidth=2, zorder=5)\n",
    "\n",
    "# Beschriftungen (damit jeder versteht, was gemeint ist)\n",
    "plt.xlabel('â° Zeit (Stunden)', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('ğŸ”‹ Akku (%)', fontsize=14, fontweight='bold')\n",
    "plt.title('ğŸ“± Deine Smartphone-Akku Messungen', fontsize=16, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xlim(-0.5, 8.5)\n",
    "plt.ylim(0, 105)\n",
    "\n",
    "# Punkte beschriften\n",
    "for i, (x, y) in enumerate(zip(zeit_stunden, akku_prozent)):\n",
    "    plt.annotate(f'{y:.1f}%', (x, y), xytext=(5, 5), textcoords='offset points', \n",
    "                fontweight='bold', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"ğŸ‘€ Was siehst du?\")\n",
    "print(\"ğŸ’¡ Der Akku wird immer leerer - das macht Sinn!\")\n",
    "print(\"ğŸ“‰ Die Punkte fallen von links nach rechts\")\n",
    "print(\"ğŸ¤” Aber wie kÃ¶nnen wir das fÃ¼r NEUE Tage vorhersagen?\")\n",
    "print(\"\\nğŸ¯ DafÃ¼r brauchen wir ein mathematisches Modell!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ§  Schritt 3: Der Computer lernt deine Daten\n",
    "\n",
    "Jetzt kommt der **KI-Teil**! Wir zeigen dem Computer deine Daten und er versucht ein **Muster** zu finden.\n",
    "\n",
    "### ğŸ”§ Die Werkzeuge erklÃ¤rt:\n",
    "- **`np.polyfit(x, y, deg=1)`** = \"Finde die beste GERADE durch die Punkte\"\n",
    "- **`deg=1`** = Gerade Linie (wie in Mathe: y = mx + b)\n",
    "- **`deg=8`** = Komplizierte Kurve (wie y = axâ¸ + bxâ· + ... + mx + b)\n",
    "\n",
    "### ğŸŸ¢ Versuch 1: Einfache Gerade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def einfache_gerade(x, y):\n",
    "    \"\"\"\n",
    "    Fittet eine GERADE durch deine Datenpunkte\n",
    "    Wie in Mathe: y = mx + b (Steigung + Achsenabschnitt)\n",
    "    \"\"\"\n",
    "    print(\"ğŸ¤– Computer denkt: 'Ich suche die beste Gerade durch die Punkte...'\")\n",
    "    \n",
    "    # np.polyfit mit degree=1 = Gerade Linie\n",
    "    koeffizienten = np.polyfit(x, y, deg=1)\n",
    "    \n",
    "    # Die Koeffizienten sind [Steigung, Achsenabschnitt]\n",
    "    steigung = koeffizienten[0]\n",
    "    achsenabschnitt = koeffizienten[1]\n",
    "    \n",
    "    print(f\"ğŸ¤– Computer sagt: 'Ich habe eine Gerade gefunden!'\")\n",
    "    print(f\"   ğŸ“ Steigung: {steigung:.2f} (Akku fÃ¤llt um {-steigung:.1f}% pro Stunde)\")\n",
    "    print(f\"   ğŸ“ Start: {achsenabschnitt:.1f}% (theoretischer Startwert)\")\n",
    "    print(f\"   ğŸ“ Formel: y = {steigung:.2f}x + {achsenabschnitt:.1f}\")\n",
    "    \n",
    "    # Funktion, die Vorhersagen macht\n",
    "    def vorhersage_funktion(neue_x_werte):\n",
    "        return np.polyval(koeffizienten, neue_x_werte)\n",
    "    \n",
    "    return vorhersage_funktion, koeffizienten\n",
    "\n",
    "def berechne_genauigkeit(echte_werte, vorhergesagte_werte):\n",
    "    \"\"\"\n",
    "    Berechnet, wie gut das Modell ist (RÂ² Score)\n",
    "    1.0 = perfekt (100%), 0.0 = schlecht (0%)\n",
    "    \"\"\"\n",
    "    # RÂ² berechnen: Wie viel Varianz erklÃ¤rt das Modell?\n",
    "    ss_res = np.sum((echte_werte - vorhergesagte_werte) ** 2)  # Summe der Fehlerquadrate\n",
    "    ss_tot = np.sum((echte_werte - np.mean(echte_werte)) ** 2)  # Gesamtvarianz\n",
    "    r2 = 1 - (ss_res / ss_tot)\n",
    "    return r2\n",
    "\n",
    "# Computer lernt von deinen Daten\n",
    "print(\"ğŸ“ LERNPHASE: Computer analysiert deine Akku-Daten...\")\n",
    "print()\n",
    "\n",
    "gerade_funktion, gerade_koeff = einfache_gerade(zeit_stunden, akku_prozent)\n",
    "\n",
    "# Computer macht Vorhersagen fÃ¼r alle deine Messzeiten\n",
    "vorhersagen_gerade = gerade_funktion(zeit_stunden)\n",
    "\n",
    "# Wie gut war der Computer?\n",
    "genauigkeit_gerade = berechne_genauigkeit(akku_prozent, vorhersagen_gerade)\n",
    "\n",
    "print()\n",
    "print(f\"ğŸ“Š ERGEBNIS: Computer ist zu {genauigkeit_gerade*100:.1f}% genau\")\n",
    "print(\"ğŸ¤” Ist das gut oder schlecht? Schauen wir uns das Ergebnis an...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisierung der Geraden-LÃ¶sung\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Deine echten Messungen\n",
    "plt.scatter(zeit_stunden, akku_prozent, color='#FF6B6B', s=30, \n",
    "           edgecolors='black', linewidth=2, label='ğŸ“± Deine Messungen', zorder=5)\n",
    "\n",
    "# Computer-Vorhersage (glatte Linie)\n",
    "zeit_glatt = np.linspace(0, 8, 100)  # Viele Punkte fÃ¼r glatte Linie\n",
    "vorhersage_glatt = gerade_funktion(zeit_glatt)\n",
    "plt.plot(zeit_glatt, vorhersage_glatt, color='#4ECDC4', \n",
    "         linewidth=3, label='ğŸ¤– Computer-Gerade')\n",
    "\n",
    "# Zeige die Abweichungen als gestrichelte Linien\n",
    "for i in range(len(zeit_stunden)):\n",
    "    plt.plot([zeit_stunden[i], zeit_stunden[i]], \n",
    "            [akku_prozent[i], vorhersagen_gerade[i]], \n",
    "            'gray', linestyle='--', alpha=0.5, linewidth=3)\n",
    "\n",
    "plt.xlabel('â° Zeit (Stunden)', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('ğŸ”‹ Akku (%)', fontsize=14, fontweight='bold')\n",
    "plt.title(f'ğŸŸ¢ Einfache Gerade - Genauigkeit: {genauigkeit_gerade*100:.1f}%', \n",
    "          fontsize=16, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend(fontsize=12)\n",
    "plt.xlim(-0.5, 8.5)\n",
    "plt.ylim(0, 105)\n",
    "\n",
    "# ErklÃ¤rungs-Box\n",
    "plt.text(0.02, 0.28, \n",
    "         f'ğŸ“ Mathematik:\\ny = {gerade_koeff[0]:.1f}x + {gerade_koeff[1]:.1f}\\n\\n' +\n",
    "         f'ğŸ”‹ Bedeutung:\\nAkku fÃ¤llt um {-gerade_koeff[0]:.1f}%\\npro Stunde', \n",
    "         transform=plt.gca().transAxes, \n",
    "         bbox=dict(boxstyle='round,pad=0.5', facecolor='lightblue', alpha=0.8),\n",
    "         fontsize=11, verticalalignment='top')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"ğŸ‘€ Was siehst du?\")\n",
    "print(\"âœ… Die Gerade folgt grob dem Trend (Akku wird leerer)\")\n",
    "print(\"âŒ Aber sie trifft nicht alle Punkte perfekt\")\n",
    "print(\"ğŸ¯ Die grauen Linien zeigen die Abweichungen\")\n",
    "print(\"ğŸ“ Manche Abweichungen sind grÃ¶ÃŸer, manche kleiner\")\n",
    "print(\"\\nğŸ¤” Denkst du: 'Der Computer soll ALLE Punkte treffen!'\")\n",
    "print(\"âš ï¸  Das ist ein gefÃ¤hrlicher Gedanke... schauen wir warum!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸš¨ Schritt 4: Der gefÃ¤hrliche Versuch\n",
    "\n",
    "Du denkst: *\"Hey, der Computer soll ALLE meine Punkte perfekt treffen!\"*\n",
    "\n",
    "DafÃ¼r verwenden wir ein **Polynom hohen Grades** - eine sehr komplizierte mathematische Kurve.\n",
    "\n",
    "### ğŸ”´ Versuch 2: Kompliziertes Polynom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def komplexes_polynom(x, y, grad=12):\n",
    "    \"\"\"\n",
    "    Fittet ein POLYNOM durch deine Datenpunkte\n",
    "    Grad 8 bedeutet: y = aâ‚ˆxâ¸ + aâ‚‡xâ· + aâ‚†xâ¶ + ... + aâ‚x + aâ‚€\n",
    "    Das ist SEHR kompliziert!\n",
    "    \"\"\"\n",
    "    print(f\"ğŸ¤– Computer denkt: 'Ich suche eine Kurve {grad}. Grades - das wird kompliziert!'\")\n",
    "    \n",
    "    # np.polyfit mit degree=8 = Sehr komplizierte Kurve\n",
    "    koeffizienten = np.polyfit(x, y, deg=grad)\n",
    "    \n",
    "    print(f\"ğŸ¤– Computer sagt: 'Fertig! Ich habe {len(koeffizienten)} Parameter gefunden:'\")\n",
    "    print(f\"   ğŸ”¢ Das sind {len(koeffizienten)} Zahlen fÃ¼r eine Kurve mit nur {len(x)} Datenpunkten!\")\n",
    "    print(f\"   ğŸ¤¯ Die Formel hÃ¤tte {grad+1} Terme: aâ‚ˆxâ¸ + aâ‚‡xâ· + ... + aâ‚x + aâ‚€\")\n",
    "    print(f\"   âš ï¸  Das ist verdÃ¤chtig kompliziert fÃ¼r so wenige Daten...\")\n",
    "    \n",
    "    # Zeige ein paar der Koeffizienten (die sind oft riesig!)\n",
    "    #print(f\"   ğŸ“Š Beispiel-Koeffizienten: {koeffizienten[:]} ...\")\n",
    "    #print(f\"   ğŸ˜µ Manche sind riesige Zahlen!\")\n",
    "    \n",
    "    # Funktion, die Vorhersagen macht\n",
    "    def vorhersage_funktion(neue_x_werte):\n",
    "        return np.polyval(koeffizienten, neue_x_werte)\n",
    "    \n",
    "    return vorhersage_funktion, koeffizienten\n",
    "\n",
    "# Computer lernt (zu viel!) von deinen Daten\n",
    "print(\"ğŸ“ GEFÃ„HRLICHE LERNPHASE: Computer wird zum Perfektionisten...\")\n",
    "print()\n",
    "\n",
    "polynom_grad = 25\n",
    "polynom_funktion, polynom_koeff = komplexes_polynom(zeit_stunden, akku_prozent, grad=polynom_grad)\n",
    "\n",
    "# Computer macht Vorhersagen\n",
    "vorhersagen_polynom = polynom_funktion(zeit_stunden)\n",
    "\n",
    "# Wie gut war der Computer diesmal?\n",
    "genauigkeit_polynom = berechne_genauigkeit(akku_prozent, vorhersagen_polynom)\n",
    "\n",
    "print()\n",
    "print(f\"ğŸ“Š ERGEBNIS: Computer ist zu {genauigkeit_polynom*100:.1f}% genau!\")\n",
    "print(\"ğŸ˜± WOW! Fast perfekt! Das muss doch super sein... oder?\")\n",
    "print(\"ğŸš¨ ACHTUNG: Lass uns schauen, was wirklich passiert ist...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Das ERSCHRECKENDE Ergebnis visualisieren\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Deine echten Messungen\n",
    "plt.scatter(zeit_stunden, akku_prozent, color='#FF6B6B', s=120, \n",
    "           edgecolors='black', linewidth=2, label='ğŸ“± Deine Messungen', zorder=5)\n",
    "\n",
    "# Computer-Vorhersage (die verrÃ¼ckte Kurve!)\n",
    "zeit_glatt = np.linspace(0, 8, 200)  # Mehr Punkte fÃ¼r die wilde Kurve\n",
    "vorhersage_polynom_glatt = polynom_funktion(zeit_glatt)\n",
    "plt.plot(zeit_glatt, vorhersage_polynom_glatt, color='#FF4757', \n",
    "         linewidth=3, label=f'ğŸ¤– Computer-Polynom (Grad {polynom_grad})')\n",
    "\n",
    "plt.xlabel('â° Zeit (Stunden)', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('ğŸ”‹ Akku (%)', fontsize=14, fontweight='bold')\n",
    "plt.title(f'ğŸ”´ Komplexes Polynom - Genauigkeit: {genauigkeit_polynom*100:.1f}% (ABER...)', \n",
    "          fontsize=16, fontweight='bold', color='red')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend(fontsize=12)\n",
    "plt.xlim(-0.5, 8.5)\n",
    "plt.ylim(-50, 150)  # Erweitert fÃ¼r die verrÃ¼ckten Werte!\n",
    "\n",
    "# Warnhinweise fÃ¼r unrealistische Bereiche\n",
    "unrealistic_high = vorhersage_polynom_glatt > 100\n",
    "unrealistic_low = vorhersage_polynom_glatt < 0\n",
    "\n",
    "if np.any(unrealistic_high):\n",
    "    plt.axhspan(100, 150, alpha=0.3, color='red')\n",
    "    \n",
    "if np.any(unrealistic_low):\n",
    "    plt.axhspan(-50, 0, alpha=0.3, color='red')\n",
    "\n",
    "# Realistische Grenzen markieren\n",
    "plt.axhline(y=0, color='black', linestyle='-', alpha=0.8, linewidth=2)\n",
    "plt.axhline(y=100, color='black', linestyle='-', alpha=0.8, linewidth=2)\n",
    "plt.text(0.5, 105, 'â† 100% Maximum', fontsize=12, fontweight='bold')\n",
    "plt.text(0.5, -5, 'â† 0% Minimum', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Warnungen als Text\n",
    "max_val = np.max(vorhersage_polynom_glatt)\n",
    "min_val = np.min(vorhersage_polynom_glatt)\n",
    "\n",
    "plt.text(0.02, 0.98, \n",
    "         f'ğŸš¨ UNREALISTISCH:\\n' +\n",
    "         #f'Minimum: {min_val:.1f}%\\n\\n' +\n",
    "         f'ğŸ¢ Die Kurve macht eine Achterbahn!\\n' +\n",
    "         f'ğŸ¢ Akkuladung steigt am Ende wieder an!\\n',\n",
    "         transform=plt.gca().transAxes, \n",
    "         bbox=dict(boxstyle='round,pad=0.5', facecolor='red', alpha=0.8),\n",
    "         fontsize=11, color='white', fontweight='bold', verticalalignment='top')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"ğŸ˜± OH NEIN! Was ist passiert?\")\n",
    "print(f\"ğŸ¢ Die Kurve macht wilde SprÃ¼nge!\")\n",
    "print(\"ğŸš¨ Die Akkuladung kann niemals ansteigen!\")\n",
    "print(\"ğŸ¤– Der Computer hat die Punkte 'auswendig gelernt' statt verstanden!\")\n",
    "print(\"ğŸ“š Wie ein Student, der Aufgaben auswendig lernt statt die Prinzipien versteht!\")\n",
    "print(\"\\nğŸ’¡ Das nennt man OVERFITTING - das Modell ist unbrauchbar!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ Schritt 5: Was ist da schiefgelaufen?\n",
    "\n",
    "### ğŸ¤” OVERFITTING einfach erklÃ¤rt:\n",
    "\n",
    "Stell dir vor, du lernst fÃ¼r eine Mathe-Klausur:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ“š OVERFITTING = Wie falsches Lernen fÃ¼r Klausuren\")\n",
    "print(\"=\"*50)\n",
    "print()\n",
    "print(\"ğŸ˜… SCHLECHTER Student (Overfitting):\")\n",
    "print(\"   â€¢ Lernt die 5 Ãœbungsaufgaben AUSWENDIG\")\n",
    "print(\"   â€¢ Kennt jede Aufgabe zu 100% perfekt\")\n",
    "print(\"   â€¢ Aber: In der Klausur (neue Aufgaben) = TOTALES VERSAGEN\")\n",
    "print(\"   â€¢ Hat die DETAILS gelernt, aber nichts VERSTANDEN\")\n",
    "print()\n",
    "print(\"ğŸ“ GUTER Student (Good Fit):\")\n",
    "print(\"   â€¢ Versteht die PRINZIPIEN hinter den Aufgaben\")\n",
    "print(\"   â€¢ Macht bei Ãœbungsaufgaben ein paar kleine Fehler (85% richtig)\")\n",
    "print(\"   â€¢ Aber: Kann NEUE Aufgaben in der Klausur lÃ¶sen\")\n",
    "print(\"   â€¢ Hat die KONZEPTE verstanden\")\n",
    "print()\n",
    "print(\"ğŸ”„ ÃœBERSETZT AUF UNSER AKKU-BEISPIEL:\")\n",
    "print(\"   ğŸ”´ Polynom Grad 8: Lernt jeden Datenpunkt auswendig\")\n",
    "print(\"   ğŸŸ¢ Gerade: Versteht das Prinzip 'Akku wird leerer'\")\n",
    "print()\n",
    "print(\"ğŸ’¡ MORAL:\")\n",
    "print(\"   Perfekte Genauigkeit bei wenigen Beispielen = VERDÃ„CHTIG!\")\n",
    "print(\"   Lieber 85% verstehen als 100% auswendig lernen!\")\n",
    "print(\"   Einfachheit schlÃ¤gt oft KomplexitÃ¤t!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“Š Direkter Vergleich: Gut vs. Schlecht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zeigen wir beide Modelle nebeneinander\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# LINKE Seite: Gutes Modell\n",
    "ax1.scatter(zeit_stunden, akku_prozent, color='#FF6B6B', s=100, \n",
    "           edgecolors='black', linewidth=2, label='ğŸ“± Deine Messungen', zorder=5)\n",
    "# Plotte beide Modelle mit dem gleichen zeit_glatt (200 Punkte)\n",
    "ax1.plot(zeit_glatt, np.polyval(gerade_koeff, zeit_glatt), color='#4ECDC4', \n",
    "         linewidth=3, label='Einfaches Modell')\n",
    "ax1.set_title(f'âœ… GUTES MODELL\\nGenauigkeit: {genauigkeit_gerade*100:.1f}%\\n(Realistisch!)', \n",
    "              fontsize=14, fontweight='bold', color='green')\n",
    "ax1.set_xlabel('Zeit (Stunden)')\n",
    "ax1.set_ylabel('Akku (%)')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.legend()\n",
    "ax1.set_ylim(0, 105)\n",
    "ax1.set_xlim(-0.5, 8.5)\n",
    "\n",
    "# Vorteile hinzufÃ¼gen\n",
    "ax1.text(0.02, 0.35, \n",
    "         'âœ… Realistische Werte\\nâœ… Glatte Kurve\\nâœ… VerstÃ¤ndlich\\nâœ… Vorhersagbar', \n",
    "         transform=ax1.transAxes, \n",
    "         bbox=dict(boxstyle='round,pad=0.3', facecolor='lightgreen', alpha=0.8),\n",
    "         fontsize=10, verticalalignment='top')\n",
    "\n",
    "# RECHTE Seite: Schlechtes Modell\n",
    "ax2.scatter(zeit_stunden, akku_prozent, color='#FF6B6B', s=100, \n",
    "           edgecolors='black', linewidth=2, label='ğŸ“± Deine Messungen', zorder=5)\n",
    "ax2.plot(zeit_glatt, vorhersage_polynom_glatt, color='#FF4757', \n",
    "         linewidth=3, label='Komplexes Modell')\n",
    "ax2.set_title(f'ğŸš¨ SCHLECHTES MODELL\\nGenauigkeit: {genauigkeit_polynom*100:.1f}%\\n(Overfitting!)', \n",
    "              fontsize=14, fontweight='bold', color='red')\n",
    "ax2.set_xlabel('Zeit (Stunden)')\n",
    "ax2.set_ylabel('Akku (%)')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.legend()\n",
    "ax2.set_ylim(-50, 150)\n",
    "ax2.set_xlim(-0.5, 8.5)\n",
    "\n",
    "# Nachteile hinzufÃ¼gen\n",
    "ax2.text(0.02, 0.35, \n",
    "         'âŒ Unrealistische Werte\\nâŒ Wilde Oszillationen\\nâŒ UnverstÃ¤ndlich\\nâŒ Unvorhersagbar', \n",
    "         transform=ax2.transAxes, \n",
    "         bbox=dict(boxstyle='round,pad=0.3', facecolor='lightcoral', alpha=0.8),\n",
    "         fontsize=10, verticalalignment='top')\n",
    "\n",
    "plt.suptitle('ğŸ¯ DER GROSSE VERGLEICH: Welches Modell wÃ¼rdest DU verwenden?', \n",
    "             fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"ğŸ¤” QUIZ: Welches Modell ist besser?\")\n",
    "print(\"A) Das linke (ungenauer, aber realistisch)\")\n",
    "print(\"B) Das rechte (100% genau, aber verrÃ¼ckte Vorhersagen)\")\n",
    "print()\n",
    "print(\"ğŸ’¡ Richtige Antwort: A! \")\n",
    "print(\"   Das rechte Modell ist 'overfitted' = unbrauchbar fÃ¼r neue Daten!\")\n",
    "print(\"   WÃ¼rdest du einem Navi vertrauen, das sagt du fÃ¤hrst 200 km/h rÃ¼ckwÃ¤rts?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”® Schritt 6: Test mit \"neuen\" Daten\n",
    "\n",
    "Lass uns testen: Was passiert, wenn du dein Handy **morgen** wieder benutzt?\n",
    "\n",
    "Spoiler: Die Ergebnisse werden dich **schockieren**! ğŸ˜±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate \"neue\" Messungen vom nÃ¤chsten Tag\n",
    "# (In echt wÃ¼rdest du diese erst spÃ¤ter haben!)\n",
    "zeit_morgen = np.array([0, 1.5, 3, 4.5, 6, 7.5])\n",
    "akku_morgen = np.array([100, 85, 68, 55, 35, 20])  # Etwas andere Werte als gestern\n",
    "\n",
    "print(\"ğŸ“… NEUER TAG - Neue Messungen:\")\n",
    "print(\"Stunde | Akku\")\n",
    "print(\"-------|------\")\n",
    "for i in range(len(zeit_morgen)):\n",
    "    print(f\"  {zeit_morgen[i]:3.1f}  | {akku_morgen[i]:3.0f}%\")\n",
    "\n",
    "print(\"\\nğŸ¤– Jetzt schauen wir, wie gut unsere beiden Modelle vorhersagen...\")\n",
    "print(\"ğŸ¯ Das ist der ECHTE Test: Funktioniert es auch bei neuen Daten?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vorhersagen fÃ¼r die neuen Daten\n",
    "# Einfaches Modell (Gerade)\n",
    "vorhersage_morgen_gerade = gerade_funktion(zeit_morgen)\n",
    "\n",
    "# Komplexes Modell (Polynom)\n",
    "vorhersage_morgen_polynom = polynom_funktion(zeit_morgen)\n",
    "\n",
    "# Wie weit lagen sie daneben? (Mittlerer absoluter Fehler)\n",
    "fehler_gerade = np.mean(np.abs(akku_morgen - vorhersage_morgen_gerade))\n",
    "fehler_polynom = np.mean(np.abs(akku_morgen - vorhersage_morgen_polynom))\n",
    "\n",
    "print(f\"ğŸ“Š ERGEBNISSE fÃ¼r den neuen Tag:\")\n",
    "print(f\"ğŸŸ¢ Einfaches Modell - Durchschnittlicher Fehler: {fehler_gerade:.1f}%\")\n",
    "print(f\"ğŸ”´ Komplexes Modell - Durchschnittlicher Fehler: {fehler_polynom:.1f}%\")\n",
    "print()\n",
    "\n",
    "if fehler_gerade < fehler_polynom:\n",
    "    print(\"ğŸ‰ Das EINFACHE Modell war besser!\")\n",
    "    print(\"ğŸ’¡ Obwohl es gestern 'schlechter' aussah!\")\n",
    "    print(\"ğŸ¯ Das beweist: Overfitting fÃ¼hrt zu schlechteren Vorhersagen!\")\n",
    "else:\n",
    "    print(\"ğŸ˜® Das komplexe Modell war besser... (ungewÃ¶hnlich!)\")\n",
    "    print(\"ğŸ’­ Das passiert manchmal, aber meist ist einfacher besser.\")\n",
    "\n",
    "print(\"\\nğŸ“š LEKTION: Hohe Genauigkeit bei Trainingsdaten â‰  gute Vorhersagen!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisierung der Vorhersagen vs. RealitÃ¤t\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Echte neue Messungen\n",
    "plt.scatter(zeit_morgen, akku_morgen, color='#2ECC71', s=150, \n",
    "           edgecolors='black', linewidth=2, label='ğŸ“± Echte Messungen (neuer Tag)', \n",
    "           zorder=6, marker='s')\n",
    "\n",
    "# Vorhersagen des einfachen Modells\n",
    "plt.scatter(zeit_morgen, vorhersage_morgen_gerade, color='#4ECDC4', s=100, \n",
    "           edgecolors='black', linewidth=1, label='ğŸŸ¢ Einfaches Modell Vorhersage', \n",
    "           zorder=5, marker='^')\n",
    "\n",
    "# Vorhersagen des komplexen Modells\n",
    "plt.scatter(zeit_morgen, vorhersage_morgen_polynom, color='#FF4757', s=100, \n",
    "           edgecolors='black', linewidth=1, label='ğŸ”´ Komplexes Modell Vorhersage', \n",
    "           zorder=5, marker='v')\n",
    "\n",
    "# Verbindungslinien zeigen Fehler\n",
    "for i in range(len(zeit_morgen)):\n",
    "    # GrÃ¼ne Linie fÃ¼r einfaches Modell\n",
    "    plt.plot([zeit_morgen[i], zeit_morgen[i]], \n",
    "            [akku_morgen[i], vorhersage_morgen_gerade[i]], \n",
    "            'g--', alpha=0.7, linewidth=2)\n",
    "    # Rote Linie fÃ¼r komplexes Modell\n",
    "    plt.plot([zeit_morgen[i], zeit_morgen[i]], \n",
    "            [akku_morgen[i], vorhersage_morgen_polynom[i]], \n",
    "            'r:', alpha=0.7, linewidth=2)\n",
    "\n",
    "plt.xlabel('â° Zeit (Stunden)', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('ğŸ”‹ Akku (%)', fontsize=14, fontweight='bold')\n",
    "plt.title('ğŸ”® Vorhersage vs. RealitÃ¤t (Neuer Tag)', fontsize=16, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend(fontsize=11)\n",
    "plt.xlim(-0.5, 8)\n",
    "plt.ylim(-20, 105)\n",
    "\n",
    "# Ergebnis-Box\n",
    "winner = \"ğŸŸ¢ Einfach\" if fehler_gerade < fehler_polynom else \"ğŸ”´ Komplex\"\n",
    "result_text = f\"ğŸ¯ Ergebnis:\\nğŸŸ¢ Einfach: {fehler_gerade:.1f}% Fehler\\nğŸ”´ Komplex: {fehler_polynom:.1f}% Fehler\\n\\nğŸ† Gewinner: {winner}\"\n",
    "plt.text(0.02, 0.28, result_text, transform=plt.gca().transAxes, \n",
    "         bbox=dict(boxstyle='round,pad=0.5', facecolor='lightblue', alpha=0.8),\n",
    "         fontsize=12, fontweight='bold', verticalalignment='top')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"ğŸ’¡ Siehst du die Linien? Sie zeigen, wie weit die Vorhersagen daneben lagen!\")\n",
    "print(\"ğŸ¯ KÃ¼rzere Linien = bessere Vorhersagen\")\n",
    "print(\"ğŸ“ GrÃ¼ne Linien (einfach) vs. rote Linien (komplex)\")\n",
    "print(\"\\nğŸ” Beobachtung: Das einfache Modell ist oft nÃ¤her an der RealitÃ¤t!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ Was hast du gelernt? (Das Wichtigste!)\n",
    "\n",
    "### ğŸ§  Die wichtigsten Erkenntnisse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ‰ HERZLICHEN GLÃœCKWUNSCH!\")\n",
    "print(\"Du hast gerade eines der wichtigsten Konzepte in Data Science gelernt!\")\n",
    "print()\n",
    "print(\"ğŸ¯ WAS IST OVERFITTING?\")\n",
    "print(\"   ğŸ“š Wie Auswendiglernen statt Verstehen\")\n",
    "print(\"   ğŸ¢ Modell wird zu komplex = Achterbahn-Kurven\")\n",
    "print(\"   ğŸ“Š Hohe Genauigkeit bei Trainingsdaten = VERDÃ„CHTIG\")\n",
    "print(\"   ğŸ”® Schlechte Vorhersagen bei neuen Daten\")\n",
    "print(\"   ğŸ”¢ Zu viele Parameter fÃ¼r zu wenige Daten\")\n",
    "print()\n",
    "print(\"âœ… WIE ERKENNST DU OVERFITTING?\")\n",
    "print(\"   ğŸš¨ Unrealistische Vorhersagen (z.B. 120% Akku)\")\n",
    "print(\"   ğŸ“ˆ Perfekte Genauigkeit bei wenigen Daten\")\n",
    "print(\"   ğŸ¢ Wilde Kurven zwischen Datenpunkten\")\n",
    "print(\"   ğŸ“‰ Schlechte Performance bei neuen Daten\")\n",
    "print(\"   ğŸ” Mehr Parameter als Datenpunkte\")\n",
    "print()\n",
    "print(\"ğŸ’¡ WIE VERMEIDEST DU OVERFITTING?\")\n",
    "print(\"   ğŸ¯ Einfachere Modelle bevorzugen (Occam's Razor!)\")\n",
    "print(\"   ğŸ“Š Mehr Daten sammeln\")\n",
    "print(\"   ğŸ” Immer mit neuen Daten testen\")\n",
    "print(\"   ğŸ§  Gesunder Menschenverstand nutzen\")\n",
    "print(\"   âš–ï¸  Balance zwischen Einfachheit und Genauigkeit\")\n",
    "print()\n",
    "print(\"ğŸš€ WARUM IST DAS WICHTIG?\")\n",
    "print(\"   ğŸ¥ Medizin: Falsche Diagnosen vermeiden\")\n",
    "print(\"   ğŸš— Autonome Autos: Sicherheit geht vor\")\n",
    "print(\"   ğŸ’° Finanzen: Bessere Vorhersagen\")\n",
    "print(\"   ğŸ“± Apps: Nutzerfreundlichere Empfehlungen\")\n",
    "print(\"   ğŸ¤– KI allgemein: VertrauenswÃ¼rdige Systeme\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ Bonus: Deine Checkliste fÃ¼r die Zukunft\n",
    "\n",
    "### ğŸ“‹ Die \"Anti-Overfitting\" Checkliste (zum Ausdrucken! ğŸ˜‰)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ“‹ DEINE ANTI-OVERFITTING CHECKLISTE\")\n",
    "print(\"=\" * 40)\n",
    "print()\n",
    "print(\"Bevor du sagst 'Mein Modell ist perfekt!'\")\n",
    "print()\n",
    "print(\"â˜ Ist meine Genauigkeit REALISTISCH? (nicht >99% bei wenigen Daten)\")\n",
    "print(\"â˜ Macht die Vorhersage-Kurve SINN? (keine wilden Achterbahnen)\")\n",
    "print(\"â˜ Habe ich mit NEUEN Daten getestet?\")\n",
    "print(\"â˜ Sind die Vorhersagen PHYSIKALISCH mÃ¶glich? (z.B. 0-100% Akku)\")\n",
    "print(\"â˜ Habe ich mehr Parameter als Datenpunkte? (Warnsignal!)\")\n",
    "print(\"â˜ WÃ¼rde ich dem Modell in der REALITÃ„T vertrauen?\")\n",
    "print(\"â˜ Ist das Modell EINFACH zu verstehen und erklÃ¤ren?\")\n",
    "print()\n",
    "print(\"ğŸ† Wenn alle Punkte âœ… sind: Dein Modell ist wahrscheinlich gut!\")\n",
    "print(\"ğŸš¨ Wenn auch nur EINER âŒ ist: Vorsicht, mÃ¶gliches Overfitting!\")\n",
    "print()\n",
    "print(\"ğŸ¯ FAUSTREGEL:\")\n",
    "print(\"   Einfach und 85% richtig > Komplex und 99% richtig\")\n",
    "print(\"   'Keep it simple, stupid!' (KISS-Prinzip)\")\n",
    "print()\n",
    "print(\"ğŸ’ª DU BIST JETZT BEREIT FÃœR KOMPLEXERE KI-PROJEKTE!\")\n",
    "print(\"ğŸ“ Dieses Wissen hilft dir bei Neural Networks, Deep Learning & Co.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ® Zum Abschluss: Mini-Quiz!\n",
    "\n",
    "Teste dein neues Wissen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ® MINI-QUIZ: Bist du ein Overfitting-Experte?\")\n",
    "print(\"=\" * 45)\n",
    "print()\n",
    "\n",
    "quiz_questions = [\n",
    "    {\n",
    "        \"question\": \"Ein Modell hat 99.9% Genauigkeit bei nur 5 Datenpunkten. Das ist...\",\n",
    "        \"options\": [\"A) Fantastisch!\", \"B) VerdÃ¤chtig\", \"C) Normal\"],\n",
    "        \"correct\": \"B\",\n",
    "        \"explanation\": \"Bei so wenigen Daten ist das hÃ¶chst verdÃ¤chtig - wahrscheinlich Overfitting!\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Dein Akku-Modell sagt 150% Ladung voraus. Du solltest...\",\n",
    "        \"options\": [\"A) Dem Modell vertrauen\", \"B) Das Modell Ã¼berprÃ¼fen\", \"C) Nichts machen\"],\n",
    "        \"correct\": \"B\",\n",
    "        \"explanation\": \"Physikalisch unmÃ¶glich! Das Modell ist definitiv overfitted.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Welches ist besser: 85% genau und realistisch ODER 98% genau aber wilde Kurven?\",\n",
    "        \"options\": [\"A) 98% - hÃ¶her ist besser\", \"B) 85% - realistischer\", \"C) Beide gleich gut\"],\n",
    "        \"correct\": \"B\",\n",
    "        \"explanation\": \"Realistische 85% sind viel besser als overfitted 98%!\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Du hast 8 Datenpunkte und dein Modell hat 10 Parameter. Das ist...\",\n",
    "        \"options\": [\"A) Perfekt\", \"B) Overfitting-Risiko\", \"C) Zu wenig\"],\n",
    "        \"correct\": \"B\",\n",
    "        \"explanation\": \"Mehr Parameter als Daten = Klassisches Overfitting-Risiko!\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Overfitting ist wie...\",\n",
    "        \"options\": [\"A) FÃ¼r Klausur auswendig lernen\", \"B) Prinzipien verstehen\", \"C) Gar nicht lernen\"],\n",
    "        \"correct\": \"A\",\n",
    "        \"explanation\": \"Genau! Auswendig lernen funktioniert nur bei bekannten Aufgaben!\"\n",
    "    }\n",
    "]\n",
    "\n",
    "score = 0\n",
    "for i, q in enumerate(quiz_questions, 1):\n",
    "    print(f\"â“ Frage {i}: {q['question']}\")\n",
    "    for option in q['options']:\n",
    "        print(f\"   {option}\")\n",
    "    print(f\"\\nğŸ’¡ Antwort: {q['correct']}) - {q['explanation']}\")\n",
    "    print(\"-\" * 50)\n",
    "    score += 1\n",
    "\n",
    "print(f\"\\nğŸ‰ Quiz beendet! Du hÃ¤ttest {score}/{len(quiz_questions)} Punkte!\")\n",
    "print(\"ğŸ“š Alle Antworten richtig? Du bist bereit fÃ¼r die nÃ¤chste Stufe!\")\n",
    "print(\"ğŸ”œ Weiter geht's mit: Cross-Validation, Regularization, Neural Networks...\")\n",
    "print(\"ğŸš€ Welcome to the world of Data Science! ğŸ¤–\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ¯ Das war's! Du hast es geschafft! ğŸ‰\n",
    "\n",
    "**Was kannst du jetzt?**\n",
    "- âœ… Overfitting erkennen und verstehen\n",
    "- âœ… Gute von schlechten Modellen unterscheiden  \n",
    "- âœ… Realistische Vorhersagen bewerten\n",
    "- âœ… Eine wichtige KI-Falle vermeiden\n",
    "- âœ… Einfachheit vs. KomplexitÃ¤t abwÃ¤gen\n",
    "\n",
    "**Das war nur der Anfang!** ğŸš€\n",
    "\n",
    "Bald lernst du:\n",
    "- ğŸ§  **Neural Networks** (KÃ¼nstliche Gehirne)\n",
    "- ğŸ¯ **Machine Learning** (Computer die selbst lernen)\n",
    "- ğŸ”® **Deep Learning** (Sehr tiefe Netzwerke)\n",
    "- ğŸ¤– **AI Applications** (Echte KI-Anwendungen)\n",
    "- ğŸ›¡ï¸ **Regularization** (Overfitting vermeiden)\n",
    "- âœ… **Cross-Validation** (Modelle richtig testen)\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“ Wichtige Kernbotschaften zum Mitnehmen:\n",
    "\n",
    "1. **Einfachheit schlÃ¤gt KomplexitÃ¤t** - Die beste LÃ¶sung ist oft die einfachste\n",
    "2. **Perfekt â‰  Gut** - 100% Genauigkeit bei wenigen Daten ist verdÃ¤chtig\n",
    "3. **Verstehen > Auswendiglernen** - Modelle sollen Prinzipien erfassen, nicht Details\n",
    "4. **Testen ist alles** - Ein Modell ist nur so gut wie seine Performance auf neuen Daten\n",
    "5. **Gesunder Menschenverstand** - Unrealistische Ergebnisse sind ein Warnsignal\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ’ Feedback erwÃ¼nscht!\n",
    "*Hat dir dieses Tutorial geholfen? Was war gut, was kÃ¶nnte besser sein?*\n",
    "\n",
    "**Happy Learning!** ğŸ˜ŠğŸ“šğŸš€\n",
    "\n",
    "### ğŸŒŸ Fun Fact:\n",
    "*Du hast gerade gelernt, was viele Data Scientists erst nach Monaten verstehen. Overfitting zu erkennen ist eine Superkraft in der KI-Welt!* ğŸ¦¸â€â™€ï¸ğŸ¦¸â€â™‚ï¸"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lecture_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
