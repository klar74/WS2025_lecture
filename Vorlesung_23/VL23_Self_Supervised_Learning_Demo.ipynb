{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd52a447",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/klar74/WS2025_lecture/blob/main/Vorlesung_23/VL23_Self_Supervised_Learning_Demo.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59dc90c",
   "metadata": {},
   "source": [
    "# Self-Supervised Learning Demo\n",
    "## Vorlesung 23: Contrastive Learning mit CIFAR-10\n",
    "\n",
    "**Ziel:** Verstehen, wie Self-supervised Learning ohne Labels funktioniert\n",
    "\n",
    "**Methode:** Contrastive Learning - das Modell lernt, dass verschiedene Augmentierungen desselben Bildes Ã¤hnlich sein sollten\n",
    "\n",
    "**Dataset:** CIFAR-10 (aber wir ignorieren die Labels fÃ¼r das Pretraining!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ebf0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotheken importieren\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import random\n",
    "\n",
    "# FÃ¼r reproduzierbare Ergebnisse\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "print(\"Bibliotheken erfolgreich importiert!\")\n",
    "print(f\"PyTorch Version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec827d3",
   "metadata": {},
   "source": [
    "## 1. Daten vorbereiten\n",
    "\n",
    "**Wichtig:** Wir verwenden CIFAR-10, aber **ignorieren die Labels komplett** fÃ¼r das Self-supervised Learning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8ff502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nur 3 CIFAR-10 Klassen fÃ¼r klarere Visualisierung\n",
    "classes = ['Flugzeug', 'Auto', 'Vogel', 'Katze', 'Hirsch', 'Hund', 'Frosch', 'Pferd', 'Schiff', 'LKW']\n",
    "selected_classes = [0, 1, 2]  # Flugzeug, Auto, Vogel\n",
    "class_names = ['Flugzeug', 'Auto', 'Vogel']\n",
    "\n",
    "# Augmentierungen fÃ¼r Contrastive Learning definieren\n",
    "class ContrastiveTransform:\n",
    "    \"\"\"Erstellt zwei verschiedene Augmentierungen desselben Bildes\"\"\"\n",
    "    def __init__(self):\n",
    "        # Starke Augmentierungen fÃ¼r Self-supervised Learning\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(32, scale=(0.8, 1.0)),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1),\n",
    "            transforms.RandomGrayscale(p=0.2),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "        ])\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        # Zwei verschiedene Augmentierungen des gleichen Bildes\n",
    "        return self.transform(x), self.transform(x)\n",
    "\n",
    "# Dataset laden (Labels werden ignoriert!)\n",
    "full_train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', \n",
    "    train=True, \n",
    "    download=True, \n",
    "    transform=ContrastiveTransform()\n",
    ")\n",
    "\n",
    "# Nur ausgewÃ¤hlte Klassen filtern\n",
    "def filter_classes(dataset, selected_classes):\n",
    "    \"\"\"Filtert Dataset um nur bestimmte Klassen zu behalten\"\"\"\n",
    "    indices = []\n",
    "    # TemporÃ¤res Dataset ohne Augmentierung fÃ¼r Label-Zugriff\n",
    "    temp_dataset = torchvision.datasets.CIFAR10(\n",
    "        root='./data', train=True, transform=transforms.ToTensor()\n",
    "    )\n",
    "    \n",
    "    for i in range(len(temp_dataset)):\n",
    "        _, label = temp_dataset[i]\n",
    "        if label in selected_classes:\n",
    "            indices.append(i)\n",
    "    \n",
    "    return torch.utils.data.Subset(dataset, indices[:1000])  # Maximal 1000 Bilder\n",
    "\n",
    "# Gefilterte Datasets erstellen\n",
    "train_dataset = filter_classes(full_train_dataset, selected_classes)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "print(f\"Dataset gefiltert: {len(train_dataset)} Bilder aus 3 Klassen fÃ¼r Self-supervised Learning\")\n",
    "print(\"WICHTIG: Wir verwenden KEINE Labels - nur die Bilder!\")\n",
    "print(f\"Klassen: {', '.join(class_names)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657b4c48",
   "metadata": {},
   "source": [
    "## 2. Augmentierungen visualisieren\n",
    "\n",
    "**Kernidee:** Das Modell lernt, dass diese verschiedenen Versionen desselben Bildes zusammengehÃ¶ren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d4b0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_augmentations():\n",
    "    \"\"\"Zeigt Original und Augmentierungen\"\"\"\n",
    "    # Original Dataset fÃ¼r Vergleich\n",
    "    original_dataset = torchvision.datasets.CIFAR10(\n",
    "        root='./data', \n",
    "        train=True, \n",
    "        transform=transforms.ToTensor()\n",
    "    )\n",
    "    \n",
    "    fig, axes = plt.subplots(3, 3, figsize=(10, 8))\n",
    "    \n",
    "    # Zeige nur 3 Beispiele (einen pro Klasse)\n",
    "    class_examples = []\n",
    "    for target_class in selected_classes:\n",
    "        for i in range(len(original_dataset)):\n",
    "            _, label = original_dataset[i]\n",
    "            if label == target_class:\n",
    "                class_examples.append(i)\n",
    "                break\n",
    "    \n",
    "    # Erstelle temporÃ¤res Dataset fÃ¼r konsistente Augmentierungen\n",
    "    temp_augment_dataset = torchvision.datasets.CIFAR10(\n",
    "        root='./data', \n",
    "        train=True, \n",
    "        transform=ContrastiveTransform()\n",
    "    )\n",
    "    \n",
    "    for col, idx in enumerate(class_examples):\n",
    "        # Original Bild\n",
    "        original_img, label = original_dataset[idx]\n",
    "        axes[0, col].imshow(np.transpose(original_img, (1, 2, 0)))\n",
    "        axes[0, col].set_title(f'Original: {classes[label]}')\n",
    "        axes[0, col].axis('off')\n",
    "        \n",
    "        # Augmentierungen vom gleichen Bild\n",
    "        aug1, aug2 = temp_augment_dataset[idx][0]  # Gleicher Index wie Original\n",
    "        \n",
    "        # Denormalisieren fÃ¼r Anzeige\n",
    "        def denorm(tensor):\n",
    "            mean = torch.tensor([0.4914, 0.4822, 0.4465]).view(3, 1, 1)\n",
    "            std = torch.tensor([0.2023, 0.1994, 0.2010]).view(3, 1, 1)\n",
    "            return torch.clamp(tensor * std + mean, 0, 1)\n",
    "        \n",
    "        axes[1, col].imshow(np.transpose(denorm(aug1), (1, 2, 0)))\n",
    "        axes[1, col].set_title('Augmentierung 1')\n",
    "        axes[1, col].axis('off')\n",
    "        \n",
    "        axes[2, col].imshow(np.transpose(denorm(aug2), (1, 2, 0)))\n",
    "        axes[2, col].set_title('Augmentierung 2')\n",
    "        axes[2, col].axis('off')\n",
    "    \n",
    "    plt.suptitle('Self-Supervised Learning: 3 Klassen - Verschiedene Ansichten', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"ğŸ’¡ KERNIDEE: Das Modell lernt, dass die beiden Augmentierungen zusammengehÃ¶ren\")\n",
    "    print(\"   - Ã„hnliche Bilder â†’ Ã¤hnliche ReprÃ¤sentationen\")\n",
    "    print(\"   - Verschiedene Bilder â†’ verschiedene ReprÃ¤sentationen\")\n",
    "\n",
    "show_augmentations()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ece93b",
   "metadata": {},
   "source": [
    "## 3. Einfaches Self-supervised Modell\n",
    "\n",
    "**SimCLR-Ansatz:** Encoder + Projection Head fÃ¼r Contrastive Learning\n",
    "\n",
    "### ğŸ’¡ **Was passiert hier?**\n",
    "- **Encoder**: CNN extrahiert Features aus Bildern (wie bei supervised Learning)\n",
    "- **Projection Head**: ZusÃ¤tzliches Netzwerk, das Features fÃ¼r Contrastive Learning optimiert\n",
    "- **Kernidee**: Ã„hnliche Bilder sollen Ã¤hnliche Features haben, verschiedene Bilder verschiedene Features\n",
    "- Das Modell lernt **ohne Labels** nur durch Vergleich von Augmentierungen!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3a3058",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleEncoder(nn.Module):\n",
    "    \"\"\"Einfacher CNN Encoder fÃ¼r CIFAR-10\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(128, 128)  # Feature-Dimension\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return F.normalize(self.fc(x), dim=1)  # L2-Normalisierung\n",
    "\n",
    "class ContrastiveModel(nn.Module):\n",
    "    \"\"\"Self-supervised Contrastive Learning Model\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = SimpleEncoder()\n",
    "        # Projection Head (wichtig fÃ¼r Contrastive Learning)\n",
    "        self.projection = nn.Sequential(\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x1, x2):\n",
    "        # Features fÃ¼r beide Augmentierungen\n",
    "        z1 = self.projection(self.encoder(x1))\n",
    "        z2 = self.projection(self.encoder(x2))\n",
    "        return F.normalize(z1, dim=1), F.normalize(z2, dim=1)\n",
    "\n",
    "# Modell erstellen\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = ContrastiveModel().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "print(f\"Modell erstellt auf: {device}\")\n",
    "print(f\"Parameter: {sum(p.numel() for p in model.parameters())/1000:.1f}k\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1036f5",
   "metadata": {},
   "source": [
    "## 4. Contrastive Loss\n",
    "\n",
    "**InfoNCE Loss:** Ã„hnliche Paare zusammenbringen, verschiedene Paare trennen\n",
    "\n",
    "### ğŸ’¡ **Die Magie des Self-supervised Learning:**\n",
    "- **Positive Paare**: Zwei Augmentierungen desselben Bildes â†’ sollen Ã¤hnlich werden\n",
    "- **Negative Paare**: Augmentierungen verschiedener Bilder â†’ sollen verschieden bleiben  \n",
    "- **InfoNCE**: Mathematische Formel, die diese Idee umsetzt\n",
    "- **Ohne Labels**: Das Modell lernt nur durch diese Ã„hnlichkeits-/Verschiedenheits-Regel!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3e7f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_loss(z1, z2, temperature=0.5):\n",
    "    \"\"\"InfoNCE Loss fÃ¼r Contrastive Learning\n",
    "    \n",
    "    Args:\n",
    "        z1, z2: Normalisierte Features der beiden Augmentierungen\n",
    "        temperature: Temperatur-Parameter fÃ¼r Softmax\n",
    "    \"\"\"\n",
    "    batch_size = z1.size(0)\n",
    "    \n",
    "    # Similarity Matrix berechnen\n",
    "    # z1 mit z2 vergleichen (positive Paare)\n",
    "    pos_sim = torch.sum(z1 * z2, dim=1) / temperature  # [batch_size]\n",
    "    \n",
    "    # z1 mit allen anderen z2 vergleichen (negative Paare)\n",
    "    neg_sim = torch.mm(z1, z2.t()) / temperature  # [batch_size, batch_size]\n",
    "    \n",
    "    # Diagonale entfernen (das sind die positiven Paare)\n",
    "    mask = torch.eye(batch_size, device=z1.device).bool()\n",
    "    neg_sim = neg_sim.masked_fill(mask, float('-inf'))\n",
    "    \n",
    "    # InfoNCE Loss\n",
    "    logits = torch.cat([pos_sim.unsqueeze(1), neg_sim], dim=1)\n",
    "    labels = torch.zeros(batch_size, device=z1.device, dtype=torch.long)\n",
    "    \n",
    "    loss = F.cross_entropy(logits, labels)\n",
    "    \n",
    "    # Accuracy berechnen (wie oft ist das positive Paar am Ã¤hnlichsten?)\n",
    "    pred = torch.argmax(logits, dim=1)\n",
    "    acc = (pred == labels).float().mean()\n",
    "    \n",
    "    return loss, acc\n",
    "\n",
    "# Test der Loss-Funktion\n",
    "with torch.no_grad():\n",
    "    test_z1 = torch.randn(4, 32).to(device)\n",
    "    test_z2 = torch.randn(4, 32).to(device)\n",
    "    test_z1 = F.normalize(test_z1, dim=1)\n",
    "    test_z2 = F.normalize(test_z2, dim=1)\n",
    "    \n",
    "    test_loss, test_acc = contrastive_loss(test_z1, test_z2)\n",
    "    print(f\"Test Loss: {test_loss:.3f}, Test Acc: {test_acc:.3f}\")\n",
    "    print(\"Loss-Funktion erfolgreich implementiert!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca45a7c5",
   "metadata": {},
   "source": [
    "## 5. Training (Self-supervised)\n",
    "\n",
    "**Ohne Labels!** Das Modell lernt nur durch Vergleich der Augmentierungen\n",
    "\n",
    "### ğŸ’¡ **Warum funktioniert das?**\n",
    "- **Pretext Task**: Erkenne, welche Augmentierungen zum gleichen Bild gehÃ¶ren\n",
    "- **Inductive Bias**: Verschiedene Ansichten eines Objekts sollten Ã¤hnliche Eigenschaften haben\n",
    "- **Emergente Features**: Das Modell entwickelt automatisch nÃ¼tzliche ReprÃ¤sentationen\n",
    "- **Skalierbar**: Funktioniert mit Millionen unlabeled Bildern!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6bc07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_self_supervised(epochs=5):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    \n",
    "    print(\"ğŸš€ Starte Self-supervised Training...\")\n",
    "    print(\"WICHTIG: Keine Labels verwendet - nur Augmentierungen!\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        epoch_losses = []\n",
    "        epoch_accs = []\n",
    "        \n",
    "        for batch_idx, (batch, _) in enumerate(train_loader):  # Labels ignorieren!\n",
    "            # batch enthÃ¤lt tuple von (aug1, aug2)\n",
    "            aug1, aug2 = batch\n",
    "            aug1, aug2 = aug1.to(device), aug2.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            z1, z2 = model(aug1, aug2)\n",
    "            \n",
    "            # Contrastive Loss\n",
    "            loss, acc = contrastive_loss(z1, z2)\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_losses.append(loss.item())\n",
    "            epoch_accs.append(acc.item())\n",
    "            \n",
    "            if batch_idx % 5 == 0:\n",
    "                print(f\"Epoch {epoch+1}/{epochs}, Batch {batch_idx}: Loss={loss:.3f}, Acc={acc:.3f}\")\n",
    "        \n",
    "        avg_loss = np.mean(epoch_losses)\n",
    "        avg_acc = np.mean(epoch_accs)\n",
    "        losses.append(avg_loss)\n",
    "        accuracies.append(avg_acc)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1} fertig: Avg Loss={avg_loss:.3f}, Avg Acc={avg_acc:.3f}\")\n",
    "        print(\"-\" * 50)\n",
    "    \n",
    "    return losses, accuracies\n",
    "\n",
    "# Training starten\n",
    "losses, accuracies = train_self_supervised(epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8a3b55",
   "metadata": {},
   "source": [
    "## 6. Training Visualisierung\n",
    "\n",
    "### ğŸ’¡ **Was zeigen diese Kurven?**\n",
    "- **Contrastive Loss**: FÃ¤llt â†’ das Modell wird besser im Unterscheiden Ã¤hnlich/verschieden\n",
    "- **Contrastive Accuracy**: Steigt â†’ das Modell erkennt korrekt, welche Augmentierungen zusammengehÃ¶ren\n",
    "- **Lernfortschritt**: Ohne Labels lernt das Modell sinnvolle ReprÃ¤sentationen!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b385bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(losses, 'b-o', label='Contrastive Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Self-supervised Learning: Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(accuracies, 'r-o', label='Contrastive Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Positive Pair Recognition')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"ğŸ“ˆ Finaler Loss: {losses[-1]:.3f}\")\n",
    "print(f\"ğŸ“ˆ Finale Accuracy: {accuracies[-1]:.3f}\")\n",
    "print(\"\")\n",
    "print(\"ğŸ’¡ Die Accuracy zeigt, wie oft das Modell korrekt erkennt,\")\n",
    "print(\"   dass zwei Augmentierungen vom gleichen Bild stammen!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5a7b6d",
   "metadata": {},
   "source": [
    "## 7. Gelernte ReprÃ¤sentationen visualisieren\n",
    "\n",
    "**Ziel:** Zeigen, dass das Modell sinnvolle Features gelernt hat (ohne Labels!)\n",
    "\n",
    "### ğŸ’¡ **Der Moment der Wahrheit:**\n",
    "- **PCA**: Reduziert 128D Features auf 2D fÃ¼r Visualisierung\n",
    "- **Cluster-Bildung**: Wenn SSL funktioniert, sollten Ã¤hnliche Objekte clustern\n",
    "- **Ohne Labels trainiert**: Das Modell hat nie gesehen, dass \"Flugzeug = 0\", trotzdem clustert es!\n",
    "- **Emergenz**: Semantische Struktur entsteht automatisch aus dem Contrastive Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8701623",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Filter fÃ¼r 3 Klassen mit Label-Remapping\n",
    "def filter_and_remap_classes(dataset, selected_classes):\n",
    "    \"\"\"Filtert Dataset und mappt Labels auf 0,1,2\"\"\"\n",
    "    indices = []\n",
    "    for i in range(len(dataset)):\n",
    "        _, label = dataset[i]\n",
    "        if label in selected_classes:\n",
    "            indices.append(i)\n",
    "    \n",
    "    # Custom Dataset mit Label-Remapping\n",
    "    class RemappedDataset(torch.utils.data.Dataset):\n",
    "        def __init__(self, dataset, indices, selected_classes):\n",
    "            self.dataset = dataset\n",
    "            self.indices = indices\n",
    "            self.class_mapping = {cls: i for i, cls in enumerate(selected_classes)}\n",
    "        \n",
    "        def __len__(self):\n",
    "            return len(self.indices)\n",
    "        \n",
    "        def __getitem__(self, idx):\n",
    "            data, label = self.dataset[self.indices[idx]]\n",
    "            return data, self.class_mapping[label]\n",
    "    \n",
    "    return RemappedDataset(dataset, indices, selected_classes)\n",
    "\n",
    "def visualize_representations():\n",
    "    \"\"\"Visualisiere die gelernten ReprÃ¤sentationen\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Test Dataset mit Labels (nur fÃ¼r Visualisierung) - gefiltert auf 3 Klassen\n",
    "    test_dataset_full = torchvision.datasets.CIFAR10(\n",
    "        root='./data', \n",
    "        train=False, \n",
    "        transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "        ])\n",
    "    )\n",
    "    \n",
    "    # Nur ausgewÃ¤hlte Klassen\n",
    "    test_dataset = filter_and_remap_classes(test_dataset_full, selected_classes)\n",
    "    \n",
    "    # Kleine Auswahl fÃ¼r Visualisierung\n",
    "    test_subset = torch.utils.data.Subset(test_dataset, range(min(300, len(test_dataset))))\n",
    "    test_loader = DataLoader(test_subset, batch_size=32, shuffle=False)\n",
    "    \n",
    "    features = []\n",
    "    labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch, batch_labels in test_loader:\n",
    "            batch = batch.to(device)\n",
    "            # Nur Encoder verwenden (ohne Projection Head)\n",
    "            feat = model.encoder(batch)\n",
    "            features.append(feat.cpu())\n",
    "            labels.append(batch_labels)\n",
    "    \n",
    "    features = torch.cat(features, dim=0).numpy()\n",
    "    labels = torch.cat(labels, dim=0).numpy()\n",
    "    \n",
    "    print(f\"Features Shape: {features.shape}\")\n",
    "    \n",
    "    # PCA fÃ¼r Dimensionsreduktion\n",
    "    pca = PCA(n_components=2)\n",
    "    features_2d = pca.fit_transform(features)\n",
    "    \n",
    "    # Visualisierung\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # Farben fÃ¼r 3 Klassen\n",
    "    colors = ['red', 'blue', 'green']\n",
    "    \n",
    "    for i in range(3):\n",
    "        mask = labels == i\n",
    "        if mask.sum() > 0:  # Nur wenn Daten vorhanden\n",
    "            plt.scatter(features_2d[mask, 0], features_2d[mask, 1], \n",
    "                       c=colors[i], label=class_names[i], alpha=0.7, s=30)\n",
    "    \n",
    "    plt.xlabel('PCA Komponente 1')\n",
    "    plt.ylabel('PCA Komponente 2')\n",
    "    plt.title('Self-supervised ReprÃ¤sentationen: 3 Klassen (ohne Labels trainiert!)')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"ğŸ¯ BEOBACHTE: Die 3 Klassen clustern klar zusammen!\")\n",
    "    print(\"   Das Modell hat OHNE Labels gelernt, sinnvolle Features zu extrahieren!\")\n",
    "    print(f\"   PCA erklÃ¤rt {pca.explained_variance_ratio_.sum():.2%} der Varianz\")\n",
    "    print(f\"   Klassen: {', '.join(class_names)}\")\n",
    "\n",
    "visualize_representations()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9967b5cd",
   "metadata": {},
   "source": [
    "## 8. Transfer Learning Test\n",
    "\n",
    "**Der wahre Test:** KÃ¶nnen die gelernten Features fÃ¼r eine supervised Aufgabe verwendet werden?\n",
    "\n",
    "### ğŸ’¡ **Praktischer Nutzen von SSL:**\n",
    "- **Feature Reuse**: Nutze die self-supervised Features fÃ¼r eine neue Aufgabe\n",
    "- **Frozen Encoder**: SSL-Features bleiben fest, nur der Klassifikator wird trainiert\n",
    "- **Weniger Labels**: Brauche nur wenige gelabelte Daten fÃ¼r die neue Aufgabe\n",
    "- **Industrieller Standard**: So funktionieren GPT, BERT, und moderne Vision Models!\n",
    "\n",
    "### ğŸ“‹ **Die supervised Aufgabe erklÃ¤rt:**\n",
    "- **Vorher (SSL)**: \"Erkenne, welche Augmentierungen zusammengehÃ¶ren\" â†’ **ohne Labels**\n",
    "- **Jetzt (Supervised)**: \"Klassifiziere: Flugzeug, Auto oder Vogel?\" â†’ **mit Labels**\n",
    "- **Unterschied**: Jetzt haben wir echte Klassenlabels und wollen konkrete Objekte erkennen\n",
    "- **Ziel**: Testen, ob die SSL-Features auch fÃ¼r \"normale\" Klassifikation taugen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9459e927",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransferClassifier(nn.Module):\n",
    "    \"\"\"Einfacher Klassifikator auf gefrorenen Features\"\"\"\n",
    "    def __init__(self, pretrained_encoder):\n",
    "        super().__init__()\n",
    "        self.encoder = pretrained_encoder\n",
    "        # Encoder einfrieren\n",
    "        for param in self.encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "        # Nur Klassifikations-Head trainieren\n",
    "        self.classifier = nn.Linear(128, 3)  # 3 ausgewÃ¤hlte CIFAR-10 Klassen\n",
    "    \n",
    "    def forward(self, x):\n",
    "        with torch.no_grad():\n",
    "            features = self.encoder(x)\n",
    "        return self.classifier(features)\n",
    "\n",
    "# Transfer Learning Setup\n",
    "transfer_model = TransferClassifier(model.encoder).to(device)\n",
    "transfer_optimizer = torch.optim.Adam(transfer_model.classifier.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Dataset mit Labels fÃ¼r Transfer Learning\n",
    "supervised_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "train_supervised_full = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, transform=supervised_transform\n",
    ")\n",
    "test_supervised_full = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, transform=supervised_transform\n",
    ")\n",
    "\n",
    "# Gefilterte Datasets fÃ¼r Transfer Learning\n",
    "train_supervised = filter_and_remap_classes(train_supervised_full, selected_classes)\n",
    "test_supervised = filter_and_remap_classes(test_supervised_full, selected_classes)\n",
    "\n",
    "# Kleine Datasets fÃ¼r schnelles Training\n",
    "train_small = torch.utils.data.Subset(train_supervised, range(min(1000, len(train_supervised))))\n",
    "test_small = torch.utils.data.Subset(test_supervised, range(min(200, len(test_supervised))))\n",
    "\n",
    "train_loader_super = DataLoader(train_small, batch_size=64, shuffle=True)\n",
    "test_loader_super = DataLoader(test_small, batch_size=64, shuffle=False)\n",
    "\n",
    "print(\"ğŸ¯ Transfer Learning Setup fertig fÃ¼r 3 Klassen!\")\n",
    "print(f\"   Klassen: {', '.join(class_names)}\")\n",
    "print(f\"   Trainiere nur {sum(p.numel() for p in transfer_model.classifier.parameters())} Parameter\")\n",
    "print(f\"   Encoder mit {sum(p.numel() for p in transfer_model.encoder.parameters())} Parametern ist eingefroren\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b11331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer Learning Training\n",
    "def train_transfer_learning(epochs=3):\n",
    "    transfer_model.train()\n",
    "    \n",
    "    print(\"ğŸš€ Starte Transfer Learning...\")\n",
    "    print(\"Nur der Klassifikations-Head wird trainiert!\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for batch_idx, (data, target) in enumerate(train_loader_super):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            transfer_optimizer.zero_grad()\n",
    "            output = transfer_model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            transfer_optimizer.step()\n",
    "            \n",
    "            # Accuracy berechnen\n",
    "            pred = output.argmax(dim=1)\n",
    "            correct += pred.eq(target).sum().item()\n",
    "            total += target.size(0)\n",
    "            \n",
    "            if batch_idx % 5 == 0:\n",
    "                acc = 100. * correct / total\n",
    "                print(f\"Epoch {epoch+1}, Batch {batch_idx}: Loss={loss:.3f}, Acc={acc:.1f}%\")\n",
    "        \n",
    "        epoch_acc = 100. * correct / total\n",
    "        print(f\"Epoch {epoch+1} fertig: Accuracy = {epoch_acc:.1f}%\")\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "# Test Funktion\n",
    "def test_transfer():\n",
    "    transfer_model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader_super:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = transfer_model(data)\n",
    "            pred = output.argmax(dim=1)\n",
    "            correct += pred.eq(target).sum().item()\n",
    "            total += target.size(0)\n",
    "    \n",
    "    accuracy = 100. * correct / total\n",
    "    print(f\"\\nğŸ¯ Test Accuracy: {accuracy:.1f}%\")\n",
    "    return accuracy\n",
    "\n",
    "# Training und Test\n",
    "train_transfer_learning(epochs=30)\n",
    "test_accuracy = test_transfer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02536afc",
   "metadata": {},
   "source": [
    "## 9. Vergleich: Random vs. Self-supervised Features\n",
    "\n",
    "### ğŸ’¡ **Wissenschaftlicher Beweis:**\n",
    "- **Baseline**: ZufÃ¤llige Features (wie wÃ¼rde ein untrainiertes Modell abschneiden?)\n",
    "- **Self-supervised**: Features aus unserem Contrastive Learning\n",
    "- **Fairer Vergleich**: Gleiche Architektur, nur die Initialisierung unterscheidet sich\n",
    "- **Erwartung**: SSL-Features sollten deutlich besser sein!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f142e778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vergleich mit zufÃ¤lligen Features\n",
    "random_encoder = SimpleEncoder().to(device)  # ZufÃ¤llig initialisiert\n",
    "random_transfer = TransferClassifier(random_encoder).to(device)\n",
    "random_optimizer = torch.optim.Adam(random_transfer.classifier.parameters(), lr=0.01)\n",
    "\n",
    "print(\"ğŸ² Teste zufÃ¤llige Features als Baseline...\")\n",
    "\n",
    "# Schnelles Training nur fÃ¼r Vergleich\n",
    "random_transfer.train()\n",
    "for epoch in range(2):  # Weniger Epochen\n",
    "    for batch_idx, (data, target) in enumerate(train_loader_super):\n",
    "        if batch_idx > 10:  # Nur wenige Batches\n",
    "            break\n",
    "            \n",
    "        data, target = data.to(device), target.to(device)\n",
    "        random_optimizer.zero_grad()\n",
    "        output = random_transfer(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        random_optimizer.step()\n",
    "\n",
    "# Test zufÃ¤llige Features\n",
    "random_transfer.eval()\n",
    "random_correct = 0\n",
    "random_total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader_super:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = random_transfer(data)\n",
    "        pred = output.argmax(dim=1)\n",
    "        random_correct += pred.eq(target).sum().item()\n",
    "        random_total += target.size(0)\n",
    "\n",
    "random_accuracy = 100. * random_correct / random_total\n",
    "\n",
    "# Ergebnisse vergleichen\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ğŸ† ERGEBNISSE VERGLEICH:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"ğŸ¯ Self-supervised Features: {test_accuracy:.1f}%\")\n",
    "print(f\"ğŸ² ZufÃ¤llige Features:       {random_accuracy:.1f}%\")\n",
    "print(f\"ğŸ“ˆ Verbesserung:             +{test_accuracy - random_accuracy:.1f}%\")\n",
    "print(\"\")\n",
    "print(\"ğŸ’¡ FAZIT: Self-supervised Learning lernt bessere ReprÃ¤sentationen!\")\n",
    "print(\"   Ohne Labels, nur durch Contrastive Learning!\")\n",
    "\n",
    "# Visualisierung des Vergleichs\n",
    "plt.figure(figsize=(8, 6))\n",
    "methods = ['ZufÃ¤llige Features', 'Self-supervised Features']\n",
    "accuracies = [random_accuracy, test_accuracy]\n",
    "colors = ['lightcoral', 'lightgreen']\n",
    "\n",
    "bars = plt.bar(methods, accuracies, color=colors, alpha=0.7, edgecolor='black')\n",
    "plt.ylabel('Test Accuracy (%)')\n",
    "plt.title('Transfer Learning: ZufÃ¤llige vs. Self-supervised Features')\n",
    "plt.ylim(0, max(accuracies) * 1.2)\n",
    "\n",
    "# Werte auf Balken anzeigen\n",
    "for bar, acc in zip(bars, accuracies):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, \n",
    "             f'{acc:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49ddbda",
   "metadata": {},
   "source": [
    "## 10. Zusammenfassung & Take-Aways\n",
    "\n",
    "### ğŸ’¡ **Das GroÃŸe Bild:**\n",
    "Self-Supervised Learning ist **der Grund**, warum moderne KI so erfolgreich ist:\n",
    "- **GPT**: Lernt Sprache ohne Labels durch \"nÃ¤chstes Wort vorhersagen\"\n",
    "- **BERT**: Lernt durch \"LÃ¼cken fÃ¼llen\" in Texten  \n",
    "- **Vision Models**: Lernen durch Contrastive Learning wie hier gezeigt\n",
    "- **Skalierung**: Kann mit unbegrenzten unlabeled Daten trainiert werden\n",
    "\n",
    "### Was haben wir gelernt?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cde9fb",
   "metadata": {},
   "source": [
    "## ğŸ“ **Self-Supervised Learning Zusammenfassung**\n",
    "\n",
    "### ğŸ”‘ **Kernprinzipien:**\n",
    "\n",
    "1. **Keine Labels erforderlich** - nur rohe Daten\n",
    "2. **Pretext-Task**: Contrastive Learning - \"gleiche Bilder Ã¤hnlich, verschiedene verschieden\"\n",
    "3. **Augmentierungen** sind entscheidend fÃ¼r den Erfolg\n",
    "4. **Transfer Learning**: Gelernte Features fÃ¼r andere Aufgaben nutzen\n",
    "\n",
    "### ğŸ“Š **Unsere Ergebnisse:**\n",
    "- Self-supervised Features Ã¼bertreffen zufÃ¤llige Features deutlich\n",
    "- Das Modell lernt sinnvolle Cluster ohne Labels\n",
    "- Transfer Learning funktioniert mit wenigen gelabelten Daten\n",
    "\n",
    "### ğŸš€ **Praktische Anwendungen:**\n",
    "\n",
    "- **Medizin**: Vortraining auf unlabeled Scans, dann Fine-tuning auf spezifische Krankheiten\n",
    "- **Industrie**: QualitÃ¤tskontrolle mit wenigen Labels\n",
    "- **NLP**: GPT, BERT - alle nutzen Self-supervised Learning!\n",
    "\n",
    "### âš¡ **Vorteile:**\n",
    "- Nutzt groÃŸe Mengen unlabeled Daten\n",
    "- Bessere Features als zufÃ¤llige Initialisierung\n",
    "- Reduziert Bedarf an teuren Labels\n",
    "\n",
    "### âš ï¸ **Herausforderungen:**\n",
    "- Augmentierungen mÃ¼ssen gut gewÃ¤hlt sein\n",
    "- Rechenaufwand fÃ¼r Contrastive Learning\n",
    "- Pretext-Task muss sinnvolle Features fÃ¶rdern\n",
    "\n",
    "### ğŸ”¬ **WeiterfÃ¼hrende Methoden:**\n",
    "- **SimCLR, SwAV, BYOL** - fortgeschrittene Contrastive Learning Methoden\n",
    "- **Masked Autoencoders (MAE)** - wie BERT fÃ¼r Bilder\n",
    "- **Multimodal Learning** - Text + Bilder (wie CLIP)\n",
    "\n",
    "---\n",
    "\n",
    "**ğŸ¯ Zentrale Erkenntnis:** Self-supervised Learning macht unlabeled Daten nutzbar und ist ein SchlÃ¼ssel fÃ¼r den Erfolg moderner KI-Systeme!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lecture_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
