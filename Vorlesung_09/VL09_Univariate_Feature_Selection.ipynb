{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6471bd21",
   "metadata": {},
   "source": [
    "# Univariate Feature Selection\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/klar74/WS2025_lecture/blob/main/Vorlesung_09/VL09_Univariate_Feature_Selection.ipynb)\n",
    "\n",
    "**Lernziel:** Verstehen und anwenden von univariaten Feature Selection Methoden\n",
    "\n",
    "**Methode:**\n",
    "- üìä **F-Test (ANOVA):** F√ºr numerische Features und kategoriale Zielvariable\n",
    "\n",
    "**Szenario:** Welche Features sind am wichtigsten f√ºr die Vorhersage?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b040e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# F√ºr bessere Plots\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"üìö Libraries geladen!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd159c6",
   "metadata": {},
   "source": [
    "## 1. Datensatz erstellen\n",
    "\n",
    "Wir erstellen einen synthetischen Datensatz mit verschiedenen Feature-Typen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a089212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthetischen Datensatz erstellen\n",
    "np.random.seed(42)\n",
    "\n",
    "# Basis-Features mit make_classification\n",
    "X_base, y = make_classification(\n",
    "    n_samples=1000,\n",
    "    n_features=10,\n",
    "    n_informative=5,\n",
    "    n_redundant=2,\n",
    "    n_clusters_per_class=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Zus√§tzliche kategoriale Features erstellen\n",
    "n_samples = X_base.shape[0]\n",
    "\n",
    "# Kategoriale Features (f√ºr Chi-Square Test)\n",
    "kategorie_A = np.random.choice(['low', 'medium', 'high'], n_samples, p=[0.3, 0.4, 0.3])\n",
    "kategorie_B = np.random.choice(['type1', 'type2', 'type3'], n_samples)\n",
    "\n",
    "# Eine kategorie die mit y korreliert (informativ)\n",
    "kategorie_informativ = np.where(y == 1, \n",
    "                                np.random.choice(['A', 'B'], n_samples, p=[0.8, 0.2]),\n",
    "                                np.random.choice(['A', 'B'], n_samples, p=[0.2, 0.8]))\n",
    "\n",
    "# Noise Features hinzuf√ºgen\n",
    "noise_features = np.random.randn(n_samples, 5)\n",
    "\n",
    "# Alles zu einem DataFrame kombinieren\n",
    "df = pd.DataFrame(X_base, columns=[f'numeric_{i}' for i in range(10)])\n",
    "df['kategorie_A'] = kategorie_A\n",
    "df['kategorie_B'] = kategorie_B\n",
    "df['kategorie_informativ'] = kategorie_informativ\n",
    "\n",
    "# Noise features hinzuf√ºgen\n",
    "for i in range(5):\n",
    "    df[f'noise_{i}'] = noise_features[:, i]\n",
    "\n",
    "df['target'] = y\n",
    "\n",
    "print(f\"Dataset erstellt: {df.shape}\")\n",
    "print(f\"Features: {df.columns.tolist()}\")\n",
    "print(f\"\\nTarget-Verteilung:\")\n",
    "print(df['target'].value_counts())\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1dbdad0",
   "metadata": {},
   "source": [
    "## 2. F-Test (ANOVA) f√ºr numerische Features\n",
    "\n",
    "Der **F-Test** misst, ob numerische Features signifikant unterschiedliche Mittelwerte zwischen den Klassen haben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c90fa5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerische Features extrahieren\n",
    "numeric_features = [col for col in df.columns if col.startswith(('numeric_', 'noise_'))]\n",
    "X_numeric = df[numeric_features]\n",
    "y_target = df['target']\n",
    "\n",
    "print(f\"Numerische Features: {len(numeric_features)}\")\n",
    "print(f\"Features: {numeric_features}\")\n",
    "\n",
    "# F-Test durchf√ºhren\n",
    "f_selector = SelectKBest(score_func=f_classif, k='all')\n",
    "f_selector.fit(X_numeric, y_target)\n",
    "\n",
    "# Ergebnisse sammeln\n",
    "f_scores = f_selector.scores_\n",
    "f_pvalues = f_selector.pvalues_\n",
    "\n",
    "# Ergebnisse in DataFrame\n",
    "f_results = pd.DataFrame({\n",
    "    'Feature': numeric_features,\n",
    "    'F_Score': f_scores,\n",
    "    'P_Value': f_pvalues,\n",
    "    'Significant': f_pvalues < 0.05\n",
    "})\n",
    "\n",
    "# Nach F-Score sortieren\n",
    "f_results = f_results.sort_values('F_Score', ascending=False)\n",
    "\n",
    "print(\"\\nüîç F-Test Ergebnisse (numerische Features):\")\n",
    "print(f_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b966580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# F-Test Ergebnisse visualisieren\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Subplot 1: F-Scores\n",
    "plt.subplot(1, 2, 1)\n",
    "colors = ['green' if sig else 'red' for sig in f_results['Significant']]\n",
    "bars = plt.bar(range(len(f_results)), f_results['F_Score'], color=colors, alpha=0.7)\n",
    "plt.xticks(range(len(f_results)), f_results['Feature'], rotation=45, ha='right')\n",
    "plt.ylabel('F-Score')\n",
    "plt.title('F-Test Scores (numerische Features)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Legende\n",
    "import matplotlib.patches as mpatches\n",
    "green_patch = mpatches.Patch(color='green', alpha=0.7, label='Signifikant (p < 0.05)')\n",
    "red_patch = mpatches.Patch(color='red', alpha=0.7, label='Nicht signifikant')\n",
    "plt.legend(handles=[green_patch, red_patch])\n",
    "\n",
    "# Subplot 2: P-Values\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(range(len(f_results)), -np.log10(f_results['P_Value']), color=colors, alpha=0.7)\n",
    "plt.xticks(range(len(f_results)), f_results['Feature'], rotation=45, ha='right')\n",
    "plt.ylabel('-log10(P-Value)')\n",
    "plt.title('Statistische Signifikanz')\n",
    "plt.axhline(y=-np.log10(0.05), color='black', linestyle='--', alpha=0.7, label='p = 0.05')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüìä Interpretation:\")\n",
    "print(f\"- Gr√ºne Balken: Statistisch signifikante Features (p < 0.05)\")\n",
    "print(f\"- Rote Balken: Nicht signifikante Features\")\n",
    "print(f\"- H√∂here F-Scores = bessere Trennung zwischen Klassen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade19797",
   "metadata": {},
   "source": [
    "## Zusammenfassung: F-Test f√ºr Feature Selection\n",
    "\n",
    "### Was haben wir gelernt?\n",
    "\n",
    "**F-Test (ANOVA):**\n",
    "- üìä Misst, ob numerische Features signifikant unterschiedliche Mittelwerte zwischen Klassen haben\n",
    "- üéØ H√∂here F-Scores = bessere Trennung zwischen Klassen  \n",
    "- üìà P-Werte < 0.05 = statistisch signifikant\n",
    "\n",
    "**Praktische Anwendung:**\n",
    "- ‚úÖ Gut f√ºr: Numerische Features ‚Üí Kategoriale Zielvariable\n",
    "- üîç Hilft bei: Identifikation der wichtigsten Features\n",
    "- ‚ö†Ô∏è Limitierung: Betrachtet Features einzeln (univariat), nicht Kombinationen\n",
    "\n",
    "**Next Steps:**\n",
    "- Chi-Square Test f√ºr kategoriale Features\n",
    "- Multivariate Feature Selection Methoden\n",
    "- Anwendung in echten ML-Pipelines"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lecture_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
